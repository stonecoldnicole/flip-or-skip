# flip-or-skip

## Domain Background
This project is focusing on real estate data, specifically past real estate sales and current real estate listings in Los Angeles County. Within the domain of real estate, this project will be considering how machine learning can be used to aid in identifying quality investment properties which can be purchased below market value, generally due to the property being in a distressed state, and then renovating the property in order for it to be sold at a profit. This process is commonly referred to as a “flip” within the domain of real estate. Finding properties which present a successful margin for a “flip” makeover can be challenging. The best indicator of a profitable real estate investment is a property which can be acquired below 70% of the value at which it could potentially be sold if it were in like-new condition, also referred to as “after repair value” (ARV) [1]. The total cost of the anticipated repairs needs to be accounted for as well, but that requires a person to scope, design, and purchase. That overall renovation cost is then subtracted from the 70% of ARV to provide a maximum purchase price for this investment.

## Problem Statement
A best-case scenario for a “flip” would be purchasing a like-new home that needs no repairs or updates and can be sold immediately as-is for a profit. This scenario would be a house at 70% or less of the ARV. Therefore, our model should target any homes that are listed at 70% or below the estimated value for that particular property. This problem suggests the use of regression and a possible solution can be using supervised learning to determine an estimate of the resale value of all listed properties. This estimate can then be compared to the actual list price to determine if the property can be acquired for 70% or less of its predicted resale value.

## Datasets and Inputs
This project uses data from the Redfin database of MLS listings for the Santa Clarita region of Los Angeles County. Listing information of recent transactions from the past three months will be downloaded, as well as all current listings for the region. There are a total of 865 past sale samples being used to build the estimator model and 605 current listings for which the model can be used to identify potential “flip” opportunities. For both current listings and recent sales, each sample contains the following features: SALE TYPE: {<string data>}, SOLD DATE: {<string data>}, PROPERTY TYPE: {<string data>}, ADDRESS: {<string data>}, CITY: {<string data>}, STATE OR PROVINCE: {<string data>}, ZIP OR POST: {<integer data>}, PRICE: {<integer data>}, BEDS: {<integer data>}, BATHS: {<float data>}, LOCATION: {<string data>}, SQUARE FEET: {<integer data>}, LOT SIZE: {<integer data>}, YEAR BUILT: {<integer data>}, DAYS ON MARKET: {<integer data>}, $/SQUARE FEET: {<integer data>}, HOA/MONTH: {<integer data>}, STATUS: {<string data>}, NEXT OPEN HOUSE START TIME: {<date data>}, NEXT OPEN HOUSE END TIME: {<date data>}, URL: {<string data>}, SOURCE: {<string data>}, MLS#: {<string data>}, FAVORITE: {<character data>}, INTERESTED: {<character data>}, LATITUDE: {<float data>}, LONGITUDE: {<float data>}. Some preprocessing steps will be necessary to create this model. 

The following features will be removed before building the model: SOLD DATE, STATE OR PROVINCE, NEXT OPEN HOUSE START TIME, NEXT OPEN HOUSE END TIME, SOURCE, MLS#, FAVORITE, INTERESTED. Removing these features before training will prune irrelevant information for predicting property value, and it should also remove some inherent bias for listings created by Redfin, who is both the source of this data as well as a real estate brokerage. All string data will need to be transformed using one hot encoding to convert these categorical variables into numerical values which the supervised learning algorithm can use. The PRICE feature will be the target for training, and will need to be removed for testing on recent sales, as well as predicting actual value of current listings.

## Solution Statement
In order to estimate the price at which a home could be sold post-repairs, a machine learning model could be fit on real sales data for the past 3 months, as reported by Redfin.com. This estimator can then be used to predict at what price a particular home should be able to sell. Then with new listings, comparisons can be made between the newly listed property’s list price and the estimated sale value. Any properties that are listed at or below 70% of the estimated sale value can then be recommended for further inspection as potential “flip” investments.

## Benchmark Model
Without the aid of machine learning models, list prices are determined by realtors and then “true” house values are determined by an appraiser using a thorough rubric of property characteristics. Appraiser evaluations cost several hundred dollars for each property, thus a rough evaluation is completed by the realtor using comparable recent sales or other listings in order to determine a proper list price. The most basic way a realtor determines how much to list a house is to consider current listings and recent sales for the immediate neighborhood of the property they are considering. An average price per square foot of house is determined and then multiplied by the square footage of the property they are listing. This is generally a pretty good starting place, and many realtors list properties solely on this number. A more accurate estimate can be determined by considering lot size, number of bedrooms, and number of bathrooms in comparison to recent sales and then adjusting the list price accordingly. However, for the benchmark in this design, it will suffice to consider price per square foot as an average for the zip code within which the home is located.

## Evaluation Metrics
A new model can be tested by considering how well it would be able to predict past sales prices given the listing information. This means some of the past sales data will need to be withheld from training the model in order to be used during testing the model. The Mean Absolute Percentage Error (MAPE) can be calculated in order to compare the performance of the newly created estimator model versus that of the benchmark value for that property (price per square foot per zip code) to see which is more accurate at predicting the true sale price of recent sales.

## Project Design
This project will implement an estimator for property values using an XGBoost model. The samples will be randomized and then split into training and testing groups. The training data will be cross validated and an accuracy score will be determined for the model’s performance on the test samples. If the model performs better than the benchmark, it can be used to help find potential “flip” properties by separating out any properties that are listed at or below 70% of their predicted value for further investigation. 

## References
[1] https://www.biggerpockets.com/blog/2014-02-14-70-rule-bible
