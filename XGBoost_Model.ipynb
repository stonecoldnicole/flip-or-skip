{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import mxnet as mx\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = pd.read_csv('transformed_active.csv')\n",
    "past = pd.read_csv('transformed_past.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590000.0</td>\n",
       "      <td>-0.383990</td>\n",
       "      <td>2.188086</td>\n",
       "      <td>0.325750</td>\n",
       "      <td>1.335988</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>-0.204843</td>\n",
       "      <td>1.428275</td>\n",
       "      <td>-1.401699</td>\n",
       "      <td>-0.134462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.101182</td>\n",
       "      <td>-0.661446</td>\n",
       "      <td>0.482604</td>\n",
       "      <td>-0.735396</td>\n",
       "      <td>0.547869</td>\n",
       "      <td>0.169401</td>\n",
       "      <td>-0.218324</td>\n",
       "      <td>-0.172415</td>\n",
       "      <td>0.231593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589000.0</td>\n",
       "      <td>1.369588</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.948351</td>\n",
       "      <td>-3.202843</td>\n",
       "      <td>0.500272</td>\n",
       "      <td>1.857549</td>\n",
       "      <td>1.780308</td>\n",
       "      <td>-1.859527</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.173409</td>\n",
       "      <td>-0.725904</td>\n",
       "      <td>1.569119</td>\n",
       "      <td>0.470643</td>\n",
       "      <td>0.631998</td>\n",
       "      <td>0.609956</td>\n",
       "      <td>-0.262356</td>\n",
       "      <td>-0.034488</td>\n",
       "      <td>-0.233402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664900.0</td>\n",
       "      <td>-3.951300</td>\n",
       "      <td>0.375523</td>\n",
       "      <td>-0.471736</td>\n",
       "      <td>-1.379998</td>\n",
       "      <td>0.326533</td>\n",
       "      <td>-1.055838</td>\n",
       "      <td>0.414315</td>\n",
       "      <td>-1.579257</td>\n",
       "      <td>-1.142416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.152648</td>\n",
       "      <td>-0.796099</td>\n",
       "      <td>0.477727</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>-1.059683</td>\n",
       "      <td>-0.508418</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>-0.571293</td>\n",
       "      <td>1.603781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435000.0</td>\n",
       "      <td>1.496055</td>\n",
       "      <td>2.919255</td>\n",
       "      <td>0.142734</td>\n",
       "      <td>2.609945</td>\n",
       "      <td>1.167647</td>\n",
       "      <td>-0.566106</td>\n",
       "      <td>0.914542</td>\n",
       "      <td>-1.527745</td>\n",
       "      <td>-0.710405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.042684</td>\n",
       "      <td>-0.706107</td>\n",
       "      <td>0.090662</td>\n",
       "      <td>-0.905591</td>\n",
       "      <td>1.083773</td>\n",
       "      <td>0.799150</td>\n",
       "      <td>-0.261384</td>\n",
       "      <td>0.114413</td>\n",
       "      <td>-0.288909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.509651</td>\n",
       "      <td>-0.767731</td>\n",
       "      <td>-0.320817</td>\n",
       "      <td>0.470610</td>\n",
       "      <td>-1.145476</td>\n",
       "      <td>-1.015600</td>\n",
       "      <td>-2.428360</td>\n",
       "      <td>-2.771265</td>\n",
       "      <td>-1.351204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.171488</td>\n",
       "      <td>-0.318554</td>\n",
       "      <td>-0.353788</td>\n",
       "      <td>-0.666221</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>-0.734822</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>-0.228598</td>\n",
       "      <td>0.806828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  590000.0 -0.383990  2.188086  0.325750  1.335988  0.003251 -0.204843   \n",
       "1  589000.0  1.369588  0.018237  0.948351 -3.202843  0.500272  1.857549   \n",
       "2  664900.0 -3.951300  0.375523 -0.471736 -1.379998  0.326533 -1.055838   \n",
       "3  435000.0  1.496055  2.919255  0.142734  2.609945  1.167647 -0.566106   \n",
       "4  400000.0  0.509651 -0.767731 -0.320817  0.470610 -1.145476 -1.015600   \n",
       "\n",
       "          7         8         9  ...        76        77        78        79  \\\n",
       "0  1.428275 -1.401699 -0.134462  ... -0.000732 -0.101182 -0.661446  0.482604   \n",
       "1  1.780308 -1.859527  0.612540  ... -0.000137  0.173409 -0.725904  1.569119   \n",
       "2  0.414315 -1.579257 -1.142416  ... -0.000833 -0.152648 -0.796099  0.477727   \n",
       "3  0.914542 -1.527745 -0.710405  ... -0.000571 -0.042684 -0.706107  0.090662   \n",
       "4 -2.428360 -2.771265 -1.351204  ... -0.001295  0.171488 -0.318554 -0.353788   \n",
       "\n",
       "         80        81        82        83        84        85  \n",
       "0 -0.735396  0.547869  0.169401 -0.218324 -0.172415  0.231593  \n",
       "1  0.470643  0.631998  0.609956 -0.262356 -0.034488 -0.233402  \n",
       "2  0.468923 -1.059683 -0.508418  0.011712 -0.571293  1.603781  \n",
       "3 -0.905591  1.083773  0.799150 -0.261384  0.114413 -0.288909  \n",
       "4 -0.666221  0.332001 -0.734822  0.003220 -0.228598  0.806828  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570000.0</td>\n",
       "      <td>-0.818375</td>\n",
       "      <td>3.408697</td>\n",
       "      <td>0.240056</td>\n",
       "      <td>1.993104</td>\n",
       "      <td>-0.653233</td>\n",
       "      <td>-0.160618</td>\n",
       "      <td>-0.290284</td>\n",
       "      <td>0.754372</td>\n",
       "      <td>0.171967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.017664</td>\n",
       "      <td>-0.154569</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>-0.910630</td>\n",
       "      <td>0.770455</td>\n",
       "      <td>0.173211</td>\n",
       "      <td>-0.117439</td>\n",
       "      <td>-0.122622</td>\n",
       "      <td>0.631282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535000.0</td>\n",
       "      <td>-0.862253</td>\n",
       "      <td>3.655905</td>\n",
       "      <td>0.327998</td>\n",
       "      <td>2.054754</td>\n",
       "      <td>-0.439575</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>0.680315</td>\n",
       "      <td>0.278540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>-0.010034</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>0.371394</td>\n",
       "      <td>0.444565</td>\n",
       "      <td>0.313832</td>\n",
       "      <td>-0.077385</td>\n",
       "      <td>0.209810</td>\n",
       "      <td>-0.327195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525000.0</td>\n",
       "      <td>-0.856397</td>\n",
       "      <td>3.756488</td>\n",
       "      <td>0.116754</td>\n",
       "      <td>2.163320</td>\n",
       "      <td>-0.277850</td>\n",
       "      <td>-0.204776</td>\n",
       "      <td>-0.271301</td>\n",
       "      <td>0.712407</td>\n",
       "      <td>0.141604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.049330</td>\n",
       "      <td>-0.079142</td>\n",
       "      <td>-0.232725</td>\n",
       "      <td>0.663266</td>\n",
       "      <td>0.301571</td>\n",
       "      <td>-0.110841</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>0.039595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>560000.0</td>\n",
       "      <td>-1.436549</td>\n",
       "      <td>3.568422</td>\n",
       "      <td>0.423014</td>\n",
       "      <td>1.428297</td>\n",
       "      <td>-0.991835</td>\n",
       "      <td>0.073920</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.785621</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>-0.070065</td>\n",
       "      <td>0.168928</td>\n",
       "      <td>-0.327523</td>\n",
       "      <td>0.286340</td>\n",
       "      <td>-0.135640</td>\n",
       "      <td>-0.097357</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>-0.685028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560000.0</td>\n",
       "      <td>-0.099081</td>\n",
       "      <td>3.604430</td>\n",
       "      <td>0.071807</td>\n",
       "      <td>2.280483</td>\n",
       "      <td>-0.136271</td>\n",
       "      <td>-0.033714</td>\n",
       "      <td>-0.143441</td>\n",
       "      <td>0.739840</td>\n",
       "      <td>-0.034038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>-0.093392</td>\n",
       "      <td>-0.036924</td>\n",
       "      <td>-0.684056</td>\n",
       "      <td>0.541267</td>\n",
       "      <td>0.165751</td>\n",
       "      <td>-0.104619</td>\n",
       "      <td>0.181542</td>\n",
       "      <td>-0.492672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  570000.0 -0.818375  3.408697  0.240056  1.993104 -0.653233 -0.160618   \n",
       "1  535000.0 -0.862253  3.655905  0.327998  2.054754 -0.439575 -0.048575   \n",
       "2  525000.0 -0.856397  3.756488  0.116754  2.163320 -0.277850 -0.204776   \n",
       "3  560000.0 -1.436549  3.568422  0.423014  1.428297 -0.991835  0.073920   \n",
       "4  560000.0 -0.099081  3.604430  0.071807  2.280483 -0.136271 -0.033714   \n",
       "\n",
       "          7         8         9  ...        76        77        78        79  \\\n",
       "0 -0.290284  0.754372  0.171967  ... -0.001048 -0.017664 -0.154569  0.077670   \n",
       "1 -0.441619  0.680315  0.278540  ... -0.000946 -0.015303 -0.010034 -0.266452   \n",
       "2 -0.271301  0.712407  0.141604  ... -0.000958 -0.001718 -0.049330 -0.079142   \n",
       "3  0.080760  0.785621  0.427419  ... -0.001061 -0.003625 -0.070065  0.168928   \n",
       "4 -0.143441  0.739840 -0.034038  ... -0.000931  0.032677 -0.093392 -0.036924   \n",
       "\n",
       "         80        81        82        83        84        85  \n",
       "0 -0.910630  0.770455  0.173211 -0.117439 -0.122622  0.631282  \n",
       "1  0.371394  0.444565  0.313832 -0.077385  0.209810 -0.327195  \n",
       "2 -0.232725  0.663266  0.301571 -0.110841  0.084703  0.039595  \n",
       "3 -0.327523  0.286340 -0.135640 -0.097357  0.132369 -0.685028  \n",
       "4 -0.684056  0.541267  0.165751 -0.104619  0.181542 -0.492672  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Now that we have cleaned, standardized, and completed dimensionality reduction for our data, let's prep it for our model. We need to extract the price feature to use for our target vector (y). It is the first column of each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target vectors\n",
    "y_active = active.iloc[:,0]\n",
    "y_past = past.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    590000.0\n",
       "1    589000.0\n",
       "2    664900.0\n",
       "3    435000.0\n",
       "4    400000.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_past.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop price column from X features\n",
    "X_active = active.drop(active.columns[0], axis=1)\n",
    "X_past = past.drop(past.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.383990</td>\n",
       "      <td>2.188086</td>\n",
       "      <td>0.325750</td>\n",
       "      <td>1.335988</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>-0.204843</td>\n",
       "      <td>1.428275</td>\n",
       "      <td>-1.401699</td>\n",
       "      <td>-0.134462</td>\n",
       "      <td>-0.471004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.101182</td>\n",
       "      <td>-0.661446</td>\n",
       "      <td>0.482604</td>\n",
       "      <td>-0.735396</td>\n",
       "      <td>0.547869</td>\n",
       "      <td>0.169401</td>\n",
       "      <td>-0.218324</td>\n",
       "      <td>-0.172415</td>\n",
       "      <td>0.231593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.369588</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.948351</td>\n",
       "      <td>-3.202843</td>\n",
       "      <td>0.500272</td>\n",
       "      <td>1.857549</td>\n",
       "      <td>1.780308</td>\n",
       "      <td>-1.859527</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>-0.252534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.173409</td>\n",
       "      <td>-0.725904</td>\n",
       "      <td>1.569119</td>\n",
       "      <td>0.470643</td>\n",
       "      <td>0.631998</td>\n",
       "      <td>0.609956</td>\n",
       "      <td>-0.262356</td>\n",
       "      <td>-0.034488</td>\n",
       "      <td>-0.233402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.951300</td>\n",
       "      <td>0.375523</td>\n",
       "      <td>-0.471736</td>\n",
       "      <td>-1.379998</td>\n",
       "      <td>0.326533</td>\n",
       "      <td>-1.055838</td>\n",
       "      <td>0.414315</td>\n",
       "      <td>-1.579257</td>\n",
       "      <td>-1.142416</td>\n",
       "      <td>-0.238487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.152648</td>\n",
       "      <td>-0.796099</td>\n",
       "      <td>0.477727</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>-1.059683</td>\n",
       "      <td>-0.508418</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>-0.571293</td>\n",
       "      <td>1.603781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.496055</td>\n",
       "      <td>2.919255</td>\n",
       "      <td>0.142734</td>\n",
       "      <td>2.609945</td>\n",
       "      <td>1.167647</td>\n",
       "      <td>-0.566106</td>\n",
       "      <td>0.914542</td>\n",
       "      <td>-1.527745</td>\n",
       "      <td>-0.710405</td>\n",
       "      <td>-0.293602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.042684</td>\n",
       "      <td>-0.706107</td>\n",
       "      <td>0.090662</td>\n",
       "      <td>-0.905591</td>\n",
       "      <td>1.083773</td>\n",
       "      <td>0.799150</td>\n",
       "      <td>-0.261384</td>\n",
       "      <td>0.114413</td>\n",
       "      <td>-0.288909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509651</td>\n",
       "      <td>-0.767731</td>\n",
       "      <td>-0.320817</td>\n",
       "      <td>0.470610</td>\n",
       "      <td>-1.145476</td>\n",
       "      <td>-1.015600</td>\n",
       "      <td>-2.428360</td>\n",
       "      <td>-2.771265</td>\n",
       "      <td>-1.351204</td>\n",
       "      <td>0.347469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.171488</td>\n",
       "      <td>-0.318554</td>\n",
       "      <td>-0.353788</td>\n",
       "      <td>-0.666221</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>-0.734822</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>-0.228598</td>\n",
       "      <td>0.806828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0 -0.383990  2.188086  0.325750  1.335988  0.003251 -0.204843  1.428275   \n",
       "1  1.369588  0.018237  0.948351 -3.202843  0.500272  1.857549  1.780308   \n",
       "2 -3.951300  0.375523 -0.471736 -1.379998  0.326533 -1.055838  0.414315   \n",
       "3  1.496055  2.919255  0.142734  2.609945  1.167647 -0.566106  0.914542   \n",
       "4  0.509651 -0.767731 -0.320817  0.470610 -1.145476 -1.015600 -2.428360   \n",
       "\n",
       "          8         9        10  ...        76        77        78        79  \\\n",
       "0 -1.401699 -0.134462 -0.471004  ... -0.000732 -0.101182 -0.661446  0.482604   \n",
       "1 -1.859527  0.612540 -0.252534  ... -0.000137  0.173409 -0.725904  1.569119   \n",
       "2 -1.579257 -1.142416 -0.238487  ... -0.000833 -0.152648 -0.796099  0.477727   \n",
       "3 -1.527745 -0.710405 -0.293602  ... -0.000571 -0.042684 -0.706107  0.090662   \n",
       "4 -2.771265 -1.351204  0.347469  ... -0.001295  0.171488 -0.318554 -0.353788   \n",
       "\n",
       "         80        81        82        83        84        85  \n",
       "0 -0.735396  0.547869  0.169401 -0.218324 -0.172415  0.231593  \n",
       "1  0.470643  0.631998  0.609956 -0.262356 -0.034488 -0.233402  \n",
       "2  0.468923 -1.059683 -0.508418  0.011712 -0.571293  1.603781  \n",
       "3 -0.905591  1.083773  0.799150 -0.261384  0.114413 -0.288909  \n",
       "4 -0.666221  0.332001 -0.734822  0.003220 -0.228598  0.806828  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.818375</td>\n",
       "      <td>3.408697</td>\n",
       "      <td>0.240056</td>\n",
       "      <td>1.993104</td>\n",
       "      <td>-0.653233</td>\n",
       "      <td>-0.160618</td>\n",
       "      <td>-0.290284</td>\n",
       "      <td>0.754372</td>\n",
       "      <td>0.171967</td>\n",
       "      <td>-0.003675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.017664</td>\n",
       "      <td>-0.154569</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>-0.910630</td>\n",
       "      <td>0.770455</td>\n",
       "      <td>0.173211</td>\n",
       "      <td>-0.117439</td>\n",
       "      <td>-0.122622</td>\n",
       "      <td>0.631282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.862253</td>\n",
       "      <td>3.655905</td>\n",
       "      <td>0.327998</td>\n",
       "      <td>2.054754</td>\n",
       "      <td>-0.439575</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>0.680315</td>\n",
       "      <td>0.278540</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>-0.010034</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>0.371394</td>\n",
       "      <td>0.444565</td>\n",
       "      <td>0.313832</td>\n",
       "      <td>-0.077385</td>\n",
       "      <td>0.209810</td>\n",
       "      <td>-0.327195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.856397</td>\n",
       "      <td>3.756488</td>\n",
       "      <td>0.116754</td>\n",
       "      <td>2.163320</td>\n",
       "      <td>-0.277850</td>\n",
       "      <td>-0.204776</td>\n",
       "      <td>-0.271301</td>\n",
       "      <td>0.712407</td>\n",
       "      <td>0.141604</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.049330</td>\n",
       "      <td>-0.079142</td>\n",
       "      <td>-0.232725</td>\n",
       "      <td>0.663266</td>\n",
       "      <td>0.301571</td>\n",
       "      <td>-0.110841</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>0.039595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.436549</td>\n",
       "      <td>3.568422</td>\n",
       "      <td>0.423014</td>\n",
       "      <td>1.428297</td>\n",
       "      <td>-0.991835</td>\n",
       "      <td>0.073920</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.785621</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>-0.090199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>-0.070065</td>\n",
       "      <td>0.168928</td>\n",
       "      <td>-0.327523</td>\n",
       "      <td>0.286340</td>\n",
       "      <td>-0.135640</td>\n",
       "      <td>-0.097357</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>-0.685028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099081</td>\n",
       "      <td>3.604430</td>\n",
       "      <td>0.071807</td>\n",
       "      <td>2.280483</td>\n",
       "      <td>-0.136271</td>\n",
       "      <td>-0.033714</td>\n",
       "      <td>-0.143441</td>\n",
       "      <td>0.739840</td>\n",
       "      <td>-0.034038</td>\n",
       "      <td>-0.003269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>-0.093392</td>\n",
       "      <td>-0.036924</td>\n",
       "      <td>-0.684056</td>\n",
       "      <td>0.541267</td>\n",
       "      <td>0.165751</td>\n",
       "      <td>-0.104619</td>\n",
       "      <td>0.181542</td>\n",
       "      <td>-0.492672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0 -0.818375  3.408697  0.240056  1.993104 -0.653233 -0.160618 -0.290284   \n",
       "1 -0.862253  3.655905  0.327998  2.054754 -0.439575 -0.048575 -0.441619   \n",
       "2 -0.856397  3.756488  0.116754  2.163320 -0.277850 -0.204776 -0.271301   \n",
       "3 -1.436549  3.568422  0.423014  1.428297 -0.991835  0.073920  0.080760   \n",
       "4 -0.099081  3.604430  0.071807  2.280483 -0.136271 -0.033714 -0.143441   \n",
       "\n",
       "          8         9        10  ...        76        77        78        79  \\\n",
       "0  0.754372  0.171967 -0.003675  ... -0.001048 -0.017664 -0.154569  0.077670   \n",
       "1  0.680315  0.278540 -0.005924  ... -0.000946 -0.015303 -0.010034 -0.266452   \n",
       "2  0.712407  0.141604  0.007767  ... -0.000958 -0.001718 -0.049330 -0.079142   \n",
       "3  0.785621  0.427419 -0.090199  ... -0.001061 -0.003625 -0.070065  0.168928   \n",
       "4  0.739840 -0.034038 -0.003269  ... -0.000931  0.032677 -0.093392 -0.036924   \n",
       "\n",
       "         80        81        82        83        84        85  \n",
       "0 -0.910630  0.770455  0.173211 -0.117439 -0.122622  0.631282  \n",
       "1  0.371394  0.444565  0.313832 -0.077385  0.209810 -0.327195  \n",
       "2 -0.232725  0.663266  0.301571 -0.110841  0.084703  0.039595  \n",
       "3 -0.327523  0.286340 -0.135640 -0.097357  0.132369 -0.685028  \n",
       "4 -0.684056  0.541267  0.165751 -0.104619  0.181542 -0.492672  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_past.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split past sales into training and validation samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_past, y_past, test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (668, 85)\n",
      "y_train shape:  (668,)\n",
      "X_test shape:  (168, 85)\n",
      "y_test shape:  (168,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation samples\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (467, 85)\n",
      "y_train shape:  (467,)\n",
      "X_val shape:  (201, 85)\n",
      "y_val shape:  (201,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_val shape: \", X_val.shape)\n",
    "print(\"y_val shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Training Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker session and role\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify an output path\n",
    "prefix = 'listings'\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/listings'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store testing samples in S3 for later use\n",
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store training samples in S3, making sure to concatenate y label as first column\n",
    "pd.concat([y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store validation samples in S3, making sure to concatenate y label as first column\n",
    "pd.concat([y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "prefix = 'listings'\n",
    "\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "We will use SageMaker's built in XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region, container, and output_path\n",
    "region_name = 'us-east-2'\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                          'xgboost', \n",
    "                          repo_version = '0.90-1'); \n",
    "\n",
    "output_path = 's3://{}/{}/output'.format(session.default_bucket(), prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct estimator object\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                      role = role, \n",
    "                                      train_instance_count = 1, \n",
    "                                      train_instance_type = 'ml.c4.xlarge', \n",
    "                                      output_path = output_path, \n",
    "                                      sagemaker_session = session);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "Let's see if we can improve the Mean Absolute Percentage Error (rmse) for the validation samples by changing some of the hyperparameters our model is using for training. Each cell below will be used to alter a single hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# Successful values that I have used previously will be our baseline\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        rate_drop=0.3,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 20, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'eta'      : ContinuousParameter(0.0, 0.5),\n",
    "                                                  'lambda'   : ContinuousParameter(0, 1000),\n",
    "                                                  'max_depth': IntegerParameter(5, 17),\n",
    "                                                  'num_round': IntegerParameter(100, 500),\n",
    "                                                  'min_child_weight': IntegerParameter(1, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We will use the built-in \"fit\" function with the model we defined above, and access the training and validation data we have stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a wrapper around the location of our train and validation data\n",
    "# This makes sure SageMaker knows our data is in csv format\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 20:29:26 Starting - Preparing the instances for training\n",
      "2019-09-06 20:29:26 Downloading - Downloading input data\n",
      "2019-09-06 20:29:26 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 20:29:26 Uploading - Uploading generated training model\n",
      "2019-09-06 20:29:26 Completed - Training job completed\u001b[31m2019-09-06 20:29:16,089 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,090 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,090 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,094 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,110 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,113 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,113 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,114 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,114 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,115 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[20:29:16] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,134 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[20:29:16] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,148 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,148 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,148 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,148 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 20:29:16,148 root         INFO     {'_tuning_objective_metric': 'validation:mae', 'max_depth': 11, 'subsample': 0.8, 'num_round': 421, 'gamma': 4.0, 'eval_metric': ['mae'], 'early_stopping_rounds': 10, 'rate_drop': 0.3, 'lambda': 474.24314972169725, 'objective': 'reg:linear', 'eta': 0.373620175273373, 'min_child_weight': 10.0}\u001b[0m\n",
      "\u001b[31m[20:29:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:430406#011validation-mae:420814\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:359158#011validation-mae:349810\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:300527#011validation-mae:292694\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:251817#011validation-mae:245751\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:212551#011validation-mae:207996\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:181529#011validation-mae:178857\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:158230#011validation-mae:156182\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:139301#011validation-mae:137752\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:123392#011validation-mae:122455\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:110041#011validation-mae:109803\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:98896.9#011validation-mae:99218.2\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:90450.2#011validation-mae:91316.5\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:82899.3#011validation-mae:84128.2\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:75979.6#011validation-mae:78642.5\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:70457.9#011validation-mae:73748.9\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:66617.5#011validation-mae:70918.8\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:62749.2#011validation-mae:68287.2\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:59462.1#011validation-mae:66347.9\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:56871#011validation-mae:64722.8\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:54461.4#011validation-mae:62912.9\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:52521.5#011validation-mae:61719.4\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:50598.8#011validation-mae:60352.4\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:49144.4#011validation-mae:59452.3\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:47862.1#011validation-mae:58711.4\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:46635.3#011validation-mae:57792.5\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:45543.2#011validation-mae:56683.6\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:44649.5#011validation-mae:55983.4\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:43671.7#011validation-mae:55261.7\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:42765.2#011validation-mae:54578.2\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:41887.9#011validation-mae:54013.4\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:41035.6#011validation-mae:53457.9\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:40305.5#011validation-mae:52822.9\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:39627.6#011validation-mae:52225.8\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:38740.7#011validation-mae:51740.4\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:38124.9#011validation-mae:51237.6\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:37347.2#011validation-mae:50733.6\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:36712.6#011validation-mae:50195.4\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:36075.2#011validation-mae:49686.9\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:35485.3#011validation-mae:49441.1\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:34928.3#011validation-mae:49002.3\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:34325#011validation-mae:48688.2\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:33848.1#011validation-mae:48528.2\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:33379.6#011validation-mae:48249.2\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:32955.3#011validation-mae:47888.7\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:32504.8#011validation-mae:47616.6\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:32088.5#011validation-mae:47297.4\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:31689.3#011validation-mae:47036.8\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:31273.5#011validation-mae:46884.1\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:30900#011validation-mae:46739.7\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:30413.4#011validation-mae:46414.6\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:30049.3#011validation-mae:46142.4\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:29706.4#011validation-mae:45881.4\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:29394.4#011validation-mae:45656.8\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:29018.4#011validation-mae:45421\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:28694.3#011validation-mae:45235.2\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:28394.2#011validation-mae:45089.5\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:28070.1#011validation-mae:44862.8\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:27727.4#011validation-mae:44714.9\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:27453.6#011validation-mae:44523.7\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:27213.3#011validation-mae:44442.1\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:26874.8#011validation-mae:44226\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:26633.5#011validation-mae:44148.7\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:26416.4#011validation-mae:43988.3\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:26171.3#011validation-mae:43843.1\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:25939.9#011validation-mae:43704.5\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:25623.2#011validation-mae:43481.4\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:25424.6#011validation-mae:43348.6\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:25178.3#011validation-mae:43186.9\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:24891.2#011validation-mae:42910.1\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:24676.7#011validation-mae:42822.4\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:24405.1#011validation-mae:42637.7\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:24141.1#011validation-mae:42563.6\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:23869#011validation-mae:42441.9\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:23625.6#011validation-mae:42372.6\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:23393.1#011validation-mae:42300.8\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:23186.7#011validation-mae:42213.8\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:22999.7#011validation-mae:42045.9\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:22813.9#011validation-mae:41908\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:22636.5#011validation-mae:41851.7\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:22443.5#011validation-mae:41778.9\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:22192.2#011validation-mae:41630.2\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:22002.8#011validation-mae:41542\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:21826.2#011validation-mae:41455.3\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:21631.1#011validation-mae:41341.7\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:21426.3#011validation-mae:41236.9\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:21210.8#011validation-mae:41139\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:21063.2#011validation-mae:41113.9\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:20845.3#011validation-mae:40960.6\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:20638.3#011validation-mae:40864.5\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:20461.3#011validation-mae:40779.9\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:20318.7#011validation-mae:40668.6\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:20127.2#011validation-mae:40622.3\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:19976.8#011validation-mae:40522.5\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:19771.5#011validation-mae:40479.4\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:19607.8#011validation-mae:40395.1\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:19466.9#011validation-mae:40267.8\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:19322.4#011validation-mae:40211.8\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:19170.1#011validation-mae:40132.3\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:19009.8#011validation-mae:40044.1\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:18880.8#011validation-mae:39906.6\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:18743.8#011validation-mae:39951.6\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:18593.2#011validation-mae:39895.1\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:18485.1#011validation-mae:39945.7\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:18345.3#011validation-mae:39880.6\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:18223#011validation-mae:39845.9\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:18102.8#011validation-mae:39739.7\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:18003.5#011validation-mae:39750.9\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:17876.7#011validation-mae:39672.3\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:17785.7#011validation-mae:39666.3\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:17682.3#011validation-mae:39577.4\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:17529#011validation-mae:39494.3\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:17400.5#011validation-mae:39443.7\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:17303.1#011validation-mae:39395.7\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:17182.2#011validation-mae:39349.3\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:17090#011validation-mae:39289.7\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:16977.9#011validation-mae:39223.3\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:16888.8#011validation-mae:39165.9\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:16789.5#011validation-mae:39145.9\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:16686.3#011validation-mae:39128.2\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:16560.8#011validation-mae:39095\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:16403.9#011validation-mae:39040.5\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:16277.6#011validation-mae:39025.9\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:16143#011validation-mae:38933.8\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:16050.8#011validation-mae:38915.7\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:15952.3#011validation-mae:38855.8\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:15840.7#011validation-mae:38789.6\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:15746.9#011validation-mae:38696.2\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:15664.4#011validation-mae:38625.3\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:15568.3#011validation-mae:38590.3\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:15444.9#011validation-mae:38599.4\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:15363.9#011validation-mae:38553.4\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:15277.7#011validation-mae:38498.5\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:15197.3#011validation-mae:38456.1\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:15128.2#011validation-mae:38454.6\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:15049.3#011validation-mae:38459\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:14967.7#011validation-mae:38440.2\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:14876.9#011validation-mae:38412.1\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:14786.9#011validation-mae:38363\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:14695.3#011validation-mae:38314.3\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:14611.2#011validation-mae:38314.7\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:14507.7#011validation-mae:38296\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:14429.9#011validation-mae:38277.2\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:14353.9#011validation-mae:38176\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:14276#011validation-mae:38171.1\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:14209#011validation-mae:38146.5\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:14133.2#011validation-mae:38133.5\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:14061#011validation-mae:38131.7\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:14004.2#011validation-mae:38105.3\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:13936.6#011validation-mae:38060.3\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:13875.6#011validation-mae:38007.6\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:13798.6#011validation-mae:37970.2\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:13728.6#011validation-mae:37967.6\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:13642.6#011validation-mae:37948.6\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:13559.9#011validation-mae:37931.4\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:13466.2#011validation-mae:37917.4\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:13387.9#011validation-mae:37927.2\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:13321.4#011validation-mae:37943.1\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:13238#011validation-mae:37961.3\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:13140.3#011validation-mae:37908.3\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:13067.9#011validation-mae:37863.5\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:13008.7#011validation-mae:37876.5\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:12934.1#011validation-mae:37848.3\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:12880.9#011validation-mae:37804.7\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:12827.5#011validation-mae:37754.7\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:12736.6#011validation-mae:37718.6\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:12685.6#011validation-mae:37695.8\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:12603.4#011validation-mae:37671.8\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:12551.2#011validation-mae:37660.4\u001b[0m\n",
      "\u001b[31m[168]#011train-mae:12488.4#011validation-mae:37650.7\u001b[0m\n",
      "\u001b[31m[169]#011train-mae:12418.2#011validation-mae:37624\u001b[0m\n",
      "\u001b[31m[170]#011train-mae:12361.3#011validation-mae:37589.5\u001b[0m\n",
      "\u001b[31m[171]#011train-mae:12305.7#011validation-mae:37546.4\u001b[0m\n",
      "\u001b[31m[172]#011train-mae:12248.4#011validation-mae:37521.9\u001b[0m\n",
      "\u001b[31m[173]#011train-mae:12193.7#011validation-mae:37492\u001b[0m\n",
      "\u001b[31m[174]#011train-mae:12115.4#011validation-mae:37478.6\u001b[0m\n",
      "\u001b[31m[175]#011train-mae:12057.6#011validation-mae:37479.9\u001b[0m\n",
      "\u001b[31m[176]#011train-mae:12001.2#011validation-mae:37455.6\u001b[0m\n",
      "\u001b[31m[177]#011train-mae:11964.3#011validation-mae:37441.1\u001b[0m\n",
      "\u001b[31m[178]#011train-mae:11897.9#011validation-mae:37393.6\u001b[0m\n",
      "\u001b[31m[179]#011train-mae:11835.3#011validation-mae:37385.3\u001b[0m\n",
      "\u001b[31m[180]#011train-mae:11765#011validation-mae:37336.7\u001b[0m\n",
      "\u001b[31m[181]#011train-mae:11700.6#011validation-mae:37317.1\u001b[0m\n",
      "\u001b[31m[182]#011train-mae:11650.4#011validation-mae:37318.3\u001b[0m\n",
      "\u001b[31m[183]#011train-mae:11590#011validation-mae:37279.6\u001b[0m\n",
      "\u001b[31m[184]#011train-mae:11527#011validation-mae:37231.4\u001b[0m\n",
      "\u001b[31m[185]#011train-mae:11460#011validation-mae:37221.2\u001b[0m\n",
      "\u001b[31m[186]#011train-mae:11408.8#011validation-mae:37211.5\u001b[0m\n",
      "\u001b[31m[187]#011train-mae:11365.6#011validation-mae:37245.5\u001b[0m\n",
      "\u001b[31m[188]#011train-mae:11310.9#011validation-mae:37212.7\u001b[0m\n",
      "\u001b[31m[189]#011train-mae:11252#011validation-mae:37184.7\u001b[0m\n",
      "\u001b[31m[190]#011train-mae:11194.3#011validation-mae:37142.9\u001b[0m\n",
      "\u001b[31m[191]#011train-mae:11132.6#011validation-mae:37123.6\u001b[0m\n",
      "\u001b[31m[192]#011train-mae:11089.4#011validation-mae:37112.7\u001b[0m\n",
      "\u001b[31m[193]#011train-mae:11030.7#011validation-mae:37127.6\u001b[0m\n",
      "\u001b[31m[194]#011train-mae:10978.3#011validation-mae:37101.9\u001b[0m\n",
      "\u001b[31m[195]#011train-mae:10919.6#011validation-mae:37071\u001b[0m\n",
      "\u001b[31m[196]#011train-mae:10873.7#011validation-mae:37068.6\u001b[0m\n",
      "\u001b[31m[197]#011train-mae:10822.1#011validation-mae:37072.6\u001b[0m\n",
      "\u001b[31m[198]#011train-mae:10772.6#011validation-mae:37043.9\u001b[0m\n",
      "\u001b[31m[199]#011train-mae:10733.4#011validation-mae:37019\u001b[0m\n",
      "\u001b[31m[200]#011train-mae:10687.5#011validation-mae:37028\u001b[0m\n",
      "\u001b[31m[201]#011train-mae:10633.2#011validation-mae:37022\u001b[0m\n",
      "\u001b[31m[202]#011train-mae:10597.3#011validation-mae:37049.7\u001b[0m\n",
      "\u001b[31m[203]#011train-mae:10562.9#011validation-mae:37018.9\u001b[0m\n",
      "\u001b[31m[204]#011train-mae:10506.4#011validation-mae:37026.7\u001b[0m\n",
      "\u001b[31m[205]#011train-mae:10464.1#011validation-mae:36991.6\u001b[0m\n",
      "\u001b[31m[206]#011train-mae:10426.4#011validation-mae:36967.7\u001b[0m\n",
      "\u001b[31m[207]#011train-mae:10383.2#011validation-mae:36925.1\u001b[0m\n",
      "\u001b[31m[208]#011train-mae:10330.6#011validation-mae:36915.3\u001b[0m\n",
      "\u001b[31m[209]#011train-mae:10284.8#011validation-mae:36877.5\u001b[0m\n",
      "\u001b[31m[210]#011train-mae:10233.5#011validation-mae:36879.3\u001b[0m\n",
      "\u001b[31m[211]#011train-mae:10191.1#011validation-mae:36868.5\u001b[0m\n",
      "\u001b[31m[212]#011train-mae:10132.5#011validation-mae:36846.2\u001b[0m\n",
      "\u001b[31m[213]#011train-mae:10087.3#011validation-mae:36840.8\u001b[0m\n",
      "\u001b[31m[214]#011train-mae:10030.9#011validation-mae:36849\u001b[0m\n",
      "\u001b[31m[215]#011train-mae:9977.89#011validation-mae:36836.8\u001b[0m\n",
      "\u001b[31m[216]#011train-mae:9940.43#011validation-mae:36814.6\u001b[0m\n",
      "\u001b[31m[217]#011train-mae:9900.24#011validation-mae:36802\u001b[0m\n",
      "\u001b[31m[218]#011train-mae:9847.2#011validation-mae:36805\u001b[0m\n",
      "\u001b[31m[219]#011train-mae:9789.1#011validation-mae:36800\u001b[0m\n",
      "\u001b[31m[220]#011train-mae:9747.01#011validation-mae:36783.1\u001b[0m\n",
      "\u001b[31m[221]#011train-mae:9702.12#011validation-mae:36767.4\u001b[0m\n",
      "\u001b[31m[222]#011train-mae:9666.33#011validation-mae:36750.8\u001b[0m\n",
      "\u001b[31m[223]#011train-mae:9626.91#011validation-mae:36742.3\u001b[0m\n",
      "\u001b[31m[224]#011train-mae:9582.79#011validation-mae:36725\u001b[0m\n",
      "\u001b[31m[225]#011train-mae:9529.11#011validation-mae:36693.5\u001b[0m\n",
      "\u001b[31m[226]#011train-mae:9488.15#011validation-mae:36678.9\u001b[0m\n",
      "\u001b[31m[227]#011train-mae:9437.81#011validation-mae:36696.4\u001b[0m\n",
      "\u001b[31m[228]#011train-mae:9408.42#011validation-mae:36674.5\u001b[0m\n",
      "\u001b[31m[229]#011train-mae:9369.58#011validation-mae:36662.8\u001b[0m\n",
      "\u001b[31m[230]#011train-mae:9328.41#011validation-mae:36652.4\u001b[0m\n",
      "\u001b[31m[231]#011train-mae:9293.74#011validation-mae:36621.4\u001b[0m\n",
      "\u001b[31m[232]#011train-mae:9250.22#011validation-mae:36581.2\u001b[0m\n",
      "\u001b[31m[233]#011train-mae:9218#011validation-mae:36576.9\u001b[0m\n",
      "\u001b[31m[234]#011train-mae:9173.76#011validation-mae:36539.6\u001b[0m\n",
      "\u001b[31m[235]#011train-mae:9129.44#011validation-mae:36536.8\u001b[0m\n",
      "\u001b[31m[236]#011train-mae:9089.92#011validation-mae:36509.8\u001b[0m\n",
      "\u001b[31m[237]#011train-mae:9043.14#011validation-mae:36500.4\u001b[0m\n",
      "\u001b[31m[238]#011train-mae:8998.4#011validation-mae:36478.9\u001b[0m\n",
      "\u001b[31m[239]#011train-mae:8959.22#011validation-mae:36481.1\u001b[0m\n",
      "\u001b[31m[240]#011train-mae:8924.76#011validation-mae:36462.7\u001b[0m\n",
      "\u001b[31m[241]#011train-mae:8891.66#011validation-mae:36441.2\u001b[0m\n",
      "\u001b[31m[242]#011train-mae:8848.79#011validation-mae:36446\u001b[0m\n",
      "\u001b[31m[243]#011train-mae:8812#011validation-mae:36415.3\u001b[0m\n",
      "\u001b[31m[244]#011train-mae:8770.26#011validation-mae:36391.5\u001b[0m\n",
      "\u001b[31m[245]#011train-mae:8727.21#011validation-mae:36403.2\u001b[0m\n",
      "\u001b[31m[246]#011train-mae:8682.07#011validation-mae:36371.4\u001b[0m\n",
      "\u001b[31m[247]#011train-mae:8641.52#011validation-mae:36352.9\u001b[0m\n",
      "\u001b[31m[248]#011train-mae:8581.72#011validation-mae:36333.5\u001b[0m\n",
      "\u001b[31m[249]#011train-mae:8553.06#011validation-mae:36321.8\u001b[0m\n",
      "\u001b[31m[250]#011train-mae:8512#011validation-mae:36315.1\u001b[0m\n",
      "\u001b[31m[251]#011train-mae:8464.52#011validation-mae:36296.7\u001b[0m\n",
      "\u001b[31m[252]#011train-mae:8423.46#011validation-mae:36286.5\u001b[0m\n",
      "\u001b[31m[253]#011train-mae:8390.58#011validation-mae:36259.1\u001b[0m\n",
      "\u001b[31m[254]#011train-mae:8340.17#011validation-mae:36241.4\u001b[0m\n",
      "\u001b[31m[255]#011train-mae:8297.1#011validation-mae:36236.4\u001b[0m\n",
      "\u001b[31m[256]#011train-mae:8259.7#011validation-mae:36226.5\u001b[0m\n",
      "\u001b[31m[257]#011train-mae:8228.17#011validation-mae:36213\u001b[0m\n",
      "\u001b[31m[258]#011train-mae:8176.35#011validation-mae:36224.3\u001b[0m\n",
      "\u001b[31m[259]#011train-mae:8144.68#011validation-mae:36225.3\u001b[0m\n",
      "\u001b[31m[260]#011train-mae:8111.1#011validation-mae:36227\u001b[0m\n",
      "\u001b[31m[261]#011train-mae:8066.09#011validation-mae:36216.3\u001b[0m\n",
      "\u001b[31m[262]#011train-mae:8029.79#011validation-mae:36223.5\u001b[0m\n",
      "\u001b[31m[263]#011train-mae:8001.36#011validation-mae:36190.5\u001b[0m\n",
      "\u001b[31m[264]#011train-mae:7960.54#011validation-mae:36163.4\u001b[0m\n",
      "\u001b[31m[265]#011train-mae:7923.67#011validation-mae:36150.9\u001b[0m\n",
      "\u001b[31m[266]#011train-mae:7893.92#011validation-mae:36154.6\u001b[0m\n",
      "\u001b[31m[267]#011train-mae:7855.75#011validation-mae:36129.3\u001b[0m\n",
      "\u001b[31m[268]#011train-mae:7823.03#011validation-mae:36106.5\u001b[0m\n",
      "\u001b[31m[269]#011train-mae:7801.58#011validation-mae:36082\u001b[0m\n",
      "\u001b[31m[270]#011train-mae:7760.81#011validation-mae:36069.4\u001b[0m\n",
      "\u001b[31m[271]#011train-mae:7723.83#011validation-mae:36080.2\u001b[0m\n",
      "\u001b[31m[272]#011train-mae:7694.47#011validation-mae:36082.3\u001b[0m\n",
      "\u001b[31m[273]#011train-mae:7663.13#011validation-mae:36066.3\u001b[0m\n",
      "\u001b[31m[274]#011train-mae:7628.5#011validation-mae:36056.1\u001b[0m\n",
      "\u001b[31m[275]#011train-mae:7595.48#011validation-mae:36035.9\u001b[0m\n",
      "\u001b[31m[276]#011train-mae:7562.27#011validation-mae:36019.2\u001b[0m\n",
      "\u001b[31m[277]#011train-mae:7521.29#011validation-mae:36033.8\u001b[0m\n",
      "\u001b[31m[278]#011train-mae:7483.93#011validation-mae:36018.5\u001b[0m\n",
      "\u001b[31m[279]#011train-mae:7454.41#011validation-mae:36029.1\u001b[0m\n",
      "\u001b[31m[280]#011train-mae:7427.42#011validation-mae:36041.8\u001b[0m\n",
      "\u001b[31m[281]#011train-mae:7392.76#011validation-mae:36041.5\u001b[0m\n",
      "\u001b[31m[282]#011train-mae:7360.59#011validation-mae:36051.3\u001b[0m\n",
      "\u001b[31m[283]#011train-mae:7328.74#011validation-mae:36040.9\u001b[0m\n",
      "\u001b[31m[284]#011train-mae:7301.66#011validation-mae:36029.7\u001b[0m\n",
      "\u001b[31m[285]#011train-mae:7276.37#011validation-mae:36010.5\u001b[0m\n",
      "\u001b[31m[286]#011train-mae:7242.05#011validation-mae:36016.5\u001b[0m\n",
      "\u001b[31m[287]#011train-mae:7210.92#011validation-mae:36025.9\u001b[0m\n",
      "\u001b[31m[288]#011train-mae:7174.68#011validation-mae:36006.6\u001b[0m\n",
      "\u001b[31m[289]#011train-mae:7140.3#011validation-mae:36010.8\u001b[0m\n",
      "\u001b[31m[290]#011train-mae:7108.37#011validation-mae:36007.7\u001b[0m\n",
      "\u001b[31m[291]#011train-mae:7089.69#011validation-mae:35990.8\u001b[0m\n",
      "\u001b[31m[292]#011train-mae:7066.57#011validation-mae:35977.9\u001b[0m\n",
      "\u001b[31m[293]#011train-mae:7030.79#011validation-mae:35962.3\u001b[0m\n",
      "\u001b[31m[294]#011train-mae:6993.28#011validation-mae:35945.4\u001b[0m\n",
      "\u001b[31m[295]#011train-mae:6967.57#011validation-mae:35922.1\u001b[0m\n",
      "\u001b[31m[296]#011train-mae:6936.09#011validation-mae:35915.7\u001b[0m\n",
      "\u001b[31m[297]#011train-mae:6899.21#011validation-mae:35898\u001b[0m\n",
      "\u001b[31m[298]#011train-mae:6876.23#011validation-mae:35887.1\u001b[0m\n",
      "\u001b[31m[299]#011train-mae:6851.96#011validation-mae:35889\u001b[0m\n",
      "\u001b[31m[300]#011train-mae:6819.99#011validation-mae:35868.5\u001b[0m\n",
      "\u001b[31m[301]#011train-mae:6783.62#011validation-mae:35843.3\u001b[0m\n",
      "\u001b[31m[302]#011train-mae:6764.85#011validation-mae:35838.4\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:6740.38#011validation-mae:35836.8\u001b[0m\n",
      "\u001b[31m[304]#011train-mae:6716.54#011validation-mae:35839.8\u001b[0m\n",
      "\u001b[31m[305]#011train-mae:6690.38#011validation-mae:35839.9\u001b[0m\n",
      "\u001b[31m[306]#011train-mae:6657.36#011validation-mae:35819.5\u001b[0m\n",
      "\u001b[31m[307]#011train-mae:6628.73#011validation-mae:35813.2\u001b[0m\n",
      "\u001b[31m[308]#011train-mae:6595.43#011validation-mae:35824\u001b[0m\n",
      "\u001b[31m[309]#011train-mae:6568.61#011validation-mae:35789.7\u001b[0m\n",
      "\u001b[31m[310]#011train-mae:6542.53#011validation-mae:35803.9\u001b[0m\n",
      "\u001b[31m[311]#011train-mae:6522.25#011validation-mae:35804.1\u001b[0m\n",
      "\u001b[31m[312]#011train-mae:6493.06#011validation-mae:35788.8\u001b[0m\n",
      "\u001b[31m[313]#011train-mae:6465.44#011validation-mae:35784.2\u001b[0m\n",
      "\u001b[31m[314]#011train-mae:6438.13#011validation-mae:35805.3\u001b[0m\n",
      "\u001b[31m[315]#011train-mae:6412.83#011validation-mae:35822.6\u001b[0m\n",
      "\u001b[31m[316]#011train-mae:6391.31#011validation-mae:35812.1\u001b[0m\n",
      "\u001b[31m[317]#011train-mae:6361.8#011validation-mae:35806.7\u001b[0m\n",
      "\u001b[31m[318]#011train-mae:6336.29#011validation-mae:35783.8\u001b[0m\n",
      "\u001b[31m[319]#011train-mae:6309.72#011validation-mae:35783.4\u001b[0m\n",
      "\u001b[31m[320]#011train-mae:6290.31#011validation-mae:35773.7\u001b[0m\n",
      "\u001b[31m[321]#011train-mae:6264.13#011validation-mae:35778.4\u001b[0m\n",
      "\u001b[31m[322]#011train-mae:6229.08#011validation-mae:35772.2\u001b[0m\n",
      "\u001b[31m[323]#011train-mae:6206.74#011validation-mae:35782.4\u001b[0m\n",
      "\u001b[31m[324]#011train-mae:6176.68#011validation-mae:35760.8\u001b[0m\n",
      "\u001b[31m[325]#011train-mae:6151.55#011validation-mae:35742.2\u001b[0m\n",
      "\u001b[31m[326]#011train-mae:6123.76#011validation-mae:35743.2\u001b[0m\n",
      "\u001b[31m[327]#011train-mae:6100.61#011validation-mae:35735.4\u001b[0m\n",
      "\u001b[31m[328]#011train-mae:6073.2#011validation-mae:35739.8\u001b[0m\n",
      "\u001b[31m[329]#011train-mae:6043.79#011validation-mae:35728.6\u001b[0m\n",
      "\u001b[31m[330]#011train-mae:6024.47#011validation-mae:35716.8\u001b[0m\n",
      "\u001b[31m[331]#011train-mae:6000.63#011validation-mae:35706.2\u001b[0m\n",
      "\u001b[31m[332]#011train-mae:5977.42#011validation-mae:35694.1\u001b[0m\n",
      "\u001b[31m[333]#011train-mae:5948.87#011validation-mae:35699.5\u001b[0m\n",
      "\u001b[31m[334]#011train-mae:5920.03#011validation-mae:35693.8\u001b[0m\n",
      "\u001b[31m[335]#011train-mae:5880.55#011validation-mae:35698.1\u001b[0m\n",
      "\u001b[31m[336]#011train-mae:5850.15#011validation-mae:35700.2\u001b[0m\n",
      "\u001b[31m[337]#011train-mae:5824.71#011validation-mae:35695.1\u001b[0m\n",
      "\u001b[31m[338]#011train-mae:5800.17#011validation-mae:35722.3\u001b[0m\n",
      "\u001b[31m[339]#011train-mae:5780.81#011validation-mae:35720.6\u001b[0m\n",
      "\u001b[31m[340]#011train-mae:5746.88#011validation-mae:35705.7\u001b[0m\n",
      "\u001b[31m[341]#011train-mae:5716.85#011validation-mae:35701.7\u001b[0m\n",
      "\u001b[31m[342]#011train-mae:5689.39#011validation-mae:35676.5\u001b[0m\n",
      "\u001b[31m[343]#011train-mae:5668.5#011validation-mae:35672.4\u001b[0m\n",
      "\u001b[31m[344]#011train-mae:5639.83#011validation-mae:35674.1\u001b[0m\n",
      "\u001b[31m[345]#011train-mae:5616.74#011validation-mae:35670.9\u001b[0m\n",
      "\u001b[31m[346]#011train-mae:5589.51#011validation-mae:35659.2\u001b[0m\n",
      "\u001b[31m[347]#011train-mae:5566.21#011validation-mae:35645.3\u001b[0m\n",
      "\u001b[31m[348]#011train-mae:5547.25#011validation-mae:35640.3\u001b[0m\n",
      "\u001b[31m[349]#011train-mae:5529.34#011validation-mae:35642.9\u001b[0m\n",
      "\u001b[31m[350]#011train-mae:5509.86#011validation-mae:35627.7\u001b[0m\n",
      "\u001b[31m[351]#011train-mae:5480.37#011validation-mae:35604.7\u001b[0m\n",
      "\u001b[31m[352]#011train-mae:5466.53#011validation-mae:35592.2\u001b[0m\n",
      "\u001b[31m[353]#011train-mae:5450.28#011validation-mae:35577.4\u001b[0m\n",
      "\u001b[31m[354]#011train-mae:5432.12#011validation-mae:35574.8\u001b[0m\n",
      "\u001b[31m[355]#011train-mae:5407.24#011validation-mae:35569\u001b[0m\n",
      "\u001b[31m[356]#011train-mae:5378.7#011validation-mae:35571.6\u001b[0m\n",
      "\u001b[31m[357]#011train-mae:5361.4#011validation-mae:35553.3\u001b[0m\n",
      "\u001b[31m[358]#011train-mae:5341.16#011validation-mae:35524.2\u001b[0m\n",
      "\u001b[31m[359]#011train-mae:5322.15#011validation-mae:35521.1\u001b[0m\n",
      "\u001b[31m[360]#011train-mae:5305.24#011validation-mae:35536.5\u001b[0m\n",
      "\u001b[31m[361]#011train-mae:5282.89#011validation-mae:35528.9\u001b[0m\n",
      "\u001b[31m[362]#011train-mae:5260.33#011validation-mae:35522.4\u001b[0m\n",
      "\u001b[31m[363]#011train-mae:5231.68#011validation-mae:35535.9\u001b[0m\n",
      "\u001b[31m[364]#011train-mae:5207.18#011validation-mae:35522.6\u001b[0m\n",
      "\u001b[31m[365]#011train-mae:5178.28#011validation-mae:35507.7\u001b[0m\n",
      "\u001b[31m[366]#011train-mae:5163.57#011validation-mae:35503.3\u001b[0m\n",
      "\u001b[31m[367]#011train-mae:5144.46#011validation-mae:35495.6\u001b[0m\n",
      "\u001b[31m[368]#011train-mae:5126.72#011validation-mae:35491.8\u001b[0m\n",
      "\u001b[31m[369]#011train-mae:5101.29#011validation-mae:35476.3\u001b[0m\n",
      "\u001b[31m[370]#011train-mae:5085.3#011validation-mae:35471\u001b[0m\n",
      "\u001b[31m[371]#011train-mae:5058.28#011validation-mae:35469\u001b[0m\n",
      "\u001b[31m[372]#011train-mae:5040.43#011validation-mae:35450.1\u001b[0m\n",
      "\u001b[31m[373]#011train-mae:5021.49#011validation-mae:35452.9\u001b[0m\n",
      "\u001b[31m[374]#011train-mae:4999.52#011validation-mae:35444.2\u001b[0m\n",
      "\u001b[31m[375]#011train-mae:4978.86#011validation-mae:35439.4\u001b[0m\n",
      "\u001b[31m[376]#011train-mae:4959.45#011validation-mae:35424.3\u001b[0m\n",
      "\u001b[31m[377]#011train-mae:4941.92#011validation-mae:35417.3\u001b[0m\n",
      "\u001b[31m[378]#011train-mae:4918.29#011validation-mae:35412.5\u001b[0m\n",
      "\u001b[31m[379]#011train-mae:4892.14#011validation-mae:35420.7\u001b[0m\n",
      "\u001b[31m[380]#011train-mae:4877.33#011validation-mae:35402.6\u001b[0m\n",
      "\u001b[31m[381]#011train-mae:4854.02#011validation-mae:35395.2\u001b[0m\n",
      "\u001b[31m[382]#011train-mae:4836.77#011validation-mae:35382.1\u001b[0m\n",
      "\u001b[31m[383]#011train-mae:4816.78#011validation-mae:35372.6\u001b[0m\n",
      "\u001b[31m[384]#011train-mae:4798.13#011validation-mae:35374\u001b[0m\n",
      "\u001b[31m[385]#011train-mae:4779.28#011validation-mae:35378.9\u001b[0m\n",
      "\u001b[31m[386]#011train-mae:4771.66#011validation-mae:35373.9\u001b[0m\n",
      "\u001b[31m[387]#011train-mae:4748.87#011validation-mae:35370.5\u001b[0m\n",
      "\u001b[31m[388]#011train-mae:4726.94#011validation-mae:35356.4\u001b[0m\n",
      "\u001b[31m[389]#011train-mae:4707.99#011validation-mae:35342.9\u001b[0m\n",
      "\u001b[31m[390]#011train-mae:4691.84#011validation-mae:35334.5\u001b[0m\n",
      "\u001b[31m[391]#011train-mae:4662.7#011validation-mae:35327.9\u001b[0m\n",
      "\u001b[31m[392]#011train-mae:4647.97#011validation-mae:35329.6\u001b[0m\n",
      "\u001b[31m[393]#011train-mae:4629.28#011validation-mae:35307.6\u001b[0m\n",
      "\u001b[31m[394]#011train-mae:4613.37#011validation-mae:35299\u001b[0m\n",
      "\u001b[31m[395]#011train-mae:4594.04#011validation-mae:35299.2\u001b[0m\n",
      "\u001b[31m[396]#011train-mae:4576.13#011validation-mae:35301.8\u001b[0m\n",
      "\u001b[31m[397]#011train-mae:4558.82#011validation-mae:35293.1\u001b[0m\n",
      "\u001b[31m[398]#011train-mae:4542.34#011validation-mae:35292.2\u001b[0m\n",
      "\u001b[31m[399]#011train-mae:4520.62#011validation-mae:35285.6\u001b[0m\n",
      "\u001b[31m[400]#011train-mae:4503.15#011validation-mae:35284.1\u001b[0m\n",
      "\u001b[31m[401]#011train-mae:4484.49#011validation-mae:35272.4\u001b[0m\n",
      "\u001b[31m[402]#011train-mae:4463.67#011validation-mae:35265\u001b[0m\n",
      "\u001b[31m[403]#011train-mae:4446.02#011validation-mae:35258.1\u001b[0m\n",
      "\u001b[31m[404]#011train-mae:4430.97#011validation-mae:35259.6\u001b[0m\n",
      "\u001b[31m[405]#011train-mae:4416.32#011validation-mae:35251.4\u001b[0m\n",
      "\u001b[31m[406]#011train-mae:4401.21#011validation-mae:35249.9\u001b[0m\n",
      "\u001b[31m[407]#011train-mae:4385.82#011validation-mae:35255.7\u001b[0m\n",
      "\u001b[31m[408]#011train-mae:4375.14#011validation-mae:35253.5\u001b[0m\n",
      "\u001b[31m[409]#011train-mae:4364.09#011validation-mae:35245.5\u001b[0m\n",
      "\u001b[31m[410]#011train-mae:4351.73#011validation-mae:35241.5\u001b[0m\n",
      "\u001b[31m[411]#011train-mae:4334.34#011validation-mae:35226.5\u001b[0m\n",
      "\u001b[31m[412]#011train-mae:4313.3#011validation-mae:35219.1\u001b[0m\n",
      "\u001b[31m[413]#011train-mae:4296.64#011validation-mae:35215.1\u001b[0m\n",
      "\u001b[31m[414]#011train-mae:4280.61#011validation-mae:35212\u001b[0m\n",
      "\u001b[31m[415]#011train-mae:4259.89#011validation-mae:35210.7\u001b[0m\n",
      "\u001b[31m[416]#011train-mae:4253.16#011validation-mae:35205.2\u001b[0m\n",
      "\u001b[31m[417]#011train-mae:4237.75#011validation-mae:35202.6\u001b[0m\n",
      "\u001b[31m[418]#011train-mae:4225.49#011validation-mae:35202.4\u001b[0m\n",
      "\u001b[31m[419]#011train-mae:4210.02#011validation-mae:35183\u001b[0m\n",
      "\u001b[31m[420]#011train-mae:4194.54#011validation-mae:35162.7\u001b[0m\n",
      "Training seconds: 45\n",
      "Billable seconds: 45\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response for our best training round:\n",
    "{'_tuning_objective_metric': 'validation:mae', 'max_depth': 11, 'subsample': 0.8, 'num_round': 421, 'gamma': 4.0, 'eval_metric': ['mae'], 'early_stopping_rounds': 10, 'rate_drop': 0.3, 'lambda': 474.24314972169725, 'objective': 'reg:linear', 'eta': 0.373620175273373, 'min_child_weight': 10.0}\n",
    "\n",
    "This shows us that the best Mean Absolute Error (MAE) we were able to achieve during training was 35162, which converted to Mean Absolute Percentage Error (MAPE) can be found by dividing this MAE value by the mean sale price of this validation sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506853.7960199005"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06937444343145338\n"
     ]
    }
   ],
   "source": [
    "top_mae = 35162.7\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's under 7% but let's try changing the drop rate to see if we can achieve an even lower MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# rate_drop has been updated to 0.5 from 0.3\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        rate_drop=0.5,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same tuning parameters are being used,\n",
    "# but we are re-assigning the xgb reference to 'estimator' now that it has been updated:\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 20, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'eta'      : ContinuousParameter(0.0, 0.5),\n",
    "                                                  'lambda'   : ContinuousParameter(0, 1000),\n",
    "                                                  'max_depth': IntegerParameter(5, 17),\n",
    "                                                  'num_round': IntegerParameter(100, 500),\n",
    "                                                  'min_child_weight': IntegerParameter(1, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 21:43:58 Starting - Preparing the instances for training\n",
      "2019-09-06 21:43:58 Downloading - Downloading input data\n",
      "2019-09-06 21:43:58 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 21:43:58 Uploading - Uploading generated training model\n",
      "2019-09-06 21:43:58 Completed - Training job completed\u001b[31m2019-09-06 21:43:47,197 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,198 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,198 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,202 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,214 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,218 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,218 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,218 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,219 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,219 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[21:43:47] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,239 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[21:43:47] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,252 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,252 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,252 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,252 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 21:43:47,252 root         INFO     {'subsample': 0.8, 'early_stopping_rounds': 10, 'eval_metric': ['mae'], 'eta': 0.4539415243497953, 'gamma': 4.0, 'max_depth': 14, '_tuning_objective_metric': 'validation:mae', 'objective': 'reg:linear', 'min_child_weight': 10.0, 'lambda': 115.80246104977371, 'rate_drop': 0.5, 'num_round': 363}\u001b[0m\n",
      "\u001b[31m[21:43:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:336027#011validation-mae:327140\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:221830#011validation-mae:217489\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:156729#011validation-mae:154276\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:113551#011validation-mae:112400\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:86239.5#011validation-mae:88842\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:68939.5#011validation-mae:73071.3\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:59115.9#011validation-mae:66186.2\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:51963.4#011validation-mae:61638.8\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:47014#011validation-mae:57317.7\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:43178.9#011validation-mae:54326.4\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:40781.7#011validation-mae:52682.9\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:38707.6#011validation-mae:50310.2\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:36211.3#011validation-mae:48626.5\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:34219.6#011validation-mae:47058.9\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:32345.8#011validation-mae:45732.6\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:30921.2#011validation-mae:44899.7\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:29865.1#011validation-mae:44409\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:28604.8#011validation-mae:43705\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:27707#011validation-mae:42665.8\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:26519.6#011validation-mae:41843.7\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:25745.6#011validation-mae:41573.6\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:24631.9#011validation-mae:41156.7\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:23870.6#011validation-mae:40820.7\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:23163.4#011validation-mae:40445.8\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:22533.3#011validation-mae:39947.7\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:21892#011validation-mae:39363.9\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:21163.8#011validation-mae:38841.5\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:20688.2#011validation-mae:38707.4\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:20205.4#011validation-mae:38510.4\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:19661.2#011validation-mae:38380\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:19096#011validation-mae:38019.5\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:18724.4#011validation-mae:37818.4\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:18305.9#011validation-mae:37678.4\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:17862.3#011validation-mae:37676.3\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:17537.7#011validation-mae:37596.9\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:17161.7#011validation-mae:37379.8\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:16830.1#011validation-mae:37200.5\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:16524.8#011validation-mae:37061.1\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:16236.8#011validation-mae:36914.2\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:15899.8#011validation-mae:36859.9\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:15612.5#011validation-mae:36956.7\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:15300.5#011validation-mae:36728.4\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:15021.1#011validation-mae:36607.4\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:14676.1#011validation-mae:36575.3\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:14423.8#011validation-mae:36531.2\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:14119.5#011validation-mae:36452.1\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:13803.5#011validation-mae:36344.8\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:13511.9#011validation-mae:36233.5\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:13233.1#011validation-mae:36128.9\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:12979#011validation-mae:36135.6\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:12703.4#011validation-mae:36044.7\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:12481.5#011validation-mae:35818.2\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:12206.9#011validation-mae:35694.5\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:11894.6#011validation-mae:35611.3\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:11714.8#011validation-mae:35542.2\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:11528.9#011validation-mae:35447.5\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:11310.8#011validation-mae:35389.6\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:11150.1#011validation-mae:35337\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:10953.3#011validation-mae:35344.7\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:10751.9#011validation-mae:35273.9\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:10586.5#011validation-mae:35328.7\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:10457.4#011validation-mae:35338.7\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:10248.4#011validation-mae:35216.4\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:10122.6#011validation-mae:35193.2\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:9915.69#011validation-mae:35157.1\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:9799.78#011validation-mae:35102.8\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:9657.86#011validation-mae:35056.5\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:9460.14#011validation-mae:34956\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:9281.24#011validation-mae:34915\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:9134.7#011validation-mae:34836.8\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:8979.82#011validation-mae:34805.2\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:8853.6#011validation-mae:34757.9\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:8705.79#011validation-mae:34680.8\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:8583.17#011validation-mae:34669.9\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:8456.84#011validation-mae:34667.6\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:8334.38#011validation-mae:34623.8\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:8237.67#011validation-mae:34627.6\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:8090.58#011validation-mae:34628.5\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:7976.85#011validation-mae:34663.2\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:7825.54#011validation-mae:34676.7\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:7708.29#011validation-mae:34637.4\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:7590.29#011validation-mae:34608.1\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:7512.83#011validation-mae:34618\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:7352.06#011validation-mae:34598\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:7250.6#011validation-mae:34554.6\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:7150.95#011validation-mae:34512.1\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:7050.13#011validation-mae:34476.5\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:6947.35#011validation-mae:34458.1\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:6818.96#011validation-mae:34410.2\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:6721.34#011validation-mae:34421.2\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:6588.94#011validation-mae:34390.4\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:6468.05#011validation-mae:34402.2\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:6374.62#011validation-mae:34368.4\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:6301.25#011validation-mae:34365\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:6201.02#011validation-mae:34367.4\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:6089.7#011validation-mae:34375.9\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:5993.92#011validation-mae:34355.5\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:5912.98#011validation-mae:34362.7\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:5856.53#011validation-mae:34334.7\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:5758.07#011validation-mae:34311.7\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:5668.96#011validation-mae:34326.9\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:5589.65#011validation-mae:34322.6\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:5506.61#011validation-mae:34322.9\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:5425.35#011validation-mae:34294.5\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:5373.18#011validation-mae:34259.6\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:5301.83#011validation-mae:34258.7\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:5212.06#011validation-mae:34273.1\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:5126.94#011validation-mae:34280.1\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:5049.1#011validation-mae:34284.9\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:4980.22#011validation-mae:34295.3\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:4917.34#011validation-mae:34318.4\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:4861.06#011validation-mae:34270.6\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:4784.03#011validation-mae:34225.1\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:4712.24#011validation-mae:34184.2\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:4623.19#011validation-mae:34192.3\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:4563.2#011validation-mae:34195.2\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:4501.79#011validation-mae:34213.3\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:4431.36#011validation-mae:34190.5\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:4357.25#011validation-mae:34169.9\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:4303.26#011validation-mae:34130.7\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:4249.06#011validation-mae:34099.4\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:4176.11#011validation-mae:34088.3\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:4133.89#011validation-mae:34066.9\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:4076.24#011validation-mae:34013.8\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:4029.77#011validation-mae:34034.9\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:3974.37#011validation-mae:33997.3\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:3924.35#011validation-mae:33966.4\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:3860.07#011validation-mae:33970.4\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:3819.14#011validation-mae:33977.6\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:3755.21#011validation-mae:33962.7\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:3710.3#011validation-mae:33959.7\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:3647.78#011validation-mae:33940.5\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:3601.86#011validation-mae:33934.6\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:3566.33#011validation-mae:33925.3\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:3513.84#011validation-mae:33886\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:3467.49#011validation-mae:33898.9\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:3411.15#011validation-mae:33869.3\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:3367.5#011validation-mae:33882.5\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:3339.36#011validation-mae:33857.2\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:3289.88#011validation-mae:33832.9\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:3244.56#011validation-mae:33845.7\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:3191.61#011validation-mae:33846.6\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:3140.97#011validation-mae:33816\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:3098.15#011validation-mae:33790.9\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:3053.73#011validation-mae:33762.3\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:3020.93#011validation-mae:33752.7\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:2970.44#011validation-mae:33764.6\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:2940.02#011validation-mae:33737.8\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:2902.73#011validation-mae:33736.4\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:2859.3#011validation-mae:33761\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:2826.22#011validation-mae:33749\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:2794.42#011validation-mae:33736.8\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:2758.45#011validation-mae:33732.5\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:2713.41#011validation-mae:33719.2\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:2682.91#011validation-mae:33689.1\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:2639.56#011validation-mae:33692.5\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:2611.82#011validation-mae:33688.9\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:2583.25#011validation-mae:33669.5\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:2554.62#011validation-mae:33683\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:2514.29#011validation-mae:33689\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:2480.13#011validation-mae:33682.4\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:2449.63#011validation-mae:33680.4\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:2420.13#011validation-mae:33673.8\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:2393.76#011validation-mae:33700.9\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:2354.76#011validation-mae:33711.9\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:2320#011validation-mae:33716.9\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:2291.25#011validation-mae:33735.3\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:2260.56#011validation-mae:33715.1\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:2583.25#011validation-mae:33669.5\n",
      "\u001b[0m\n",
      "Training seconds: 45\n",
      "Billable seconds: 45\n"
     ]
    }
   ],
   "source": [
    "xgb_attached2 = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06642842623334727\n"
     ]
    }
   ],
   "source": [
    "top_mae = 33669.5\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This drop out rate performed a bit better overall, let's see what values were selected for the other parameters as this job's \"best\" round of training:\n",
    "{'subsample': 0.8, 'early_stopping_rounds': 10, 'eval_metric': ['mae'], 'eta': 0.4539415243497953, 'gamma': 4.0, 'max_depth': 14, '_tuning_objective_metric': 'validation:mae', 'objective': 'reg:linear', 'min_child_weight': 10.0, 'lambda': 115.80246104977371, 'rate_drop': 0.5, 'num_round': 363}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# rate_drop has been updated to 0.2 from 0.5\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        rate_drop=0.2,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same tuning parameters are being used,\n",
    "# but we are re-assigning the xgb reference to 'estimator' now that it has been updated:\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 20, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'eta'      : ContinuousParameter(0.0, 0.5),\n",
    "                                                  'lambda'   : ContinuousParameter(0, 1000),\n",
    "                                                  'max_depth': IntegerParameter(5, 17),\n",
    "                                                  'num_round': IntegerParameter(100, 500),\n",
    "                                                  'min_child_weight': IntegerParameter(1, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 22:06:45 Starting - Preparing the instances for training\n",
      "2019-09-06 22:06:45 Downloading - Downloading input data\n",
      "2019-09-06 22:06:45 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 22:06:45 Uploading - Uploading generated training model\n",
      "2019-09-06 22:06:45 Completed - Training job completed\u001b[31m2019-09-06 22:06:34,840 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,841 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,841 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,844 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,856 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,859 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,859 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,860 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,860 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,861 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:06:34] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,880 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:06:34] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,893 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,893 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,893 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,893 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:06:34,893 root         INFO     {'eval_metric': ['mae'], 'num_round': 437, '_tuning_objective_metric': 'validation:mae', 'early_stopping_rounds': 10, 'subsample': 0.8, 'eta': 0.43166340798965475, 'lambda': 682.9055918627323, 'gamma': 4.0, 'max_depth': 5, 'rate_drop': 0.2, 'objective': 'reg:linear', 'min_child_weight': 8.0}\u001b[0m\n",
      "\u001b[31m[22:06:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:436590#011validation-mae:426998\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:369496#011validation-mae:360024\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:313585#011validation-mae:305366\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:266263#011validation-mae:259566\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:226513#011validation-mae:221913\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:194923#011validation-mae:191739\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:171171#011validation-mae:168523\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:151052#011validation-mae:149612\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:134471#011validation-mae:133323\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:120541#011validation-mae:119559\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:108665#011validation-mae:108133\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:99365.5#011validation-mae:98975.2\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:91233#011validation-mae:91981.5\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:83859.8#011validation-mae:85511.1\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:77668.3#011validation-mae:80151.7\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:72763.3#011validation-mae:76129.3\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:68360.1#011validation-mae:72688.1\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:64692.5#011validation-mae:70150.5\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:61550.2#011validation-mae:68224.6\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:58660.6#011validation-mae:66139.4\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:56693.2#011validation-mae:65314.2\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:54555#011validation-mae:63658.5\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:52969.4#011validation-mae:62367.1\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:51219#011validation-mae:61183.7\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:49916.3#011validation-mae:60410.3\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:48794.8#011validation-mae:59459\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:47783.4#011validation-mae:58547.3\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:46667.3#011validation-mae:57742.6\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:45717.1#011validation-mae:56930.8\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:44939.3#011validation-mae:56220\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:44073.4#011validation-mae:55669.1\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:43314.5#011validation-mae:55046\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:42544.6#011validation-mae:54484\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:41851.8#011validation-mae:54010.8\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:41175.7#011validation-mae:53591.4\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:40325#011validation-mae:53007.6\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:39494.3#011validation-mae:52195.5\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:38942.8#011validation-mae:51896.8\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:38374.7#011validation-mae:51374.4\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:37751.2#011validation-mae:50769.3\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:37075.4#011validation-mae:50243.3\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:36614.6#011validation-mae:49912.7\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:36155.4#011validation-mae:49496\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:35707.3#011validation-mae:49213.4\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:35292.9#011validation-mae:48956.4\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:34783.9#011validation-mae:48595.3\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:34379.7#011validation-mae:48199.4\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:34019.7#011validation-mae:48026\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:33568.9#011validation-mae:47674.4\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:33173.6#011validation-mae:47374.6\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:32710#011validation-mae:46967\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:32336.2#011validation-mae:46637.8\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:32014.8#011validation-mae:46397.5\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:31652.6#011validation-mae:46129.5\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:31276.6#011validation-mae:45851.1\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:30987.7#011validation-mae:45662.8\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:30671#011validation-mae:45390.1\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:30375.5#011validation-mae:45278.2\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:30073.5#011validation-mae:45179.9\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:29788.2#011validation-mae:45069.7\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:29444.3#011validation-mae:44845.6\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:29208.3#011validation-mae:44794.5\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:28910.3#011validation-mae:44615.7\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:28634.8#011validation-mae:44385.3\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:28391.1#011validation-mae:44281.5\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:28095.3#011validation-mae:44020.4\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:27858.8#011validation-mae:43923.3\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:27635.6#011validation-mae:43809.1\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:27352#011validation-mae:43656.6\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:27131.3#011validation-mae:43517\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:26847.5#011validation-mae:43356\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:26572.6#011validation-mae:43188.3\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:26370.8#011validation-mae:42969.1\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:26144#011validation-mae:42843.9\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:25922.7#011validation-mae:42646.1\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:25688.8#011validation-mae:42560.1\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:25477.1#011validation-mae:42377.9\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:25272.1#011validation-mae:42329.4\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:25064.9#011validation-mae:42161.7\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:24810.8#011validation-mae:42016.3\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:24612.9#011validation-mae:41886.8\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:24445.4#011validation-mae:41779.8\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:24277.2#011validation-mae:41644.9\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:23993.1#011validation-mae:41480.7\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:23770.8#011validation-mae:41302.7\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:23604.9#011validation-mae:41313.8\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:23402#011validation-mae:41211.8\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:23240.8#011validation-mae:41080.4\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:23076.3#011validation-mae:41023.5\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:22949.2#011validation-mae:40943.9\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:22804.7#011validation-mae:40787.4\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:22648.3#011validation-mae:40710.8\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:22525#011validation-mae:40631.7\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:22380.1#011validation-mae:40636.5\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:22217.4#011validation-mae:40565.6\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:22064.5#011validation-mae:40493\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:21876#011validation-mae:40345.8\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:21678.8#011validation-mae:40179.1\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:21520.4#011validation-mae:40126.8\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:21379.7#011validation-mae:39990.5\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:21273.6#011validation-mae:39960.8\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:21148.1#011validation-mae:39952.9\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:21024.4#011validation-mae:39833.7\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:20889.5#011validation-mae:39742.4\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:20711.5#011validation-mae:39669.7\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:20584.2#011validation-mae:39599.8\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:20475.6#011validation-mae:39519.7\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:20374.2#011validation-mae:39447.6\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:20256.1#011validation-mae:39334.6\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:20184#011validation-mae:39318.7\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:20072.3#011validation-mae:39222.7\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:19928#011validation-mae:39151.2\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:19806.4#011validation-mae:39095.3\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:19684.7#011validation-mae:39040.5\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:19605.7#011validation-mae:38975.3\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:19453.3#011validation-mae:38936.8\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:19361.2#011validation-mae:38880.5\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:19227.2#011validation-mae:38805.5\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:19094.9#011validation-mae:38799.2\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:18944.6#011validation-mae:38772.6\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:18851.9#011validation-mae:38733.9\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:18766.9#011validation-mae:38679.4\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:18665.6#011validation-mae:38586.4\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:18581.9#011validation-mae:38550.8\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:18484.9#011validation-mae:38466.8\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:18410.4#011validation-mae:38468.6\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:18337.2#011validation-mae:38382.9\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:18235.2#011validation-mae:38316.1\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:18117.4#011validation-mae:38275.8\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:17991.7#011validation-mae:38217.3\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:17881.1#011validation-mae:38162.6\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:17779.4#011validation-mae:38102.5\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:17690.2#011validation-mae:38089.9\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:17609.3#011validation-mae:38095.5\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:17491.6#011validation-mae:38043.3\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:17402.1#011validation-mae:38027.5\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:17290.7#011validation-mae:37992.8\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:17198.7#011validation-mae:37933.1\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:17119.4#011validation-mae:37865.5\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:17014.1#011validation-mae:37843.5\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:16935.3#011validation-mae:37863.3\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:16823.5#011validation-mae:37834.9\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:16732.9#011validation-mae:37793.6\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:16669.5#011validation-mae:37806.6\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:16593.2#011validation-mae:37773.2\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:16506.7#011validation-mae:37732.3\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:16428.5#011validation-mae:37694.2\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:16353.9#011validation-mae:37663.6\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:16269.7#011validation-mae:37624.7\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:16182.1#011validation-mae:37567.1\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:16084.5#011validation-mae:37522.7\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:16021.4#011validation-mae:37490.6\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:15925.3#011validation-mae:37472.5\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:15843.5#011validation-mae:37427.6\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:15772.7#011validation-mae:37416.1\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:15698#011validation-mae:37338.2\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:15629.7#011validation-mae:37344.7\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:15529.6#011validation-mae:37306.8\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:15420.8#011validation-mae:37271.5\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:15356.5#011validation-mae:37252\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:15306.5#011validation-mae:37237.1\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:15209.3#011validation-mae:37191\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:15155.4#011validation-mae:37170.9\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:15086.8#011validation-mae:37153.2\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:15006#011validation-mae:37112.8\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:14933.3#011validation-mae:37055.9\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:14866.1#011validation-mae:37005.6\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:14782#011validation-mae:37003.5\u001b[0m\n",
      "\u001b[31m[168]#011train-mae:14717.3#011validation-mae:36935\u001b[0m\n",
      "\u001b[31m[169]#011train-mae:14645.7#011validation-mae:36873\u001b[0m\n",
      "\u001b[31m[170]#011train-mae:14579#011validation-mae:36859.3\u001b[0m\n",
      "\u001b[31m[171]#011train-mae:14518.7#011validation-mae:36871.1\u001b[0m\n",
      "\u001b[31m[172]#011train-mae:14452.3#011validation-mae:36872.7\u001b[0m\n",
      "\u001b[31m[173]#011train-mae:14381#011validation-mae:36869.4\u001b[0m\n",
      "\u001b[31m[174]#011train-mae:14307#011validation-mae:36820.9\u001b[0m\n",
      "\u001b[31m[175]#011train-mae:14260.9#011validation-mae:36776.9\u001b[0m\n",
      "\u001b[31m[176]#011train-mae:14199.7#011validation-mae:36754.6\u001b[0m\n",
      "\u001b[31m[177]#011train-mae:14151.1#011validation-mae:36733.2\u001b[0m\n",
      "\u001b[31m[178]#011train-mae:14079.9#011validation-mae:36692.6\u001b[0m\n",
      "\u001b[31m[179]#011train-mae:14032.6#011validation-mae:36668\u001b[0m\n",
      "\u001b[31m[180]#011train-mae:13979#011validation-mae:36656.6\u001b[0m\n",
      "\u001b[31m[181]#011train-mae:13915.3#011validation-mae:36644.7\u001b[0m\n",
      "\u001b[31m[182]#011train-mae:13869#011validation-mae:36640.8\u001b[0m\n",
      "\u001b[31m[183]#011train-mae:13811.4#011validation-mae:36617.1\u001b[0m\n",
      "\u001b[31m[184]#011train-mae:13757.5#011validation-mae:36621.5\u001b[0m\n",
      "\u001b[31m[185]#011train-mae:13686.4#011validation-mae:36622.4\u001b[0m\n",
      "\u001b[31m[186]#011train-mae:13622.8#011validation-mae:36588.5\u001b[0m\n",
      "\u001b[31m[187]#011train-mae:13541.5#011validation-mae:36586.8\u001b[0m\n",
      "\u001b[31m[188]#011train-mae:13495.8#011validation-mae:36572.1\u001b[0m\n",
      "\u001b[31m[189]#011train-mae:13437.2#011validation-mae:36528.6\u001b[0m\n",
      "\u001b[31m[190]#011train-mae:13383.9#011validation-mae:36489.1\u001b[0m\n",
      "\u001b[31m[191]#011train-mae:13325.3#011validation-mae:36467.7\u001b[0m\n",
      "\u001b[31m[192]#011train-mae:13256.8#011validation-mae:36460.7\u001b[0m\n",
      "\u001b[31m[193]#011train-mae:13199.8#011validation-mae:36452.5\u001b[0m\n",
      "\u001b[31m[194]#011train-mae:13136.7#011validation-mae:36409.5\u001b[0m\n",
      "\u001b[31m[195]#011train-mae:13076.7#011validation-mae:36368.9\u001b[0m\n",
      "\u001b[31m[196]#011train-mae:13037.1#011validation-mae:36352.5\u001b[0m\n",
      "\u001b[31m[197]#011train-mae:12982.8#011validation-mae:36357.7\u001b[0m\n",
      "\u001b[31m[198]#011train-mae:12928.4#011validation-mae:36333.9\u001b[0m\n",
      "\u001b[31m[199]#011train-mae:12901.6#011validation-mae:36334.2\u001b[0m\n",
      "\u001b[31m[200]#011train-mae:12840.5#011validation-mae:36334.3\u001b[0m\n",
      "\u001b[31m[201]#011train-mae:12772.9#011validation-mae:36289.8\u001b[0m\n",
      "\u001b[31m[202]#011train-mae:12727.8#011validation-mae:36279\u001b[0m\n",
      "\u001b[31m[203]#011train-mae:12681.9#011validation-mae:36271.1\u001b[0m\n",
      "\u001b[31m[204]#011train-mae:12625.1#011validation-mae:36225.9\u001b[0m\n",
      "\u001b[31m[205]#011train-mae:12565.1#011validation-mae:36194.9\u001b[0m\n",
      "\u001b[31m[206]#011train-mae:12527.2#011validation-mae:36153.7\u001b[0m\n",
      "\u001b[31m[207]#011train-mae:12479.4#011validation-mae:36130.8\u001b[0m\n",
      "\u001b[31m[208]#011train-mae:12440.1#011validation-mae:36083.4\u001b[0m\n",
      "\u001b[31m[209]#011train-mae:12397.5#011validation-mae:36062.4\u001b[0m\n",
      "\u001b[31m[210]#011train-mae:12366#011validation-mae:36052\u001b[0m\n",
      "\u001b[31m[211]#011train-mae:12315.6#011validation-mae:35991.4\u001b[0m\n",
      "\u001b[31m[212]#011train-mae:12260.5#011validation-mae:36028.1\u001b[0m\n",
      "\u001b[31m[213]#011train-mae:12201.9#011validation-mae:35995\u001b[0m\n",
      "\u001b[31m[214]#011train-mae:12154.3#011validation-mae:35985.1\u001b[0m\n",
      "\u001b[31m[215]#011train-mae:12100.4#011validation-mae:35998\u001b[0m\n",
      "\u001b[31m[216]#011train-mae:12059.7#011validation-mae:35992.6\u001b[0m\n",
      "\u001b[31m[217]#011train-mae:12019.8#011validation-mae:35958.9\u001b[0m\n",
      "\u001b[31m[218]#011train-mae:11974.2#011validation-mae:35952.2\u001b[0m\n",
      "\u001b[31m[219]#011train-mae:11933.6#011validation-mae:35949\u001b[0m\n",
      "\u001b[31m[220]#011train-mae:11880.7#011validation-mae:35941.1\u001b[0m\n",
      "\u001b[31m[221]#011train-mae:11822.6#011validation-mae:35910.6\u001b[0m\n",
      "\u001b[31m[222]#011train-mae:11790.8#011validation-mae:35903.1\u001b[0m\n",
      "\u001b[31m[223]#011train-mae:11751.3#011validation-mae:35871.6\u001b[0m\n",
      "\u001b[31m[224]#011train-mae:11710.5#011validation-mae:35845.1\u001b[0m\n",
      "\u001b[31m[225]#011train-mae:11678.1#011validation-mae:35864.2\u001b[0m\n",
      "\u001b[31m[226]#011train-mae:11635.6#011validation-mae:35844.1\u001b[0m\n",
      "\u001b[31m[227]#011train-mae:11596#011validation-mae:35842.8\u001b[0m\n",
      "\u001b[31m[228]#011train-mae:11550.9#011validation-mae:35853.4\u001b[0m\n",
      "\u001b[31m[229]#011train-mae:11520.9#011validation-mae:35823.3\u001b[0m\n",
      "\u001b[31m[230]#011train-mae:11469.5#011validation-mae:35793.9\u001b[0m\n",
      "\u001b[31m[231]#011train-mae:11420.4#011validation-mae:35782.1\u001b[0m\n",
      "\u001b[31m[232]#011train-mae:11385.6#011validation-mae:35788.1\u001b[0m\n",
      "\u001b[31m[233]#011train-mae:11339.6#011validation-mae:35769.9\u001b[0m\n",
      "\u001b[31m[234]#011train-mae:11286.4#011validation-mae:35720.9\u001b[0m\n",
      "\u001b[31m[235]#011train-mae:11236.6#011validation-mae:35718.6\u001b[0m\n",
      "\u001b[31m[236]#011train-mae:11204.3#011validation-mae:35719.5\u001b[0m\n",
      "\u001b[31m[237]#011train-mae:11180#011validation-mae:35723.8\u001b[0m\n",
      "\u001b[31m[238]#011train-mae:11130.6#011validation-mae:35721.6\u001b[0m\n",
      "\u001b[31m[239]#011train-mae:11104.7#011validation-mae:35681.3\u001b[0m\n",
      "\u001b[31m[240]#011train-mae:11052.9#011validation-mae:35668.3\u001b[0m\n",
      "\u001b[31m[241]#011train-mae:11020.8#011validation-mae:35669.2\u001b[0m\n",
      "\u001b[31m[242]#011train-mae:10970.5#011validation-mae:35651.7\u001b[0m\n",
      "\u001b[31m[243]#011train-mae:10942.1#011validation-mae:35648.4\u001b[0m\n",
      "\u001b[31m[244]#011train-mae:10891.9#011validation-mae:35582.9\u001b[0m\n",
      "\u001b[31m[245]#011train-mae:10839.8#011validation-mae:35552.8\u001b[0m\n",
      "\u001b[31m[246]#011train-mae:10809.1#011validation-mae:35532.7\u001b[0m\n",
      "\u001b[31m[247]#011train-mae:10761.3#011validation-mae:35493.5\u001b[0m\n",
      "\u001b[31m[248]#011train-mae:10726.5#011validation-mae:35508.1\u001b[0m\n",
      "\u001b[31m[249]#011train-mae:10687.4#011validation-mae:35482.7\u001b[0m\n",
      "\u001b[31m[250]#011train-mae:10647.9#011validation-mae:35477.1\u001b[0m\n",
      "\u001b[31m[251]#011train-mae:10599.1#011validation-mae:35448.6\u001b[0m\n",
      "\u001b[31m[252]#011train-mae:10553.3#011validation-mae:35439.1\u001b[0m\n",
      "\u001b[31m[253]#011train-mae:10523.2#011validation-mae:35435.8\u001b[0m\n",
      "\u001b[31m[254]#011train-mae:10493.9#011validation-mae:35462.6\u001b[0m\n",
      "\u001b[31m[255]#011train-mae:10456#011validation-mae:35468.1\u001b[0m\n",
      "\u001b[31m[256]#011train-mae:10414.4#011validation-mae:35446.9\u001b[0m\n",
      "\u001b[31m[257]#011train-mae:10350.3#011validation-mae:35432.7\u001b[0m\n",
      "\u001b[31m[258]#011train-mae:10301.2#011validation-mae:35433.4\u001b[0m\n",
      "\u001b[31m[259]#011train-mae:10258.3#011validation-mae:35425.2\u001b[0m\n",
      "\u001b[31m[260]#011train-mae:10216.7#011validation-mae:35403.2\u001b[0m\n",
      "\u001b[31m[261]#011train-mae:10172.5#011validation-mae:35385.4\u001b[0m\n",
      "\u001b[31m[262]#011train-mae:10133.3#011validation-mae:35367\u001b[0m\n",
      "\u001b[31m[263]#011train-mae:10085.7#011validation-mae:35352.1\u001b[0m\n",
      "\u001b[31m[264]#011train-mae:10053.9#011validation-mae:35325.1\u001b[0m\n",
      "\u001b[31m[265]#011train-mae:10013.3#011validation-mae:35315.4\u001b[0m\n",
      "\u001b[31m[266]#011train-mae:9977.31#011validation-mae:35303.2\u001b[0m\n",
      "\u001b[31m[267]#011train-mae:9946.81#011validation-mae:35289.2\u001b[0m\n",
      "\u001b[31m[268]#011train-mae:9906.38#011validation-mae:35264.8\u001b[0m\n",
      "\u001b[31m[269]#011train-mae:9876.9#011validation-mae:35250\u001b[0m\n",
      "\u001b[31m[270]#011train-mae:9829.89#011validation-mae:35243.3\u001b[0m\n",
      "\u001b[31m[271]#011train-mae:9784.64#011validation-mae:35220.5\u001b[0m\n",
      "\u001b[31m[272]#011train-mae:9748.05#011validation-mae:35221.2\u001b[0m\n",
      "\u001b[31m[273]#011train-mae:9705.66#011validation-mae:35204.6\u001b[0m\n",
      "\u001b[31m[274]#011train-mae:9681#011validation-mae:35189.1\u001b[0m\n",
      "\u001b[31m[275]#011train-mae:9645.54#011validation-mae:35191.1\u001b[0m\n",
      "\u001b[31m[276]#011train-mae:9605.43#011validation-mae:35169.7\u001b[0m\n",
      "\u001b[31m[277]#011train-mae:9569.76#011validation-mae:35149.2\u001b[0m\n",
      "\u001b[31m[278]#011train-mae:9531.08#011validation-mae:35121.3\u001b[0m\n",
      "\u001b[31m[279]#011train-mae:9500.62#011validation-mae:35113.3\u001b[0m\n",
      "\u001b[31m[280]#011train-mae:9463.79#011validation-mae:35120.7\u001b[0m\n",
      "\u001b[31m[281]#011train-mae:9434.86#011validation-mae:35124.3\u001b[0m\n",
      "\u001b[31m[282]#011train-mae:9400.08#011validation-mae:35111.7\u001b[0m\n",
      "\u001b[31m[283]#011train-mae:9357.7#011validation-mae:35117.3\u001b[0m\n",
      "\u001b[31m[284]#011train-mae:9314.55#011validation-mae:35107.3\u001b[0m\n",
      "\u001b[31m[285]#011train-mae:9291.95#011validation-mae:35099.8\u001b[0m\n",
      "\u001b[31m[286]#011train-mae:9261.28#011validation-mae:35087.5\u001b[0m\n",
      "\u001b[31m[287]#011train-mae:9229.71#011validation-mae:35066.8\u001b[0m\n",
      "\u001b[31m[288]#011train-mae:9185.73#011validation-mae:35071.1\u001b[0m\n",
      "\u001b[31m[289]#011train-mae:9148.25#011validation-mae:35083.5\u001b[0m\n",
      "\u001b[31m[290]#011train-mae:9122.23#011validation-mae:35070.9\u001b[0m\n",
      "\u001b[31m[291]#011train-mae:9097.57#011validation-mae:35070.9\u001b[0m\n",
      "\u001b[31m[292]#011train-mae:9063.23#011validation-mae:35035.2\u001b[0m\n",
      "\u001b[31m[293]#011train-mae:9031.85#011validation-mae:35011.5\u001b[0m\n",
      "\u001b[31m[294]#011train-mae:9000.24#011validation-mae:34979.1\u001b[0m\n",
      "\u001b[31m[295]#011train-mae:8973.12#011validation-mae:34953.3\u001b[0m\n",
      "\u001b[31m[296]#011train-mae:8939.3#011validation-mae:34941.9\u001b[0m\n",
      "\u001b[31m[297]#011train-mae:8908.56#011validation-mae:34927.2\u001b[0m\n",
      "\u001b[31m[298]#011train-mae:8880.02#011validation-mae:34930.9\u001b[0m\n",
      "\u001b[31m[299]#011train-mae:8856.68#011validation-mae:34940.2\u001b[0m\n",
      "\u001b[31m[300]#011train-mae:8829.42#011validation-mae:34895.8\u001b[0m\n",
      "\u001b[31m[301]#011train-mae:8806.39#011validation-mae:34867.4\u001b[0m\n",
      "\u001b[31m[302]#011train-mae:8777.71#011validation-mae:34846.4\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:8741.58#011validation-mae:34834.2\u001b[0m\n",
      "\u001b[31m[304]#011train-mae:8702.73#011validation-mae:34866.8\u001b[0m\n",
      "\u001b[31m[305]#011train-mae:8662#011validation-mae:34892.5\u001b[0m\n",
      "\u001b[31m[306]#011train-mae:8644.55#011validation-mae:34896.1\u001b[0m\n",
      "\u001b[31m[307]#011train-mae:8609.9#011validation-mae:34886.2\u001b[0m\n",
      "\u001b[31m[308]#011train-mae:8569.57#011validation-mae:34891.4\u001b[0m\n",
      "\u001b[31m[309]#011train-mae:8544.82#011validation-mae:34875.6\u001b[0m\n",
      "\u001b[31m[310]#011train-mae:8512.92#011validation-mae:34846.8\u001b[0m\n",
      "\u001b[31m[311]#011train-mae:8469.26#011validation-mae:34858\u001b[0m\n",
      "\u001b[31m[312]#011train-mae:8428.95#011validation-mae:34845.9\u001b[0m\n",
      "\u001b[31m[313]#011train-mae:8406.75#011validation-mae:34836\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:8741.58#011validation-mae:34834.2\n",
      "\u001b[0m\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "xgb_attached3 = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06872632753969216\n"
     ]
    }
   ],
   "source": [
    "top_mae = 34834.2\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for this job's best round were: {'eval_metric': ['mae'], 'num_round': 437, '_tuning_objective_metric': 'validation:mae', 'early_stopping_rounds': 10, 'subsample': 0.8, 'eta': 0.43166340798965475, 'lambda': 682.9055918627323, 'gamma': 4.0, 'max_depth': 5, 'rate_drop': 0.2, 'objective': 'reg:linear', 'min_child_weight': 8.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the parameters for the \"best\" training rounds with dropout rates of 0.2, 0.3, and 0.5, I am interested in increasing the early stopping rounds and checking the MAPE for a dropout rate of 0.4. While we are trying to minimize MAPE for this validation set, our ultimate goal is best generalize these findings, in order to minimize MAPE for new samples to have as accurate of a model as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# rate_drop has been updated to 0.4 from 0.2\n",
    "# early stopping rounds have also been increased to 30\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=30,\n",
    "                        rate_drop=0.4,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same tuning parameters are being used,\n",
    "# but we are re-assigning the xgb reference to 'estimator' now that it has been updated:\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 20, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'eta'      : ContinuousParameter(0.0, 0.5),\n",
    "                                                  'lambda'   : ContinuousParameter(0, 1000),\n",
    "                                                  'max_depth': IntegerParameter(5, 17),\n",
    "                                                  'num_round': IntegerParameter(100, 500),\n",
    "                                                  'min_child_weight': IntegerParameter(1, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 22:28:53 Starting - Preparing the instances for training\n",
      "2019-09-06 22:28:53 Downloading - Downloading input data\n",
      "2019-09-06 22:28:53 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 22:28:53 Uploading - Uploading generated training model\n",
      "2019-09-06 22:28:53 Completed - Training job completed\u001b[31m2019-09-06 22:28:43,213 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,214 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,214 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,217 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,229 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,232 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,232 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,233 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,233 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,234 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:28:43] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,254 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:28:43] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,267 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,267 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,267 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,268 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:28:43,268 root         INFO     {'lambda': 558.6096209933158, 'subsample': 0.8, 'max_depth': 8, 'gamma': 4.0, 'num_round': 391, 'min_child_weight': 9.0, 'eval_metric': ['mae'], 'rate_drop': 0.4, 'objective': 'reg:linear', 'eta': 0.4978509338613065, 'early_stopping_rounds': 30, '_tuning_objective_metric': 'validation:mae'}\u001b[0m\n",
      "\u001b[31m[22:28:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:412124#011validation-mae:402532\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 30 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:329417#011validation-mae:320675\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:264805#011validation-mae:258171\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:214070#011validation-mae:210135\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:177042#011validation-mae:174568\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:149269#011validation-mae:147564\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:128648#011validation-mae:127443\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:111780#011validation-mae:111269\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:98167.9#011validation-mae:98054\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:87411.9#011validation-mae:87828.6\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:79145#011validation-mae:80462.2\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:72696.5#011validation-mae:75283.5\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:67155.9#011validation-mae:70883.4\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:62260.7#011validation-mae:67768.5\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:58582.8#011validation-mae:65084.9\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:55735.6#011validation-mae:63457.2\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:53344.9#011validation-mae:61683.9\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:51260#011validation-mae:60361.9\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:49467.7#011validation-mae:58798.7\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:47731.1#011validation-mae:57498.4\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:46414.6#011validation-mae:56695.3\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:45142.9#011validation-mae:55728.3\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:43961.3#011validation-mae:54939.1\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:42877.6#011validation-mae:54189.3\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:41874.6#011validation-mae:53314.1\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:40953.8#011validation-mae:52476.4\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:40031.6#011validation-mae:51925.6\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:39090.6#011validation-mae:51257\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:38224.1#011validation-mae:50913.8\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:37525.9#011validation-mae:50512.6\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:36978.9#011validation-mae:50154.1\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:36335.9#011validation-mae:49544.7\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:35561.2#011validation-mae:48976.3\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:34772#011validation-mae:48462.3\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:34167.5#011validation-mae:48089.9\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:33479.1#011validation-mae:47616.4\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:32970.9#011validation-mae:47340.4\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:32460.8#011validation-mae:47019.9\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:31835.5#011validation-mae:46670.5\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:31329.5#011validation-mae:46377\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:30899.3#011validation-mae:46221.8\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:30488#011validation-mae:45997.1\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:30028.8#011validation-mae:45792.9\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:29644#011validation-mae:45614\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:29242.5#011validation-mae:45410.2\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:28863.7#011validation-mae:45192.7\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:28487.1#011validation-mae:45045\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:28097.6#011validation-mae:44896.9\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:27717#011validation-mae:44717.9\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:27327.9#011validation-mae:44425.8\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:26953.4#011validation-mae:44192.8\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:26666#011validation-mae:43949.8\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:26340.7#011validation-mae:43761.1\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:25979.2#011validation-mae:43614.8\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:25660.5#011validation-mae:43417.3\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:25316.8#011validation-mae:43229.3\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:24986.8#011validation-mae:42981.3\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:24693.2#011validation-mae:42892.4\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:24399.2#011validation-mae:42778.7\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:24134.8#011validation-mae:42615.4\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:23842.3#011validation-mae:42429.5\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:23636#011validation-mae:42345.9\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:23338.7#011validation-mae:42115.9\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:23053.3#011validation-mae:41985.3\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:22807.7#011validation-mae:41879\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:22498.2#011validation-mae:41642.4\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:22308.5#011validation-mae:41533.4\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:22063#011validation-mae:41432.7\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:21754#011validation-mae:41311.1\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:21568.8#011validation-mae:41159\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:21313.7#011validation-mae:40963.7\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:21071.8#011validation-mae:40881.7\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:20852.7#011validation-mae:40771.7\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:20659.5#011validation-mae:40669.2\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:20490.5#011validation-mae:40542.3\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:20308.8#011validation-mae:40525.9\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:20090.9#011validation-mae:40383.5\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:19882.1#011validation-mae:40322.5\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:19683.9#011validation-mae:40093.6\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:19518.4#011validation-mae:39965.4\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:19355.4#011validation-mae:39807.8\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:19177.7#011validation-mae:39766\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:19044.2#011validation-mae:39770.3\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:18799.3#011validation-mae:39644.7\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:18622.1#011validation-mae:39529.2\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:18470.6#011validation-mae:39564.4\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:18343.8#011validation-mae:39504.3\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:18203.6#011validation-mae:39445.2\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:17988.5#011validation-mae:39373.7\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:17808.8#011validation-mae:39322.1\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:17677#011validation-mae:39252.1\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:17539.5#011validation-mae:39164.6\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:17393.7#011validation-mae:39123\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:17229.5#011validation-mae:39071.7\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:17101#011validation-mae:39047.5\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:16937.9#011validation-mae:38932.4\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:16828.8#011validation-mae:38895.4\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:16715.6#011validation-mae:38857\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:16578.7#011validation-mae:38843.7\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:16454.5#011validation-mae:38749.3\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:16350.9#011validation-mae:38789\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:16257.2#011validation-mae:38805.1\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:16155.6#011validation-mae:38837.2\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:16055.8#011validation-mae:38772.6\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:15943.9#011validation-mae:38687.3\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:15818.2#011validation-mae:38657.7\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:15725.3#011validation-mae:38653.7\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:15611.2#011validation-mae:38636.3\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:15516.1#011validation-mae:38594\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:15414.9#011validation-mae:38547.7\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:15285.6#011validation-mae:38499.7\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:15178.8#011validation-mae:38446.1\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:15077.4#011validation-mae:38344.9\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:14986.5#011validation-mae:38315.4\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:14886.9#011validation-mae:38262.4\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:14780.5#011validation-mae:38218.7\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:14660.9#011validation-mae:38197.7\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:14589.8#011validation-mae:38173.5\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:14475.7#011validation-mae:38145.5\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:14382.1#011validation-mae:38131.4\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:14254.9#011validation-mae:38091.1\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:14147.6#011validation-mae:38024\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:14042.9#011validation-mae:37925.3\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:13949.5#011validation-mae:37927.8\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:13869.3#011validation-mae:37878.4\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:13779.4#011validation-mae:37886.4\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:13671#011validation-mae:37862.6\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:13574.9#011validation-mae:37784.9\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:13510.7#011validation-mae:37770.1\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:13395.9#011validation-mae:37747.8\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:13306.2#011validation-mae:37721.4\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:13226#011validation-mae:37702\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:13152.4#011validation-mae:37662.9\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:13087.5#011validation-mae:37667.7\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:12991.1#011validation-mae:37675.1\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:12912.1#011validation-mae:37678.4\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:12828.6#011validation-mae:37629.2\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:12768.8#011validation-mae:37596.4\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:12665.8#011validation-mae:37554.8\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:12571.5#011validation-mae:37529.1\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:12490.4#011validation-mae:37537.2\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:12410.4#011validation-mae:37504.7\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:12327.2#011validation-mae:37543.9\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:12261.8#011validation-mae:37551.2\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:12181.6#011validation-mae:37507.3\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:12103.8#011validation-mae:37471.7\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:12027.5#011validation-mae:37424.3\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:11953.4#011validation-mae:37404.7\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:11883#011validation-mae:37370.9\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:11824.9#011validation-mae:37324.6\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:11748.3#011validation-mae:37310.1\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:11686#011validation-mae:37276.8\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:11613.5#011validation-mae:37254.9\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:11561.1#011validation-mae:37246.4\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:11506.6#011validation-mae:37197.6\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:11420.2#011validation-mae:37213.9\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:11351.6#011validation-mae:37184.8\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:11287.5#011validation-mae:37215.7\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:11203.4#011validation-mae:37164.2\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:11143#011validation-mae:37116.4\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:11087.6#011validation-mae:37108\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:11001.6#011validation-mae:37076.7\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:10931#011validation-mae:37072.5\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:10882.2#011validation-mae:37052.6\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:10816.2#011validation-mae:37030.9\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:10758.6#011validation-mae:37018.2\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:10692.5#011validation-mae:37025.1\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:10617.7#011validation-mae:37006.8\u001b[0m\n",
      "\u001b[31m[168]#011train-mae:10560.9#011validation-mae:36969\u001b[0m\n",
      "\u001b[31m[169]#011train-mae:10502.9#011validation-mae:36939.2\u001b[0m\n",
      "\u001b[31m[170]#011train-mae:10439.5#011validation-mae:36901\u001b[0m\n",
      "\u001b[31m[171]#011train-mae:10377.3#011validation-mae:36899.2\u001b[0m\n",
      "\u001b[31m[172]#011train-mae:10316.9#011validation-mae:36863.3\u001b[0m\n",
      "\u001b[31m[173]#011train-mae:10259.4#011validation-mae:36847.5\u001b[0m\n",
      "\u001b[31m[174]#011train-mae:10186.9#011validation-mae:36815.1\u001b[0m\n",
      "\u001b[31m[175]#011train-mae:10126.6#011validation-mae:36816.8\u001b[0m\n",
      "\u001b[31m[176]#011train-mae:10065.3#011validation-mae:36833.3\u001b[0m\n",
      "\u001b[31m[177]#011train-mae:10009.4#011validation-mae:36832.5\u001b[0m\n",
      "\u001b[31m[178]#011train-mae:9939.79#011validation-mae:36805.5\u001b[0m\n",
      "\u001b[31m[179]#011train-mae:9886.95#011validation-mae:36826.6\u001b[0m\n",
      "\u001b[31m[180]#011train-mae:9821.96#011validation-mae:36787.2\u001b[0m\n",
      "\u001b[31m[181]#011train-mae:9775.2#011validation-mae:36777.3\u001b[0m\n",
      "\u001b[31m[182]#011train-mae:9720.44#011validation-mae:36769.6\u001b[0m\n",
      "\u001b[31m[183]#011train-mae:9668.72#011validation-mae:36717.2\u001b[0m\n",
      "\u001b[31m[184]#011train-mae:9609#011validation-mae:36694.5\u001b[0m\n",
      "\u001b[31m[185]#011train-mae:9543.25#011validation-mae:36683.2\u001b[0m\n",
      "\u001b[31m[186]#011train-mae:9498.46#011validation-mae:36679.4\u001b[0m\n",
      "\u001b[31m[187]#011train-mae:9429.41#011validation-mae:36636.6\u001b[0m\n",
      "\u001b[31m[188]#011train-mae:9365.6#011validation-mae:36591.3\u001b[0m\n",
      "\u001b[31m[189]#011train-mae:9314.91#011validation-mae:36555.2\u001b[0m\n",
      "\u001b[31m[190]#011train-mae:9272.33#011validation-mae:36520.5\u001b[0m\n",
      "\u001b[31m[191]#011train-mae:9227.34#011validation-mae:36501.7\u001b[0m\n",
      "\u001b[31m[192]#011train-mae:9188.8#011validation-mae:36501.6\u001b[0m\n",
      "\u001b[31m[193]#011train-mae:9141.66#011validation-mae:36492.2\u001b[0m\n",
      "\u001b[31m[194]#011train-mae:9086.84#011validation-mae:36461.9\u001b[0m\n",
      "\u001b[31m[195]#011train-mae:9037.48#011validation-mae:36448.2\u001b[0m\n",
      "\u001b[31m[196]#011train-mae:8982.37#011validation-mae:36449.9\u001b[0m\n",
      "\u001b[31m[197]#011train-mae:8932.17#011validation-mae:36452.2\u001b[0m\n",
      "\u001b[31m[198]#011train-mae:8893.1#011validation-mae:36441.3\u001b[0m\n",
      "\u001b[31m[199]#011train-mae:8852.42#011validation-mae:36417.5\u001b[0m\n",
      "\u001b[31m[200]#011train-mae:8818.51#011validation-mae:36429\u001b[0m\n",
      "\u001b[31m[201]#011train-mae:8767.1#011validation-mae:36394\u001b[0m\n",
      "\u001b[31m[202]#011train-mae:8726.25#011validation-mae:36390.5\u001b[0m\n",
      "\u001b[31m[203]#011train-mae:8676.64#011validation-mae:36384.3\u001b[0m\n",
      "\u001b[31m[204]#011train-mae:8612.95#011validation-mae:36358.2\u001b[0m\n",
      "\u001b[31m[205]#011train-mae:8569.92#011validation-mae:36317.7\u001b[0m\n",
      "\u001b[31m[206]#011train-mae:8524.18#011validation-mae:36287.5\u001b[0m\n",
      "\u001b[31m[207]#011train-mae:8475.63#011validation-mae:36291.3\u001b[0m\n",
      "\u001b[31m[208]#011train-mae:8441.93#011validation-mae:36297.2\u001b[0m\n",
      "\u001b[31m[209]#011train-mae:8393.46#011validation-mae:36266.5\u001b[0m\n",
      "\u001b[31m[210]#011train-mae:8352.52#011validation-mae:36276.5\u001b[0m\n",
      "\u001b[31m[211]#011train-mae:8307.65#011validation-mae:36237.4\u001b[0m\n",
      "\u001b[31m[212]#011train-mae:8262.2#011validation-mae:36221.5\u001b[0m\n",
      "\u001b[31m[213]#011train-mae:8226.81#011validation-mae:36216.3\u001b[0m\n",
      "\u001b[31m[214]#011train-mae:8184.98#011validation-mae:36197.6\u001b[0m\n",
      "\u001b[31m[215]#011train-mae:8138.45#011validation-mae:36202.3\u001b[0m\n",
      "\u001b[31m[216]#011train-mae:8108.92#011validation-mae:36191.3\u001b[0m\n",
      "\u001b[31m[217]#011train-mae:8072.89#011validation-mae:36140.9\u001b[0m\n",
      "\u001b[31m[218]#011train-mae:8034.4#011validation-mae:36144.5\u001b[0m\n",
      "\u001b[31m[219]#011train-mae:8004.09#011validation-mae:36146.4\u001b[0m\n",
      "\u001b[31m[220]#011train-mae:7960.55#011validation-mae:36159.7\u001b[0m\n",
      "\u001b[31m[221]#011train-mae:7904.05#011validation-mae:36128\u001b[0m\n",
      "\u001b[31m[222]#011train-mae:7865.17#011validation-mae:36110.8\u001b[0m\n",
      "\u001b[31m[223]#011train-mae:7829.65#011validation-mae:36096.4\u001b[0m\n",
      "\u001b[31m[224]#011train-mae:7792.25#011validation-mae:36096.5\u001b[0m\n",
      "\u001b[31m[225]#011train-mae:7751.61#011validation-mae:36092.3\u001b[0m\n",
      "\u001b[31m[226]#011train-mae:7703.64#011validation-mae:36081.9\u001b[0m\n",
      "\u001b[31m[227]#011train-mae:7656.94#011validation-mae:36097.7\u001b[0m\n",
      "\u001b[31m[228]#011train-mae:7619.37#011validation-mae:36068\u001b[0m\n",
      "\u001b[31m[229]#011train-mae:7581.69#011validation-mae:36075.8\u001b[0m\n",
      "\u001b[31m[230]#011train-mae:7550.41#011validation-mae:36087.3\u001b[0m\n",
      "\u001b[31m[231]#011train-mae:7529.66#011validation-mae:36083\u001b[0m\n",
      "\u001b[31m[232]#011train-mae:7490.82#011validation-mae:36051.2\u001b[0m\n",
      "\u001b[31m[233]#011train-mae:7458.39#011validation-mae:36038.9\u001b[0m\n",
      "\u001b[31m[234]#011train-mae:7431.31#011validation-mae:36035.5\u001b[0m\n",
      "\u001b[31m[235]#011train-mae:7391.57#011validation-mae:36012\u001b[0m\n",
      "\u001b[31m[236]#011train-mae:7343.49#011validation-mae:35975\u001b[0m\n",
      "\u001b[31m[237]#011train-mae:7302.44#011validation-mae:35982.8\u001b[0m\n",
      "\u001b[31m[238]#011train-mae:7251.35#011validation-mae:35976.8\u001b[0m\n",
      "\u001b[31m[239]#011train-mae:7227.97#011validation-mae:35977.7\u001b[0m\n",
      "\u001b[31m[240]#011train-mae:7196.52#011validation-mae:35982.9\u001b[0m\n",
      "\u001b[31m[241]#011train-mae:7159.21#011validation-mae:35987.1\u001b[0m\n",
      "\u001b[31m[242]#011train-mae:7125.82#011validation-mae:35992.2\u001b[0m\n",
      "\u001b[31m[243]#011train-mae:7101.2#011validation-mae:35978.6\u001b[0m\n",
      "\u001b[31m[244]#011train-mae:7058.36#011validation-mae:35961\u001b[0m\n",
      "\u001b[31m[245]#011train-mae:7008.15#011validation-mae:35972.7\u001b[0m\n",
      "\u001b[31m[246]#011train-mae:6979.52#011validation-mae:35963.8\u001b[0m\n",
      "\u001b[31m[247]#011train-mae:6938.03#011validation-mae:35964.1\u001b[0m\n",
      "\u001b[31m[248]#011train-mae:6900.24#011validation-mae:35965.4\u001b[0m\n",
      "\u001b[31m[249]#011train-mae:6877.4#011validation-mae:35956.2\u001b[0m\n",
      "\u001b[31m[250]#011train-mae:6830.53#011validation-mae:35936.2\u001b[0m\n",
      "\u001b[31m[251]#011train-mae:6791.24#011validation-mae:35912.3\u001b[0m\n",
      "\u001b[31m[252]#011train-mae:6756.92#011validation-mae:35927.8\u001b[0m\n",
      "\u001b[31m[253]#011train-mae:6718.28#011validation-mae:35932\u001b[0m\n",
      "\u001b[31m[254]#011train-mae:6686.56#011validation-mae:35947.4\u001b[0m\n",
      "\u001b[31m[255]#011train-mae:6649.84#011validation-mae:35946.9\u001b[0m\n",
      "\u001b[31m[256]#011train-mae:6613#011validation-mae:35923.5\u001b[0m\n",
      "\u001b[31m[257]#011train-mae:6593.75#011validation-mae:35895.3\u001b[0m\n",
      "\u001b[31m[258]#011train-mae:6566.82#011validation-mae:35907.5\u001b[0m\n",
      "\u001b[31m[259]#011train-mae:6543.46#011validation-mae:35887.5\u001b[0m\n",
      "\u001b[31m[260]#011train-mae:6518.85#011validation-mae:35873.5\u001b[0m\n",
      "\u001b[31m[261]#011train-mae:6484.74#011validation-mae:35848.6\u001b[0m\n",
      "\u001b[31m[262]#011train-mae:6439.6#011validation-mae:35829.3\u001b[0m\n",
      "\u001b[31m[263]#011train-mae:6405.01#011validation-mae:35817.5\u001b[0m\n",
      "\u001b[31m[264]#011train-mae:6369.05#011validation-mae:35803.2\u001b[0m\n",
      "\u001b[31m[265]#011train-mae:6338.28#011validation-mae:35779.2\u001b[0m\n",
      "\u001b[31m[266]#011train-mae:6307.29#011validation-mae:35780.2\u001b[0m\n",
      "\u001b[31m[267]#011train-mae:6271.99#011validation-mae:35756.1\u001b[0m\n",
      "\u001b[31m[268]#011train-mae:6237.22#011validation-mae:35731.2\u001b[0m\n",
      "\u001b[31m[269]#011train-mae:6219.15#011validation-mae:35708.4\u001b[0m\n",
      "\u001b[31m[270]#011train-mae:6188.14#011validation-mae:35703.9\u001b[0m\n",
      "\u001b[31m[271]#011train-mae:6161#011validation-mae:35697.6\u001b[0m\n",
      "\u001b[31m[272]#011train-mae:6139.95#011validation-mae:35698.9\u001b[0m\n",
      "\u001b[31m[273]#011train-mae:6116.25#011validation-mae:35712.6\u001b[0m\n",
      "\u001b[31m[274]#011train-mae:6077.87#011validation-mae:35684.3\u001b[0m\n",
      "\u001b[31m[275]#011train-mae:6046.43#011validation-mae:35688.6\u001b[0m\n",
      "\u001b[31m[276]#011train-mae:6013.33#011validation-mae:35690.8\u001b[0m\n",
      "\u001b[31m[277]#011train-mae:5975.22#011validation-mae:35667.7\u001b[0m\n",
      "\u001b[31m[278]#011train-mae:5938.98#011validation-mae:35643.2\u001b[0m\n",
      "\u001b[31m[279]#011train-mae:5914.55#011validation-mae:35620.7\u001b[0m\n",
      "\u001b[31m[280]#011train-mae:5898.58#011validation-mae:35623.8\u001b[0m\n",
      "\u001b[31m[281]#011train-mae:5880.96#011validation-mae:35621.9\u001b[0m\n",
      "\u001b[31m[282]#011train-mae:5851.96#011validation-mae:35625.6\u001b[0m\n",
      "\u001b[31m[283]#011train-mae:5832.66#011validation-mae:35628.2\u001b[0m\n",
      "\u001b[31m[284]#011train-mae:5801.39#011validation-mae:35624.6\u001b[0m\n",
      "\u001b[31m[285]#011train-mae:5776.23#011validation-mae:35606\u001b[0m\n",
      "\u001b[31m[286]#011train-mae:5742.82#011validation-mae:35609.6\u001b[0m\n",
      "\u001b[31m[287]#011train-mae:5719.18#011validation-mae:35604.4\u001b[0m\n",
      "\u001b[31m[288]#011train-mae:5686.56#011validation-mae:35596.6\u001b[0m\n",
      "\u001b[31m[289]#011train-mae:5657.67#011validation-mae:35582.1\u001b[0m\n",
      "\u001b[31m[290]#011train-mae:5624.08#011validation-mae:35562.6\u001b[0m\n",
      "\u001b[31m[291]#011train-mae:5605.22#011validation-mae:35533.2\u001b[0m\n",
      "\u001b[31m[292]#011train-mae:5578.51#011validation-mae:35521.7\u001b[0m\n",
      "\u001b[31m[293]#011train-mae:5550.29#011validation-mae:35498.3\u001b[0m\n",
      "\u001b[31m[294]#011train-mae:5519.66#011validation-mae:35491.1\u001b[0m\n",
      "\u001b[31m[295]#011train-mae:5491.1#011validation-mae:35481.2\u001b[0m\n",
      "\u001b[31m[296]#011train-mae:5464.13#011validation-mae:35485.6\u001b[0m\n",
      "\u001b[31m[297]#011train-mae:5444.04#011validation-mae:35462\u001b[0m\n",
      "\u001b[31m[298]#011train-mae:5419.15#011validation-mae:35450.9\u001b[0m\n",
      "\u001b[31m[299]#011train-mae:5395.13#011validation-mae:35452.2\u001b[0m\n",
      "\u001b[31m[300]#011train-mae:5357.03#011validation-mae:35427.7\u001b[0m\n",
      "\u001b[31m[301]#011train-mae:5332.16#011validation-mae:35406.5\u001b[0m\n",
      "\u001b[31m[302]#011train-mae:5314.99#011validation-mae:35382.2\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:5295.11#011validation-mae:35365.5\u001b[0m\n",
      "\u001b[31m[304]#011train-mae:5256.1#011validation-mae:35370.9\u001b[0m\n",
      "\u001b[31m[305]#011train-mae:5236.06#011validation-mae:35384.8\u001b[0m\n",
      "\u001b[31m[306]#011train-mae:5219.38#011validation-mae:35365.7\u001b[0m\n",
      "\u001b[31m[307]#011train-mae:5188.37#011validation-mae:35354.4\u001b[0m\n",
      "\u001b[31m[308]#011train-mae:5161.96#011validation-mae:35369\u001b[0m\n",
      "\u001b[31m[309]#011train-mae:5142.02#011validation-mae:35369.5\u001b[0m\n",
      "\u001b[31m[310]#011train-mae:5116.1#011validation-mae:35349.2\u001b[0m\n",
      "\u001b[31m[311]#011train-mae:5088.49#011validation-mae:35361.4\u001b[0m\n",
      "\u001b[31m[312]#011train-mae:5057.4#011validation-mae:35350.9\u001b[0m\n",
      "\u001b[31m[313]#011train-mae:5038.99#011validation-mae:35348.2\u001b[0m\n",
      "\u001b[31m[314]#011train-mae:5018.9#011validation-mae:35353.5\u001b[0m\n",
      "\u001b[31m[315]#011train-mae:4993.26#011validation-mae:35361.7\u001b[0m\n",
      "\u001b[31m[316]#011train-mae:4964.53#011validation-mae:35334.2\u001b[0m\n",
      "\u001b[31m[317]#011train-mae:4944.22#011validation-mae:35330.6\u001b[0m\n",
      "\u001b[31m[318]#011train-mae:4928.3#011validation-mae:35330.4\u001b[0m\n",
      "\u001b[31m[319]#011train-mae:4912.37#011validation-mae:35317.2\u001b[0m\n",
      "\u001b[31m[320]#011train-mae:4901.73#011validation-mae:35322.1\u001b[0m\n",
      "\u001b[31m[321]#011train-mae:4882.32#011validation-mae:35319.8\u001b[0m\n",
      "\u001b[31m[322]#011train-mae:4866.89#011validation-mae:35318\u001b[0m\n",
      "\u001b[31m[323]#011train-mae:4842.11#011validation-mae:35316\u001b[0m\n",
      "\u001b[31m[324]#011train-mae:4821#011validation-mae:35301.7\u001b[0m\n",
      "\u001b[31m[325]#011train-mae:4799.34#011validation-mae:35296.9\u001b[0m\n",
      "\u001b[31m[326]#011train-mae:4784.78#011validation-mae:35304.9\u001b[0m\n",
      "\u001b[31m[327]#011train-mae:4762.28#011validation-mae:35308\u001b[0m\n",
      "\u001b[31m[328]#011train-mae:4732.61#011validation-mae:35306.7\u001b[0m\n",
      "\u001b[31m[329]#011train-mae:4710.63#011validation-mae:35306.8\u001b[0m\n",
      "\u001b[31m[330]#011train-mae:4687.55#011validation-mae:35302\u001b[0m\n",
      "\u001b[31m[331]#011train-mae:4664.1#011validation-mae:35311.4\u001b[0m\n",
      "\u001b[31m[332]#011train-mae:4644.62#011validation-mae:35300.5\u001b[0m\n",
      "\u001b[31m[333]#011train-mae:4623.3#011validation-mae:35282.7\u001b[0m\n",
      "\u001b[31m[334]#011train-mae:4595.56#011validation-mae:35280.8\u001b[0m\n",
      "\u001b[31m[335]#011train-mae:4561.81#011validation-mae:35289.5\u001b[0m\n",
      "\u001b[31m[336]#011train-mae:4541.42#011validation-mae:35282.9\u001b[0m\n",
      "\u001b[31m[337]#011train-mae:4519.02#011validation-mae:35284.7\u001b[0m\n",
      "\u001b[31m[338]#011train-mae:4493.37#011validation-mae:35280.9\u001b[0m\n",
      "\u001b[31m[339]#011train-mae:4474.32#011validation-mae:35289.8\u001b[0m\n",
      "\u001b[31m[340]#011train-mae:4449.62#011validation-mae:35289.9\u001b[0m\n",
      "\u001b[31m[341]#011train-mae:4425.38#011validation-mae:35289.8\u001b[0m\n",
      "\u001b[31m[342]#011train-mae:4408.32#011validation-mae:35275.1\u001b[0m\n",
      "\u001b[31m[343]#011train-mae:4385.35#011validation-mae:35282.2\u001b[0m\n",
      "\u001b[31m[344]#011train-mae:4362.85#011validation-mae:35270.4\u001b[0m\n",
      "\u001b[31m[345]#011train-mae:4344.62#011validation-mae:35271.8\u001b[0m\n",
      "\u001b[31m[346]#011train-mae:4319.36#011validation-mae:35262.6\u001b[0m\n",
      "\u001b[31m[347]#011train-mae:4299.48#011validation-mae:35270.7\u001b[0m\n",
      "\u001b[31m[348]#011train-mae:4279.26#011validation-mae:35247.8\u001b[0m\n",
      "\u001b[31m[349]#011train-mae:4263.52#011validation-mae:35239.4\u001b[0m\n",
      "\u001b[31m[350]#011train-mae:4240.36#011validation-mae:35221.5\u001b[0m\n",
      "\u001b[31m[351]#011train-mae:4218.61#011validation-mae:35217.5\u001b[0m\n",
      "\u001b[31m[352]#011train-mae:4210.05#011validation-mae:35215.8\u001b[0m\n",
      "\u001b[31m[353]#011train-mae:4200.79#011validation-mae:35219.4\u001b[0m\n",
      "\u001b[31m[354]#011train-mae:4177.86#011validation-mae:35215\u001b[0m\n",
      "\u001b[31m[355]#011train-mae:4156.9#011validation-mae:35198.3\u001b[0m\n",
      "\u001b[31m[356]#011train-mae:4145.45#011validation-mae:35198.4\u001b[0m\n",
      "\u001b[31m[357]#011train-mae:4120.23#011validation-mae:35177\u001b[0m\n",
      "\u001b[31m[358]#011train-mae:4097.69#011validation-mae:35168.8\u001b[0m\n",
      "\u001b[31m[359]#011train-mae:4086.42#011validation-mae:35154.6\u001b[0m\n",
      "\u001b[31m[360]#011train-mae:4059.63#011validation-mae:35137.7\u001b[0m\n",
      "\u001b[31m[361]#011train-mae:4044.67#011validation-mae:35123.7\u001b[0m\n",
      "\u001b[31m[362]#011train-mae:4020.79#011validation-mae:35121.7\u001b[0m\n",
      "\u001b[31m[363]#011train-mae:3992.89#011validation-mae:35134.8\u001b[0m\n",
      "\u001b[31m[364]#011train-mae:3982.86#011validation-mae:35142.1\u001b[0m\n",
      "\u001b[31m[365]#011train-mae:3957.14#011validation-mae:35140.4\u001b[0m\n",
      "\u001b[31m[366]#011train-mae:3946.92#011validation-mae:35143.2\u001b[0m\n",
      "\u001b[31m[367]#011train-mae:3931.28#011validation-mae:35129.4\u001b[0m\n",
      "\u001b[31m[368]#011train-mae:3905.83#011validation-mae:35142\u001b[0m\n",
      "\u001b[31m[369]#011train-mae:3885.98#011validation-mae:35143.4\u001b[0m\n",
      "\u001b[31m[370]#011train-mae:3873.13#011validation-mae:35136.2\u001b[0m\n",
      "\u001b[31m[371]#011train-mae:3856.69#011validation-mae:35132.1\u001b[0m\n",
      "\u001b[31m[372]#011train-mae:3838.87#011validation-mae:35138\u001b[0m\n",
      "\u001b[31m[373]#011train-mae:3829.53#011validation-mae:35137\u001b[0m\n",
      "\u001b[31m[374]#011train-mae:3809.96#011validation-mae:35137\u001b[0m\n",
      "\u001b[31m[375]#011train-mae:3792.88#011validation-mae:35119.6\u001b[0m\n",
      "\u001b[31m[376]#011train-mae:3779.29#011validation-mae:35108.8\u001b[0m\n",
      "\u001b[31m[377]#011train-mae:3767.82#011validation-mae:35101.4\u001b[0m\n",
      "\u001b[31m[378]#011train-mae:3754.55#011validation-mae:35089.5\u001b[0m\n",
      "\u001b[31m[379]#011train-mae:3734.89#011validation-mae:35075.7\u001b[0m\n",
      "\u001b[31m[380]#011train-mae:3723.32#011validation-mae:35075.4\u001b[0m\n",
      "\u001b[31m[381]#011train-mae:3711.2#011validation-mae:35066.4\u001b[0m\n",
      "\u001b[31m[382]#011train-mae:3692.84#011validation-mae:35074.5\u001b[0m\n",
      "\u001b[31m[383]#011train-mae:3683.8#011validation-mae:35063.3\u001b[0m\n",
      "\u001b[31m[384]#011train-mae:3669.28#011validation-mae:35060.9\u001b[0m\n",
      "\u001b[31m[385]#011train-mae:3649.87#011validation-mae:35063.3\u001b[0m\n",
      "\u001b[31m[386]#011train-mae:3637.15#011validation-mae:35060.8\u001b[0m\n",
      "\u001b[31m[387]#011train-mae:3619.01#011validation-mae:35055\u001b[0m\n",
      "\u001b[31m[388]#011train-mae:3603.02#011validation-mae:35054.7\u001b[0m\n",
      "\u001b[31m[389]#011train-mae:3586.76#011validation-mae:35059.4\u001b[0m\n",
      "\u001b[31m[390]#011train-mae:3567.82#011validation-mae:35049.7\u001b[0m\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    }
   ],
   "source": [
    "xgb_attached4 = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06915149945650964\n"
     ]
    }
   ],
   "source": [
    "top_mae = 35049.7\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, it is looking like 0.5 is our ideal drop rate, but let's try 0.6 just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# rate_drop has been updated to 0.6 from 0.4\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=30,\n",
    "                        rate_drop=0.6,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same tuning parameters are being used,\n",
    "# but we are re-assigning the xgb reference to 'estimator' now that it has been updated:\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 20, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'eta'      : ContinuousParameter(0.0, 0.5),\n",
    "                                                  'lambda'   : ContinuousParameter(0, 1000),\n",
    "                                                  'max_depth': IntegerParameter(5, 17),\n",
    "                                                  'num_round': IntegerParameter(100, 500),\n",
    "                                                  'min_child_weight': IntegerParameter(1, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 22:54:52 Starting - Preparing the instances for training\n",
      "2019-09-06 22:54:52 Downloading - Downloading input data\n",
      "2019-09-06 22:54:52 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 22:54:52 Uploading - Uploading generated training model\n",
      "2019-09-06 22:54:52 Completed - Training job completed\u001b[31m2019-09-06 22:54:23,730 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,731 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,731 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,734 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,746 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,749 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,749 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,750 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,750 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,751 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:54:23] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,769 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:54:23] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,782 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,782 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,782 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,782 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 22:54:23,782 root         INFO     {'lambda': 771.87621778944, 'objective': 'reg:linear', 'rate_drop': 0.6, 'gamma': 4.0, 'num_round': 453, 'max_depth': 5, 'subsample': 0.8, 'eval_metric': ['mae'], '_tuning_objective_metric': 'validation:mae', 'early_stopping_rounds': 30, 'eta': 0.43286464178692785, 'min_child_weight': 7.0}\u001b[0m\n",
      "\u001b[31m[22:54:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:442564#011validation-mae:432972\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 30 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:379633#011validation-mae:370059\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:326490#011validation-mae:317823\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:280718#011validation-mae:273481\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:241539#011validation-mae:236040\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:209249#011validation-mae:205203\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:184501#011validation-mae:181258\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:163967#011validation-mae:161609\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:146352#011validation-mae:144607\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:131652#011validation-mae:130349\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:119098#011validation-mae:117575\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:109277#011validation-mae:108055\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:100136#011validation-mae:99358.5\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:91855.6#011validation-mae:91816.3\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:85044.6#011validation-mae:86043.8\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:79506.8#011validation-mae:81384.7\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:74427#011validation-mae:76687.7\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:70300#011validation-mae:73684.5\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:66748.8#011validation-mae:71144.5\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:63413.7#011validation-mae:68466.8\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:60891.4#011validation-mae:66780.2\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:58302.7#011validation-mae:65014.5\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:56401.4#011validation-mae:63813.6\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:54601.9#011validation-mae:62774.7\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:53006.1#011validation-mae:61758.8\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:51614.9#011validation-mae:60602.5\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:50275.4#011validation-mae:59760.2\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:49177.9#011validation-mae:58817.2\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:48186.3#011validation-mae:58256.3\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:47240.9#011validation-mae:57587.8\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:46322.4#011validation-mae:56979\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:45610.8#011validation-mae:56478.6\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:44891.3#011validation-mae:55914.4\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:44131.8#011validation-mae:55329.9\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:43469.9#011validation-mae:54830.1\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:42607.6#011validation-mae:54215.7\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:42040.6#011validation-mae:53662.6\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:41468.3#011validation-mae:53277.3\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:40936.5#011validation-mae:52982.5\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:40354.3#011validation-mae:52459.1\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:39889.8#011validation-mae:52075.8\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:39339.3#011validation-mae:51738.8\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:38772.5#011validation-mae:51321.9\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:38147#011validation-mae:50772.8\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:37657.4#011validation-mae:50438.1\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:37183.9#011validation-mae:50122.7\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:36721.2#011validation-mae:49822\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:36323#011validation-mae:49605.6\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:35819.8#011validation-mae:49245.1\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:35433#011validation-mae:48914\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:34905.5#011validation-mae:48568.3\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:34539#011validation-mae:48322\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:34171.6#011validation-mae:48032.6\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:33790.3#011validation-mae:47788.3\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:33384.1#011validation-mae:47431.3\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:33037.7#011validation-mae:47270.1\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:32629.3#011validation-mae:46974.2\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:32330.1#011validation-mae:46770.8\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:31982.8#011validation-mae:46639.3\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:31666.5#011validation-mae:46460.5\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:31336.2#011validation-mae:46194.5\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:31073.6#011validation-mae:46072.1\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:30810#011validation-mae:45932.9\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:30479.5#011validation-mae:45739.6\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:30184.5#011validation-mae:45631.5\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:29856.7#011validation-mae:45389.9\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:29602.7#011validation-mae:45351.7\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:29374.5#011validation-mae:45205.5\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:29028.6#011validation-mae:45010.5\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:28803.5#011validation-mae:44828.7\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:28520.6#011validation-mae:44665.2\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:28222.5#011validation-mae:44505.7\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:27939.5#011validation-mae:44433.6\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:27720#011validation-mae:44289.5\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:27477.1#011validation-mae:44121.3\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:27262.5#011validation-mae:43993.2\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:27099.6#011validation-mae:43909.5\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:26901.9#011validation-mae:43767.8\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:26751.7#011validation-mae:43618.3\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:26545.7#011validation-mae:43457.5\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:26359.8#011validation-mae:43351.5\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:26173.4#011validation-mae:43272.2\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:26015.4#011validation-mae:43156.9\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:25811.6#011validation-mae:42986.7\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:25579.7#011validation-mae:42837.5\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:25354.2#011validation-mae:42688.3\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:25197.3#011validation-mae:42574.1\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:25016.8#011validation-mae:42447.5\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:24810#011validation-mae:42276.4\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:24694#011validation-mae:42148.4\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:24527.7#011validation-mae:41991.2\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:24356.2#011validation-mae:41860.4\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:24197.3#011validation-mae:41778.5\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:24037.2#011validation-mae:41751.3\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:23906.2#011validation-mae:41693.5\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:23724.6#011validation-mae:41634.8\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:23582.5#011validation-mae:41508.6\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:23385.7#011validation-mae:41386.8\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:23200.5#011validation-mae:41265.9\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:23049.2#011validation-mae:41145.8\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:22913.2#011validation-mae:41177.2\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:22759#011validation-mae:41071.1\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:22609#011validation-mae:40953\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:22458.6#011validation-mae:40925.7\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:22272.7#011validation-mae:40819.3\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:22172.6#011validation-mae:40729.6\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:22079.4#011validation-mae:40703\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:21959.9#011validation-mae:40654.4\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:21832.1#011validation-mae:40643.4\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:21709.5#011validation-mae:40529.7\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:21565.9#011validation-mae:40449.9\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:21474.2#011validation-mae:40407.2\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:21329#011validation-mae:40338.1\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:21200.3#011validation-mae:40276.6\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:21102.8#011validation-mae:40239.7\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:20954.7#011validation-mae:40179.6\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:20849.8#011validation-mae:40047.7\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:20727.4#011validation-mae:40019.3\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:20615#011validation-mae:39933.3\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:20479.3#011validation-mae:39894.7\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:20346.2#011validation-mae:39804.1\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:20211.3#011validation-mae:39767.9\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:20081.7#011validation-mae:39715.2\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:20003.6#011validation-mae:39670.9\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:19887.3#011validation-mae:39590.9\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:19782.6#011validation-mae:39504\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:19643.6#011validation-mae:39486.2\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:19541.3#011validation-mae:39473.5\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:19458.9#011validation-mae:39434.2\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:19332.5#011validation-mae:39398.6\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:19232.7#011validation-mae:39322.8\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:19119.4#011validation-mae:39251.3\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:19015#011validation-mae:39242.8\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:18890.3#011validation-mae:39168.1\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:18761.3#011validation-mae:39128.2\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:18666#011validation-mae:39073.1\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:18596.6#011validation-mae:39063\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:18515.4#011validation-mae:39037.3\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:18409.1#011validation-mae:39028.4\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:18334.6#011validation-mae:39002.4\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:18230.8#011validation-mae:39010.1\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:18164.6#011validation-mae:38936.6\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:18070.1#011validation-mae:38879.5\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:18012.4#011validation-mae:38837.1\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:17938#011validation-mae:38790.2\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:17872.7#011validation-mae:38755\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:17798.1#011validation-mae:38717\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:17722.5#011validation-mae:38669.5\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:17617.8#011validation-mae:38646.3\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:17520#011validation-mae:38595.6\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:17477.3#011validation-mae:38601.5\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:17387.5#011validation-mae:38580.9\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:17278.1#011validation-mae:38536\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:17190.4#011validation-mae:38475\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:17110.4#011validation-mae:38458.1\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:17022.6#011validation-mae:38412.1\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:16916#011validation-mae:38385.3\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:16841.7#011validation-mae:38395.7\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:16732.6#011validation-mae:38373.4\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:16664.6#011validation-mae:38368.5\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:16587.4#011validation-mae:38347.1\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:16481.3#011validation-mae:38323.2\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:16421.4#011validation-mae:38288.8\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:16345.7#011validation-mae:38236\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:16254.9#011validation-mae:38216\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:16182.6#011validation-mae:38197.6\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:16114.2#011validation-mae:38155.4\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:16017#011validation-mae:38119.3\u001b[0m\n",
      "\u001b[31m[168]#011train-mae:15943.4#011validation-mae:38101.1\u001b[0m\n",
      "\u001b[31m[169]#011train-mae:15887.5#011validation-mae:38077.8\u001b[0m\n",
      "\u001b[31m[170]#011train-mae:15819.7#011validation-mae:38070.9\u001b[0m\n",
      "\u001b[31m[171]#011train-mae:15766.3#011validation-mae:38063.4\u001b[0m\n",
      "\u001b[31m[172]#011train-mae:15698.6#011validation-mae:38079.1\u001b[0m\n",
      "\u001b[31m[173]#011train-mae:15627.7#011validation-mae:38053.1\u001b[0m\n",
      "\u001b[31m[174]#011train-mae:15549.8#011validation-mae:38056.3\u001b[0m\n",
      "\u001b[31m[175]#011train-mae:15476.7#011validation-mae:38013.6\u001b[0m\n",
      "\u001b[31m[176]#011train-mae:15409.6#011validation-mae:37999.9\u001b[0m\n",
      "\u001b[31m[177]#011train-mae:15366.2#011validation-mae:37993.9\u001b[0m\n",
      "\u001b[31m[178]#011train-mae:15298.2#011validation-mae:37944.9\u001b[0m\n",
      "\u001b[31m[179]#011train-mae:15244.7#011validation-mae:37907.1\u001b[0m\n",
      "\u001b[31m[180]#011train-mae:15166.5#011validation-mae:37862.2\u001b[0m\n",
      "\u001b[31m[181]#011train-mae:15103#011validation-mae:37830.5\u001b[0m\n",
      "\u001b[31m[182]#011train-mae:15040.3#011validation-mae:37827.3\u001b[0m\n",
      "\u001b[31m[183]#011train-mae:14986.9#011validation-mae:37764.8\u001b[0m\n",
      "\u001b[31m[184]#011train-mae:14936.6#011validation-mae:37726.7\u001b[0m\n",
      "\u001b[31m[185]#011train-mae:14871.1#011validation-mae:37733.1\u001b[0m\n",
      "\u001b[31m[186]#011train-mae:14818.5#011validation-mae:37704.1\u001b[0m\n",
      "\u001b[31m[187]#011train-mae:14774.1#011validation-mae:37683.1\u001b[0m\n",
      "\u001b[31m[188]#011train-mae:14727.6#011validation-mae:37666.2\u001b[0m\n",
      "\u001b[31m[189]#011train-mae:14679#011validation-mae:37639.5\u001b[0m\n",
      "\u001b[31m[190]#011train-mae:14626.1#011validation-mae:37597.7\u001b[0m\n",
      "\u001b[31m[191]#011train-mae:14568.4#011validation-mae:37582.2\u001b[0m\n",
      "\u001b[31m[192]#011train-mae:14495.7#011validation-mae:37540.1\u001b[0m\n",
      "\u001b[31m[193]#011train-mae:14427.3#011validation-mae:37495.7\u001b[0m\n",
      "\u001b[31m[194]#011train-mae:14379.6#011validation-mae:37493.1\u001b[0m\n",
      "\u001b[31m[195]#011train-mae:14318.7#011validation-mae:37439.4\u001b[0m\n",
      "\u001b[31m[196]#011train-mae:14270#011validation-mae:37416.4\u001b[0m\n",
      "\u001b[31m[197]#011train-mae:14214.9#011validation-mae:37419\u001b[0m\n",
      "\u001b[31m[198]#011train-mae:14154.1#011validation-mae:37393.7\u001b[0m\n",
      "\u001b[31m[199]#011train-mae:14107.8#011validation-mae:37381.2\u001b[0m\n",
      "\u001b[31m[200]#011train-mae:14068.1#011validation-mae:37384.9\u001b[0m\n",
      "\u001b[31m[201]#011train-mae:13988.4#011validation-mae:37387.4\u001b[0m\n",
      "\u001b[31m[202]#011train-mae:13945#011validation-mae:37401.1\u001b[0m\n",
      "\u001b[31m[203]#011train-mae:13893.1#011validation-mae:37390.9\u001b[0m\n",
      "\u001b[31m[204]#011train-mae:13835.1#011validation-mae:37342.1\u001b[0m\n",
      "\u001b[31m[205]#011train-mae:13767.1#011validation-mae:37333.4\u001b[0m\n",
      "\u001b[31m[206]#011train-mae:13726.6#011validation-mae:37318.3\u001b[0m\n",
      "\u001b[31m[207]#011train-mae:13677.1#011validation-mae:37310\u001b[0m\n",
      "\u001b[31m[208]#011train-mae:13638.4#011validation-mae:37281.3\u001b[0m\n",
      "\u001b[31m[209]#011train-mae:13579.2#011validation-mae:37241\u001b[0m\n",
      "\u001b[31m[210]#011train-mae:13526.2#011validation-mae:37206.7\u001b[0m\n",
      "\u001b[31m[211]#011train-mae:13468.8#011validation-mae:37198.4\u001b[0m\n",
      "\u001b[31m[212]#011train-mae:13419.3#011validation-mae:37220.2\u001b[0m\n",
      "\u001b[31m[213]#011train-mae:13362.3#011validation-mae:37213.9\u001b[0m\n",
      "\u001b[31m[214]#011train-mae:13320.8#011validation-mae:37198.1\u001b[0m\n",
      "\u001b[31m[215]#011train-mae:13259.5#011validation-mae:37178.2\u001b[0m\n",
      "\u001b[31m[216]#011train-mae:13216.9#011validation-mae:37131.1\u001b[0m\n",
      "\u001b[31m[217]#011train-mae:13172.9#011validation-mae:37103\u001b[0m\n",
      "\u001b[31m[218]#011train-mae:13127.9#011validation-mae:37105.6\u001b[0m\n",
      "\u001b[31m[219]#011train-mae:13076.2#011validation-mae:37076.2\u001b[0m\n",
      "\u001b[31m[220]#011train-mae:13035.8#011validation-mae:37057.4\u001b[0m\n",
      "\u001b[31m[221]#011train-mae:12996.5#011validation-mae:37025.9\u001b[0m\n",
      "\u001b[31m[222]#011train-mae:12958.6#011validation-mae:37033.6\u001b[0m\n",
      "\u001b[31m[223]#011train-mae:12910.5#011validation-mae:36994\u001b[0m\n",
      "\u001b[31m[224]#011train-mae:12858.6#011validation-mae:37003.2\u001b[0m\n",
      "\u001b[31m[225]#011train-mae:12797.5#011validation-mae:36989.9\u001b[0m\n",
      "\u001b[31m[226]#011train-mae:12745.1#011validation-mae:36962.8\u001b[0m\n",
      "\u001b[31m[227]#011train-mae:12700.5#011validation-mae:36941.7\u001b[0m\n",
      "\u001b[31m[228]#011train-mae:12667.4#011validation-mae:36931.2\u001b[0m\n",
      "\u001b[31m[229]#011train-mae:12622.1#011validation-mae:36910.7\u001b[0m\n",
      "\u001b[31m[230]#011train-mae:12580.7#011validation-mae:36888.1\u001b[0m\n",
      "\u001b[31m[231]#011train-mae:12538.5#011validation-mae:36848.2\u001b[0m\n",
      "\u001b[31m[232]#011train-mae:12492.4#011validation-mae:36823.5\u001b[0m\n",
      "\u001b[31m[233]#011train-mae:12437.3#011validation-mae:36812.3\u001b[0m\n",
      "\u001b[31m[234]#011train-mae:12383.6#011validation-mae:36781.1\u001b[0m\n",
      "\u001b[31m[235]#011train-mae:12336.2#011validation-mae:36777.3\u001b[0m\n",
      "\u001b[31m[236]#011train-mae:12300.6#011validation-mae:36769.3\u001b[0m\n",
      "\u001b[31m[237]#011train-mae:12250.7#011validation-mae:36766.1\u001b[0m\n",
      "\u001b[31m[238]#011train-mae:12205#011validation-mae:36758.3\u001b[0m\n",
      "\u001b[31m[239]#011train-mae:12168.2#011validation-mae:36733.7\u001b[0m\n",
      "\u001b[31m[240]#011train-mae:12123.5#011validation-mae:36726.4\u001b[0m\n",
      "\u001b[31m[241]#011train-mae:12069.3#011validation-mae:36735.6\u001b[0m\n",
      "\u001b[31m[242]#011train-mae:12018.6#011validation-mae:36726.5\u001b[0m\n",
      "\u001b[31m[243]#011train-mae:11969.3#011validation-mae:36695.5\u001b[0m\n",
      "\u001b[31m[244]#011train-mae:11932.3#011validation-mae:36649.7\u001b[0m\n",
      "\u001b[31m[245]#011train-mae:11893#011validation-mae:36643.8\u001b[0m\n",
      "\u001b[31m[246]#011train-mae:11849.1#011validation-mae:36663.7\u001b[0m\n",
      "\u001b[31m[247]#011train-mae:11798.2#011validation-mae:36660.6\u001b[0m\n",
      "\u001b[31m[248]#011train-mae:11737.4#011validation-mae:36613.5\u001b[0m\n",
      "\u001b[31m[249]#011train-mae:11698.1#011validation-mae:36600.1\u001b[0m\n",
      "\u001b[31m[250]#011train-mae:11662#011validation-mae:36557.7\u001b[0m\n",
      "\u001b[31m[251]#011train-mae:11603.1#011validation-mae:36532.9\u001b[0m\n",
      "\u001b[31m[252]#011train-mae:11572.9#011validation-mae:36509.2\u001b[0m\n",
      "\u001b[31m[253]#011train-mae:11540.1#011validation-mae:36489.5\u001b[0m\n",
      "\u001b[31m[254]#011train-mae:11508.2#011validation-mae:36468.8\u001b[0m\n",
      "\u001b[31m[255]#011train-mae:11472.1#011validation-mae:36449.3\u001b[0m\n",
      "\u001b[31m[256]#011train-mae:11432.3#011validation-mae:36418\u001b[0m\n",
      "\u001b[31m[257]#011train-mae:11393.5#011validation-mae:36386.9\u001b[0m\n",
      "\u001b[31m[258]#011train-mae:11338.7#011validation-mae:36363\u001b[0m\n",
      "\u001b[31m[259]#011train-mae:11310.2#011validation-mae:36360.9\u001b[0m\n",
      "\u001b[31m[260]#011train-mae:11270.9#011validation-mae:36336.9\u001b[0m\n",
      "\u001b[31m[261]#011train-mae:11226.1#011validation-mae:36312.7\u001b[0m\n",
      "\u001b[31m[262]#011train-mae:11192.6#011validation-mae:36265.1\u001b[0m\n",
      "\u001b[31m[263]#011train-mae:11154.2#011validation-mae:36261.5\u001b[0m\n",
      "\u001b[31m[264]#011train-mae:11127.4#011validation-mae:36240.6\u001b[0m\n",
      "\u001b[31m[265]#011train-mae:11077.8#011validation-mae:36244.4\u001b[0m\n",
      "\u001b[31m[266]#011train-mae:11034.9#011validation-mae:36239.9\u001b[0m\n",
      "\u001b[31m[267]#011train-mae:11000.6#011validation-mae:36237.3\u001b[0m\n",
      "\u001b[31m[268]#011train-mae:10963.8#011validation-mae:36242.7\u001b[0m\n",
      "\u001b[31m[269]#011train-mae:10920.5#011validation-mae:36212.7\u001b[0m\n",
      "\u001b[31m[270]#011train-mae:10875.7#011validation-mae:36208\u001b[0m\n",
      "\u001b[31m[271]#011train-mae:10832.9#011validation-mae:36186.5\u001b[0m\n",
      "\u001b[31m[272]#011train-mae:10800#011validation-mae:36198.4\u001b[0m\n",
      "\u001b[31m[273]#011train-mae:10768.4#011validation-mae:36185.3\u001b[0m\n",
      "\u001b[31m[274]#011train-mae:10739.3#011validation-mae:36165.9\u001b[0m\n",
      "\u001b[31m[275]#011train-mae:10703#011validation-mae:36180.9\u001b[0m\n",
      "\u001b[31m[276]#011train-mae:10667.3#011validation-mae:36184.4\u001b[0m\n",
      "\u001b[31m[277]#011train-mae:10633.5#011validation-mae:36149.5\u001b[0m\n",
      "\u001b[31m[278]#011train-mae:10588.1#011validation-mae:36111.5\u001b[0m\n",
      "\u001b[31m[279]#011train-mae:10553.4#011validation-mae:36111.2\u001b[0m\n",
      "\u001b[31m[280]#011train-mae:10522#011validation-mae:36120.7\u001b[0m\n",
      "\u001b[31m[281]#011train-mae:10493.1#011validation-mae:36122.6\u001b[0m\n",
      "\u001b[31m[282]#011train-mae:10461#011validation-mae:36117.1\u001b[0m\n",
      "\u001b[31m[283]#011train-mae:10427.6#011validation-mae:36094.5\u001b[0m\n",
      "\u001b[31m[284]#011train-mae:10390.5#011validation-mae:36103.1\u001b[0m\n",
      "\u001b[31m[285]#011train-mae:10360.5#011validation-mae:36080.1\u001b[0m\n",
      "\u001b[31m[286]#011train-mae:10321.5#011validation-mae:36067.6\u001b[0m\n",
      "\u001b[31m[287]#011train-mae:10287.8#011validation-mae:36037.9\u001b[0m\n",
      "\u001b[31m[288]#011train-mae:10245.9#011validation-mae:36042.9\u001b[0m\n",
      "\u001b[31m[289]#011train-mae:10204.2#011validation-mae:36042.9\u001b[0m\n",
      "\u001b[31m[290]#011train-mae:10165.7#011validation-mae:36005.3\u001b[0m\n",
      "\u001b[31m[291]#011train-mae:10136#011validation-mae:35964.9\u001b[0m\n",
      "\u001b[31m[292]#011train-mae:10104#011validation-mae:35939.8\u001b[0m\n",
      "\u001b[31m[293]#011train-mae:10070.3#011validation-mae:35936.9\u001b[0m\n",
      "\u001b[31m[294]#011train-mae:10033.3#011validation-mae:35905.2\u001b[0m\n",
      "\u001b[31m[295]#011train-mae:10007.4#011validation-mae:35891.1\u001b[0m\n",
      "\u001b[31m[296]#011train-mae:9972.71#011validation-mae:35888.7\u001b[0m\n",
      "\u001b[31m[297]#011train-mae:9935.64#011validation-mae:35863.7\u001b[0m\n",
      "\u001b[31m[298]#011train-mae:9898.12#011validation-mae:35857\u001b[0m\n",
      "\u001b[31m[299]#011train-mae:9866.46#011validation-mae:35860.7\u001b[0m\n",
      "\u001b[31m[300]#011train-mae:9828.72#011validation-mae:35831\u001b[0m\n",
      "\u001b[31m[301]#011train-mae:9784.1#011validation-mae:35817\u001b[0m\n",
      "\u001b[31m[302]#011train-mae:9752.34#011validation-mae:35804.4\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:9723.41#011validation-mae:35789.5\u001b[0m\n",
      "\u001b[31m[304]#011train-mae:9682.87#011validation-mae:35822.4\u001b[0m\n",
      "\u001b[31m[305]#011train-mae:9646.47#011validation-mae:35818\u001b[0m\n",
      "\u001b[31m[306]#011train-mae:9618.8#011validation-mae:35828.8\u001b[0m\n",
      "\u001b[31m[307]#011train-mae:9586.28#011validation-mae:35821.2\u001b[0m\n",
      "\u001b[31m[308]#011train-mae:9548.17#011validation-mae:35814\u001b[0m\n",
      "\u001b[31m[309]#011train-mae:9516.86#011validation-mae:35813.1\u001b[0m\n",
      "\u001b[31m[310]#011train-mae:9483.84#011validation-mae:35821\u001b[0m\n",
      "\u001b[31m[311]#011train-mae:9460.84#011validation-mae:35844.1\u001b[0m\n",
      "\u001b[31m[312]#011train-mae:9428.5#011validation-mae:35846.6\u001b[0m\n",
      "\u001b[31m[313]#011train-mae:9402.5#011validation-mae:35847.2\u001b[0m\n",
      "\u001b[31m[314]#011train-mae:9376.57#011validation-mae:35830.1\u001b[0m\n",
      "\u001b[31m[315]#011train-mae:9343.64#011validation-mae:35834.8\u001b[0m\n",
      "\u001b[31m[316]#011train-mae:9310.77#011validation-mae:35828.7\u001b[0m\n",
      "\u001b[31m[317]#011train-mae:9278.85#011validation-mae:35823.6\u001b[0m\n",
      "\u001b[31m[318]#011train-mae:9253.13#011validation-mae:35811.5\u001b[0m\n",
      "\u001b[31m[319]#011train-mae:9220.23#011validation-mae:35792.1\u001b[0m\n",
      "\u001b[31m[320]#011train-mae:9192.54#011validation-mae:35784\u001b[0m\n",
      "\u001b[31m[321]#011train-mae:9168.23#011validation-mae:35750.9\u001b[0m\n",
      "\u001b[31m[322]#011train-mae:9146.81#011validation-mae:35754.8\u001b[0m\n",
      "\u001b[31m[323]#011train-mae:9107.02#011validation-mae:35720.7\u001b[0m\n",
      "\u001b[31m[324]#011train-mae:9075.33#011validation-mae:35720.5\u001b[0m\n",
      "\u001b[31m[325]#011train-mae:9032.88#011validation-mae:35704.4\u001b[0m\n",
      "\u001b[31m[326]#011train-mae:9007.37#011validation-mae:35724.4\u001b[0m\n",
      "\u001b[31m[327]#011train-mae:8974.56#011validation-mae:35693.6\u001b[0m\n",
      "\u001b[31m[328]#011train-mae:8963.01#011validation-mae:35713.2\u001b[0m\n",
      "\u001b[31m[329]#011train-mae:8939.82#011validation-mae:35686.3\u001b[0m\n",
      "\u001b[31m[330]#011train-mae:8925.97#011validation-mae:35678.2\u001b[0m\n",
      "\u001b[31m[331]#011train-mae:8908.34#011validation-mae:35680.6\u001b[0m\n",
      "\u001b[31m[332]#011train-mae:8863.65#011validation-mae:35661.7\u001b[0m\n",
      "\u001b[31m[333]#011train-mae:8840.7#011validation-mae:35642.4\u001b[0m\n",
      "\u001b[31m[334]#011train-mae:8816.97#011validation-mae:35623.4\u001b[0m\n",
      "\u001b[31m[335]#011train-mae:8781.9#011validation-mae:35614.6\u001b[0m\n",
      "\u001b[31m[336]#011train-mae:8758.41#011validation-mae:35615.1\u001b[0m\n",
      "\u001b[31m[337]#011train-mae:8728.73#011validation-mae:35631.2\u001b[0m\n",
      "\u001b[31m[338]#011train-mae:8710.67#011validation-mae:35651.2\u001b[0m\n",
      "\u001b[31m[339]#011train-mae:8683.36#011validation-mae:35667.1\u001b[0m\n",
      "\u001b[31m[340]#011train-mae:8646.54#011validation-mae:35668.8\u001b[0m\n",
      "\u001b[31m[341]#011train-mae:8614.67#011validation-mae:35657.2\u001b[0m\n",
      "\u001b[31m[342]#011train-mae:8577.55#011validation-mae:35627.3\u001b[0m\n",
      "\u001b[31m[343]#011train-mae:8552.24#011validation-mae:35618.1\u001b[0m\n",
      "\u001b[31m[344]#011train-mae:8528.17#011validation-mae:35622.2\u001b[0m\n",
      "\u001b[31m[345]#011train-mae:8501.11#011validation-mae:35622.3\u001b[0m\n",
      "\u001b[31m[346]#011train-mae:8475.8#011validation-mae:35610.4\u001b[0m\n",
      "\u001b[31m[347]#011train-mae:8455.09#011validation-mae:35608.4\u001b[0m\n",
      "\u001b[31m[348]#011train-mae:8424.47#011validation-mae:35580.9\u001b[0m\n",
      "\u001b[31m[349]#011train-mae:8405.3#011validation-mae:35570.5\u001b[0m\n",
      "\u001b[31m[350]#011train-mae:8381.71#011validation-mae:35539.2\u001b[0m\n",
      "\u001b[31m[351]#011train-mae:8354.21#011validation-mae:35534.8\u001b[0m\n",
      "\u001b[31m[352]#011train-mae:8329.29#011validation-mae:35516.6\u001b[0m\n",
      "\u001b[31m[353]#011train-mae:8313.36#011validation-mae:35524.5\u001b[0m\n",
      "\u001b[31m[354]#011train-mae:8284.79#011validation-mae:35506.8\u001b[0m\n",
      "\u001b[31m[355]#011train-mae:8259.32#011validation-mae:35488.3\u001b[0m\n",
      "\u001b[31m[356]#011train-mae:8230.71#011validation-mae:35492\u001b[0m\n",
      "\u001b[31m[357]#011train-mae:8191.8#011validation-mae:35493.5\u001b[0m\n",
      "\u001b[31m[358]#011train-mae:8170.21#011validation-mae:35461.1\u001b[0m\n",
      "\u001b[31m[359]#011train-mae:8151.51#011validation-mae:35469.4\u001b[0m\n",
      "\u001b[31m[360]#011train-mae:8126.48#011validation-mae:35462.9\u001b[0m\n",
      "\u001b[31m[361]#011train-mae:8096.08#011validation-mae:35454\u001b[0m\n",
      "\u001b[31m[362]#011train-mae:8079.31#011validation-mae:35449.5\u001b[0m\n",
      "\u001b[31m[363]#011train-mae:8059.65#011validation-mae:35447.2\u001b[0m\n",
      "\u001b[31m[364]#011train-mae:8025.08#011validation-mae:35452.9\u001b[0m\n",
      "\u001b[31m[365]#011train-mae:7998.07#011validation-mae:35449.2\u001b[0m\n",
      "\u001b[31m[366]#011train-mae:7973.32#011validation-mae:35452\u001b[0m\n",
      "\u001b[31m[367]#011train-mae:7944.27#011validation-mae:35435\u001b[0m\n",
      "\u001b[31m[368]#011train-mae:7919.24#011validation-mae:35430.1\u001b[0m\n",
      "\u001b[31m[369]#011train-mae:7892.73#011validation-mae:35422.7\u001b[0m\n",
      "\u001b[31m[370]#011train-mae:7874.64#011validation-mae:35431.3\u001b[0m\n",
      "\u001b[31m[371]#011train-mae:7852#011validation-mae:35416.2\u001b[0m\n",
      "\u001b[31m[372]#011train-mae:7824.66#011validation-mae:35397.7\u001b[0m\n",
      "\u001b[31m[373]#011train-mae:7806.83#011validation-mae:35387.6\u001b[0m\n",
      "\u001b[31m[374]#011train-mae:7785.33#011validation-mae:35381\u001b[0m\n",
      "\u001b[31m[375]#011train-mae:7756.77#011validation-mae:35392.8\u001b[0m\n",
      "\u001b[31m[376]#011train-mae:7741.32#011validation-mae:35379.4\u001b[0m\n",
      "\u001b[31m[377]#011train-mae:7723.8#011validation-mae:35383.2\u001b[0m\n",
      "\u001b[31m[378]#011train-mae:7700.45#011validation-mae:35363.7\u001b[0m\n",
      "\u001b[31m[379]#011train-mae:7678.5#011validation-mae:35360.8\u001b[0m\n",
      "\u001b[31m[380]#011train-mae:7665.33#011validation-mae:35337.6\u001b[0m\n",
      "\u001b[31m[381]#011train-mae:7643.28#011validation-mae:35339.2\u001b[0m\n",
      "\u001b[31m[382]#011train-mae:7620.65#011validation-mae:35335.3\u001b[0m\n",
      "\u001b[31m[383]#011train-mae:7605.07#011validation-mae:35314.9\u001b[0m\n",
      "\u001b[31m[384]#011train-mae:7578.24#011validation-mae:35305.3\u001b[0m\n",
      "\u001b[31m[385]#011train-mae:7555.08#011validation-mae:35306.3\u001b[0m\n",
      "\u001b[31m[386]#011train-mae:7533.12#011validation-mae:35324.1\u001b[0m\n",
      "\u001b[31m[387]#011train-mae:7514.36#011validation-mae:35335.4\u001b[0m\n",
      "\u001b[31m[388]#011train-mae:7495.93#011validation-mae:35310.3\u001b[0m\n",
      "\u001b[31m[389]#011train-mae:7462.75#011validation-mae:35301.1\u001b[0m\n",
      "\u001b[31m[390]#011train-mae:7439.2#011validation-mae:35305.7\u001b[0m\n",
      "\u001b[31m[391]#011train-mae:7421.85#011validation-mae:35307.1\u001b[0m\n",
      "\u001b[31m[392]#011train-mae:7396.49#011validation-mae:35318\u001b[0m\n",
      "\u001b[31m[393]#011train-mae:7368.24#011validation-mae:35305.9\u001b[0m\n",
      "\u001b[31m[394]#011train-mae:7345.28#011validation-mae:35296.8\u001b[0m\n",
      "\u001b[31m[395]#011train-mae:7319.39#011validation-mae:35310.8\u001b[0m\n",
      "\u001b[31m[396]#011train-mae:7293.43#011validation-mae:35311.1\u001b[0m\n",
      "\u001b[31m[397]#011train-mae:7269.62#011validation-mae:35297\u001b[0m\n",
      "\u001b[31m[398]#011train-mae:7252.21#011validation-mae:35291.9\u001b[0m\n",
      "\u001b[31m[399]#011train-mae:7226.85#011validation-mae:35286\u001b[0m\n",
      "\u001b[31m[400]#011train-mae:7201.29#011validation-mae:35283.4\u001b[0m\n",
      "\u001b[31m[401]#011train-mae:7175.57#011validation-mae:35270.2\u001b[0m\n",
      "\u001b[31m[402]#011train-mae:7154.28#011validation-mae:35266.9\u001b[0m\n",
      "\u001b[31m[403]#011train-mae:7141.23#011validation-mae:35262.8\u001b[0m\n",
      "\u001b[31m[404]#011train-mae:7118.15#011validation-mae:35261.9\u001b[0m\n",
      "\u001b[31m[405]#011train-mae:7099.74#011validation-mae:35259.9\u001b[0m\n",
      "\u001b[31m[406]#011train-mae:7087.66#011validation-mae:35258.6\u001b[0m\n",
      "\u001b[31m[407]#011train-mae:7064.24#011validation-mae:35254.1\u001b[0m\n",
      "\u001b[31m[408]#011train-mae:7048.34#011validation-mae:35256\u001b[0m\n",
      "\u001b[31m[409]#011train-mae:7031.93#011validation-mae:35265.1\u001b[0m\n",
      "\u001b[31m[410]#011train-mae:7012.9#011validation-mae:35260.9\u001b[0m\n",
      "\u001b[31m[411]#011train-mae:6984.97#011validation-mae:35252.1\u001b[0m\n",
      "\u001b[31m[412]#011train-mae:6961.81#011validation-mae:35251.6\u001b[0m\n",
      "\u001b[31m[413]#011train-mae:6936.33#011validation-mae:35241.7\u001b[0m\n",
      "\u001b[31m[414]#011train-mae:6913.89#011validation-mae:35241.2\u001b[0m\n",
      "\u001b[31m[415]#011train-mae:6884.51#011validation-mae:35221.9\u001b[0m\n",
      "\u001b[31m[416]#011train-mae:6868.18#011validation-mae:35212.3\u001b[0m\n",
      "\u001b[31m[417]#011train-mae:6847.11#011validation-mae:35214.7\u001b[0m\n",
      "\u001b[31m[418]#011train-mae:6839.67#011validation-mae:35213.2\u001b[0m\n",
      "\u001b[31m[419]#011train-mae:6822.6#011validation-mae:35201.5\u001b[0m\n",
      "\u001b[31m[420]#011train-mae:6802.62#011validation-mae:35197.1\u001b[0m\n",
      "\u001b[31m[421]#011train-mae:6784.08#011validation-mae:35202.6\u001b[0m\n",
      "\u001b[31m[422]#011train-mae:6760.42#011validation-mae:35170.2\u001b[0m\n",
      "\u001b[31m[423]#011train-mae:6742.02#011validation-mae:35168.9\u001b[0m\n",
      "\u001b[31m[424]#011train-mae:6724.8#011validation-mae:35174.7\u001b[0m\n",
      "\u001b[31m[425]#011train-mae:6705.92#011validation-mae:35175.6\u001b[0m\n",
      "\u001b[31m[426]#011train-mae:6682.35#011validation-mae:35190.4\u001b[0m\n",
      "\u001b[31m[427]#011train-mae:6660.76#011validation-mae:35188.8\u001b[0m\n",
      "\u001b[31m[428]#011train-mae:6640.17#011validation-mae:35185.9\u001b[0m\n",
      "\u001b[31m[429]#011train-mae:6618.86#011validation-mae:35175.5\u001b[0m\n",
      "\u001b[31m[430]#011train-mae:6599.36#011validation-mae:35168.6\u001b[0m\n",
      "\u001b[31m[431]#011train-mae:6579.37#011validation-mae:35178.5\u001b[0m\n",
      "\u001b[31m[432]#011train-mae:6564.31#011validation-mae:35170.6\u001b[0m\n",
      "\u001b[31m[433]#011train-mae:6550.99#011validation-mae:35166.8\u001b[0m\n",
      "\u001b[31m[434]#011train-mae:6531.14#011validation-mae:35163.9\u001b[0m\n",
      "\u001b[31m[435]#011train-mae:6508.87#011validation-mae:35160.3\u001b[0m\n",
      "\u001b[31m[436]#011train-mae:6491.93#011validation-mae:35156.1\u001b[0m\n",
      "\u001b[31m[437]#011train-mae:6474.11#011validation-mae:35145.5\u001b[0m\n",
      "\u001b[31m[438]#011train-mae:6461.96#011validation-mae:35126.8\u001b[0m\n",
      "\u001b[31m[439]#011train-mae:6440.84#011validation-mae:35104.9\u001b[0m\n",
      "\u001b[31m[440]#011train-mae:6424.21#011validation-mae:35107.7\u001b[0m\n",
      "\u001b[31m[441]#011train-mae:6405.46#011validation-mae:35099.5\u001b[0m\n",
      "\u001b[31m[442]#011train-mae:6382.49#011validation-mae:35086.3\u001b[0m\n",
      "\u001b[31m[443]#011train-mae:6367.17#011validation-mae:35078.2\u001b[0m\n",
      "\u001b[31m[444]#011train-mae:6349.96#011validation-mae:35077.2\u001b[0m\n",
      "\u001b[31m[445]#011train-mae:6331.89#011validation-mae:35076.5\u001b[0m\n",
      "\u001b[31m[446]#011train-mae:6313.46#011validation-mae:35072.1\u001b[0m\n",
      "\u001b[31m[447]#011train-mae:6299.86#011validation-mae:35089.2\u001b[0m\n",
      "\u001b[31m[448]#011train-mae:6282.15#011validation-mae:35084.7\u001b[0m\n",
      "\u001b[31m[449]#011train-mae:6269.24#011validation-mae:35085.3\u001b[0m\n",
      "\u001b[31m[450]#011train-mae:6253.74#011validation-mae:35076.7\u001b[0m\n",
      "\u001b[31m[451]#011train-mae:6236.68#011validation-mae:35078.6\u001b[0m\n",
      "\u001b[31m[452]#011train-mae:6208.22#011validation-mae:35078.9\u001b[0m\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "xgb_attached5 = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06920910975799954\n"
     ]
    }
   ],
   "source": [
    "top_mae = 35078.9\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It looks like we have found our optimal hyperparameters with a dropout rate of 0.5:\n",
    "{'subsample': 0.8, 'early_stopping_rounds': 10, 'eval_metric': ['mae'], 'eta': 0.4539415243497953, 'gamma': 4.0, 'max_depth': 14, '_tuning_objective_metric': 'validation:mae', 'objective': 'reg:linear', 'min_child_weight': 10.0, 'lambda': 115.80246104977371, 'rate_drop': 0.5, 'num_round': 363}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for this model\n",
    "# rate_drop has been updated to 0.5 from 0.6\n",
    "xgb.set_hyperparameters(max_depth=14,\n",
    "                        eta=0.45394,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=10,\n",
    "                        subsample=0.8,\n",
    "                        early_stopping_rounds=30,\n",
    "                        rate_drop=0.5,\n",
    "                        num_round=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same tuning parameters are being used,\n",
    "# but we are re-assigning the xgb reference to 'estimator' now that it has been updated:\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner( estimator = xgb,\n",
    "                                                objective_metric_name = 'validation:mae',\n",
    "                                                objective_type = 'Minimize',\n",
    "                                                max_jobs = 10, \n",
    "                                                max_parallel_jobs = 3, \n",
    "                                                hyperparameter_ranges = {\n",
    "                                                  'lambda'   : ContinuousParameter(100, 200),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-06 23:58:20 Starting - Preparing the instances for training\n",
      "2019-09-06 23:58:20 Downloading - Downloading input data\n",
      "2019-09-06 23:58:20 Training - Training image download completed. Training in progress.\n",
      "2019-09-06 23:58:20 Uploading - Uploading generated training model\n",
      "2019-09-06 23:58:20 Completed - Training job completed\u001b[31m2019-09-06 23:58:10,417 sagemaker-containers INFO     Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,417 sagemaker-containers INFO     Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,418 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value validation:mae to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,421 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,433 sagemaker_xgboost_container.training INFO     Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,436 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,436 root         ERROR    649000.0,-2.59673810005188,0.8944152593612671,-0.6997796297073364,-0.6050152778625488,1.1100763082504272,-0.9957510232925416,-1.3983920812606812,0.2752825915813446,-0.9857340455055236,0.23114825785160065,-0.04536552354693413,-0.30214813351631165,-0.0709041953086853,0.1358107626438141,-0.029074938967823982,0.545179545879364,-0.16357740759849548,0.6112319827079773,0.6417662501335144,-0.8000364899635315,-0.6074079871177673,-0.761078953742981,-0.7988041639328003,0.3164117932319641,0.6087758541107178,-0.01725584827363491,-0.1066948175430298,0.0060977740213274964,-0.017247438430786133,-0.13264071941375732,-0.27493926882743835,0.014118960127234459,-0.028357185423374176,-0.12276042997837068,-0.044906001538038254,0.01663091406226158,0.07447211444377899,-0.030445732176303864,0.08804729580879211,0.01564594730734825,-0.08368896692991258,-0.03306031972169876,-0.02193128876388073,-0.011020347476005554,0.028213648125529286,0.05316627398133278,0.04557787999510765,-0.01063720975071192,0.06940343976020813,-0.06346318870782852,0.05088774487376213,-0.04973801225423813,0.028962563723325733,0.028376210480928418,0.01083255186676979,0.003692733589559794,0.00713842548429966,-0.005449775606393814,0.017252538353204727,0.01987201347947121,-0.018312960863113403,0.020311800763010982,-0.003589545609429478,-0.002454450121149421,-0.020161433145403862,0.0012618748005479574,0.00997318420559168,-0.0009753929916769266,-0.02228300087153912,-0.00349371787160635,-0.009372037835419178,-0.00038852708530612284,-0.0023808369878679514,-0.007743273861706256,-0.0050904760137200356,-0.0007680385024286808,-0.16891485452651978,0.06714918464422226,0.14912228286266327,-0.3556605875492096,-0.3055618107318878,-0.4489739239215851,0.07281673699617386,-0.0915629267692566,-0.08688820153474808\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,437 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,437 root         ERROR    350000.0,3.863768815994263,0.5416293740272522,0.3424359560012817,-2.946662425994873,0.2734585404396057,2.3109805583953857,-0.5730682611465454,-0.504883348941803,0.8917572498321533,0.3146991729736328,-0.15195046365261078,0.785619854927063,-0.00090096885105595,-0.051579974591732025,0.0712490975856781,1.1994010210037231,-1.6014878749847412,0.7757213115692139,0.18136478960514069,0.40525272488594055,-0.9157418608665466,-0.4410257339477539,1.1309773921966553,0.737374484539032,0.13452066481113434,-0.7013677358627319,-0.7751986384391785,-0.607075035572052,0.44387537240982056,-0.3131888210773468,0.20158159732818606,-0.07598249614238739,0.923827588558197,0.1723061501979828,-0.29406502842903137,0.10347031056880952,0.09648262709379196,-0.02042094245553017,0.2838054299354553,0.022683834657073017,0.0010468607069924474,0.1008548140525818,-0.07457905262708664,0.14862020313739774,0.0803658589720726,0.08995367586612701,0.032955437898635864,-0.014131385833024982,0.1063583493232727,-0.05455930531024933,0.0012890638317912815,-0.036257702857255936,-0.032795358449220664,0.05154741555452347,-0.05519497767090797,-0.09301582723855972,0.09628242999315262,0.07656985521316527,0.04908391460776329,-0.025134462863206863,-0.1424405425786972,-0.019051194190979004,-0.06313177198171616,-0.041909009218215935,0.017593864351511,0.10095301270484924,-0.06551122665405272,0.023182524368166924,0.05789417400956154,-0.049904409795999534,0.009507807902991772,0.007628106046468019,0.007874961942434311,0.0003760497784242034,-0.005329986568540336,-7.453819853253664e-05,0.18988832831382751,0.2108508199453354,0.7519832849502563,-0.28855130076408386,0.18321268260478973,-0.9632862210273744,0.011171185411512852,-0.281840980052948,0.644162118434906\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,437 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[23:58:10] 467x85 matrix with 39695 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,457 root         INFO     Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[23:58:10] 201x85 matrix with 17085 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,471 root         INFO     Single node training.\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,471 root         INFO     Setting up HPO optimized metric to be : mae\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,471 root         INFO     Train matrix has 467 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,471 root         INFO     Validation matrix has 201 rows\u001b[0m\n",
      "\u001b[31m2019-09-06 23:58:10,472 root         INFO     {'min_child_weight': 10.0, 'gamma': 4.0, 'rate_drop': 0.5, 'objective': 'reg:linear', 'lambda': 113.6658465747104, 'num_round': 400, 'max_depth': 14, 'eval_metric': ['mae'], 'subsample': 0.8, 'eta': 0.45394, '_tuning_objective_metric': 'validation:mae', 'early_stopping_rounds': 30}\u001b[0m\n",
      "\u001b[31m[23:58:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-mae:335244#011validation-mae:326372\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-mae' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-mae hasn't improved in 30 rounds.\u001b[0m\n",
      "\u001b[31m[1]#011train-mae:220877#011validation-mae:216586\u001b[0m\n",
      "\u001b[31m[2]#011train-mae:155800#011validation-mae:153377\u001b[0m\n",
      "\u001b[31m[3]#011train-mae:112717#011validation-mae:111565\u001b[0m\n",
      "\u001b[31m[4]#011train-mae:85725.7#011validation-mae:89035.1\u001b[0m\n",
      "\u001b[31m[5]#011train-mae:68759#011validation-mae:73628.8\u001b[0m\n",
      "\u001b[31m[6]#011train-mae:58847.4#011validation-mae:65442.6\u001b[0m\n",
      "\u001b[31m[7]#011train-mae:51863.2#011validation-mae:60657.8\u001b[0m\n",
      "\u001b[31m[8]#011train-mae:46527.7#011validation-mae:57088\u001b[0m\n",
      "\u001b[31m[9]#011train-mae:43120.4#011validation-mae:54803.4\u001b[0m\n",
      "\u001b[31m[10]#011train-mae:40221.4#011validation-mae:53108.5\u001b[0m\n",
      "\u001b[31m[11]#011train-mae:38059.2#011validation-mae:50328\u001b[0m\n",
      "\u001b[31m[12]#011train-mae:36224.1#011validation-mae:49206.3\u001b[0m\n",
      "\u001b[31m[13]#011train-mae:34227.5#011validation-mae:47988.9\u001b[0m\n",
      "\u001b[31m[14]#011train-mae:32111.4#011validation-mae:46393.6\u001b[0m\n",
      "\u001b[31m[15]#011train-mae:30699.2#011validation-mae:45531.8\u001b[0m\n",
      "\u001b[31m[16]#011train-mae:29460.9#011validation-mae:44612.9\u001b[0m\n",
      "\u001b[31m[17]#011train-mae:28303#011validation-mae:43600.8\u001b[0m\n",
      "\u001b[31m[18]#011train-mae:27230.3#011validation-mae:42949\u001b[0m\n",
      "\u001b[31m[19]#011train-mae:26150.6#011validation-mae:42218.5\u001b[0m\n",
      "\u001b[31m[20]#011train-mae:25197.6#011validation-mae:41723.2\u001b[0m\n",
      "\u001b[31m[21]#011train-mae:24238.2#011validation-mae:41117.3\u001b[0m\n",
      "\u001b[31m[22]#011train-mae:23481.6#011validation-mae:40674\u001b[0m\n",
      "\u001b[31m[23]#011train-mae:22755.3#011validation-mae:40193.8\u001b[0m\n",
      "\u001b[31m[24]#011train-mae:22084.9#011validation-mae:39851.7\u001b[0m\n",
      "\u001b[31m[25]#011train-mae:21306.6#011validation-mae:39615.8\u001b[0m\n",
      "\u001b[31m[26]#011train-mae:20623.3#011validation-mae:39155.1\u001b[0m\n",
      "\u001b[31m[27]#011train-mae:20018.7#011validation-mae:39042.2\u001b[0m\n",
      "\u001b[31m[28]#011train-mae:19432.5#011validation-mae:38874.2\u001b[0m\n",
      "\u001b[31m[29]#011train-mae:18893#011validation-mae:38709.9\u001b[0m\n",
      "\u001b[31m[30]#011train-mae:18447#011validation-mae:38629.9\u001b[0m\n",
      "\u001b[31m[31]#011train-mae:17985.3#011validation-mae:38508.3\u001b[0m\n",
      "\u001b[31m[32]#011train-mae:17518.2#011validation-mae:38228.7\u001b[0m\n",
      "\u001b[31m[33]#011train-mae:17042.5#011validation-mae:38119.1\u001b[0m\n",
      "\u001b[31m[34]#011train-mae:16647.6#011validation-mae:37943.9\u001b[0m\n",
      "\u001b[31m[35]#011train-mae:16253#011validation-mae:37722.2\u001b[0m\n",
      "\u001b[31m[36]#011train-mae:15832.2#011validation-mae:37521.5\u001b[0m\n",
      "\u001b[31m[37]#011train-mae:15483.6#011validation-mae:37277.4\u001b[0m\n",
      "\u001b[31m[38]#011train-mae:15109.8#011validation-mae:37101.2\u001b[0m\n",
      "\u001b[31m[39]#011train-mae:14760.9#011validation-mae:36828.1\u001b[0m\n",
      "\u001b[31m[40]#011train-mae:14471.8#011validation-mae:36999\u001b[0m\n",
      "\u001b[31m[41]#011train-mae:14207.7#011validation-mae:36780\u001b[0m\n",
      "\u001b[31m[42]#011train-mae:13872.1#011validation-mae:36685.6\u001b[0m\n",
      "\u001b[31m[43]#011train-mae:13562.6#011validation-mae:36615\u001b[0m\n",
      "\u001b[31m[44]#011train-mae:13328.7#011validation-mae:36561.2\u001b[0m\n",
      "\u001b[31m[45]#011train-mae:13101.5#011validation-mae:36435.4\u001b[0m\n",
      "\u001b[31m[46]#011train-mae:12817#011validation-mae:36471.3\u001b[0m\n",
      "\u001b[31m[47]#011train-mae:12528.9#011validation-mae:36347.1\u001b[0m\n",
      "\u001b[31m[48]#011train-mae:12290.3#011validation-mae:36233.3\u001b[0m\n",
      "\u001b[31m[49]#011train-mae:12084.3#011validation-mae:36099.2\u001b[0m\n",
      "\u001b[31m[50]#011train-mae:11771.8#011validation-mae:35980.9\u001b[0m\n",
      "\u001b[31m[51]#011train-mae:11596.4#011validation-mae:35828.8\u001b[0m\n",
      "\u001b[31m[52]#011train-mae:11340.2#011validation-mae:35662.8\u001b[0m\n",
      "\u001b[31m[53]#011train-mae:11136.7#011validation-mae:35586.2\u001b[0m\n",
      "\u001b[31m[54]#011train-mae:10934.4#011validation-mae:35538.6\u001b[0m\n",
      "\u001b[31m[55]#011train-mae:10715.9#011validation-mae:35533.2\u001b[0m\n",
      "\u001b[31m[56]#011train-mae:10464#011validation-mae:35418.2\u001b[0m\n",
      "\u001b[31m[57]#011train-mae:10357#011validation-mae:35455\u001b[0m\n",
      "\u001b[31m[58]#011train-mae:10157.8#011validation-mae:35355.9\u001b[0m\n",
      "\u001b[31m[59]#011train-mae:9974.06#011validation-mae:35383\u001b[0m\n",
      "\u001b[31m[60]#011train-mae:9792.03#011validation-mae:35358.5\u001b[0m\n",
      "\u001b[31m[61]#011train-mae:9665.97#011validation-mae:35256.7\u001b[0m\n",
      "\u001b[31m[62]#011train-mae:9486.58#011validation-mae:35118.1\u001b[0m\n",
      "\u001b[31m[63]#011train-mae:9303.24#011validation-mae:35128.8\u001b[0m\n",
      "\u001b[31m[64]#011train-mae:9126.54#011validation-mae:35054.1\u001b[0m\n",
      "\u001b[31m[65]#011train-mae:8995.39#011validation-mae:34960.7\u001b[0m\n",
      "\u001b[31m[66]#011train-mae:8829.18#011validation-mae:34927.7\u001b[0m\n",
      "\u001b[31m[67]#011train-mae:8672.35#011validation-mae:34831.7\u001b[0m\n",
      "\u001b[31m[68]#011train-mae:8537.85#011validation-mae:34791.6\u001b[0m\n",
      "\u001b[31m[69]#011train-mae:8388.54#011validation-mae:34787.8\u001b[0m\n",
      "\u001b[31m[70]#011train-mae:8241.12#011validation-mae:34789.7\u001b[0m\n",
      "\u001b[31m[71]#011train-mae:8060.06#011validation-mae:34820\u001b[0m\n",
      "\u001b[31m[72]#011train-mae:7938.71#011validation-mae:34745.9\u001b[0m\n",
      "\u001b[31m[73]#011train-mae:7812.74#011validation-mae:34682.9\u001b[0m\n",
      "\u001b[31m[74]#011train-mae:7671.37#011validation-mae:34711.5\u001b[0m\n",
      "\u001b[31m[75]#011train-mae:7569.9#011validation-mae:34718.1\u001b[0m\n",
      "\u001b[31m[76]#011train-mae:7462.51#011validation-mae:34635.4\u001b[0m\n",
      "\u001b[31m[77]#011train-mae:7363.35#011validation-mae:34647.4\u001b[0m\n",
      "\u001b[31m[78]#011train-mae:7277.12#011validation-mae:34651.5\u001b[0m\n",
      "\u001b[31m[79]#011train-mae:7178.73#011validation-mae:34647.5\u001b[0m\n",
      "\u001b[31m[80]#011train-mae:7069.22#011validation-mae:34670.5\u001b[0m\n",
      "\u001b[31m[81]#011train-mae:6953.49#011validation-mae:34629.4\u001b[0m\n",
      "\u001b[31m[82]#011train-mae:6832.65#011validation-mae:34575.1\u001b[0m\n",
      "\u001b[31m[83]#011train-mae:6713.43#011validation-mae:34586.9\u001b[0m\n",
      "\u001b[31m[84]#011train-mae:6601.53#011validation-mae:34521.3\u001b[0m\n",
      "\u001b[31m[85]#011train-mae:6497.21#011validation-mae:34515\u001b[0m\n",
      "\u001b[31m[86]#011train-mae:6380.53#011validation-mae:34546.1\u001b[0m\n",
      "\u001b[31m[87]#011train-mae:6284.41#011validation-mae:34566.2\u001b[0m\n",
      "\u001b[31m[88]#011train-mae:6175.97#011validation-mae:34507.3\u001b[0m\n",
      "\u001b[31m[89]#011train-mae:6105.99#011validation-mae:34498\u001b[0m\n",
      "\u001b[31m[90]#011train-mae:6006.78#011validation-mae:34451.6\u001b[0m\n",
      "\u001b[31m[91]#011train-mae:5928.97#011validation-mae:34444.8\u001b[0m\n",
      "\u001b[31m[92]#011train-mae:5841.28#011validation-mae:34377.8\u001b[0m\n",
      "\u001b[31m[93]#011train-mae:5758.63#011validation-mae:34385.5\u001b[0m\n",
      "\u001b[31m[94]#011train-mae:5685.35#011validation-mae:34356.5\u001b[0m\n",
      "\u001b[31m[95]#011train-mae:5576.61#011validation-mae:34330.2\u001b[0m\n",
      "\u001b[31m[96]#011train-mae:5473.59#011validation-mae:34281.1\u001b[0m\n",
      "\u001b[31m[97]#011train-mae:5388.26#011validation-mae:34263.2\u001b[0m\n",
      "\u001b[31m[98]#011train-mae:5301.71#011validation-mae:34236\u001b[0m\n",
      "\u001b[31m[99]#011train-mae:5195.76#011validation-mae:34203\u001b[0m\n",
      "\u001b[31m[100]#011train-mae:5101.07#011validation-mae:34164.4\u001b[0m\n",
      "\u001b[31m[101]#011train-mae:5024.86#011validation-mae:34155.9\u001b[0m\n",
      "\u001b[31m[102]#011train-mae:4954.78#011validation-mae:34192.4\u001b[0m\n",
      "\u001b[31m[103]#011train-mae:4869.29#011validation-mae:34138.7\u001b[0m\n",
      "\u001b[31m[104]#011train-mae:4790.77#011validation-mae:34094.8\u001b[0m\n",
      "\u001b[31m[105]#011train-mae:4722.9#011validation-mae:34108.4\u001b[0m\n",
      "\u001b[31m[106]#011train-mae:4630.75#011validation-mae:34100\u001b[0m\n",
      "\u001b[31m[107]#011train-mae:4574.92#011validation-mae:34138.5\u001b[0m\n",
      "\u001b[31m[108]#011train-mae:4502.14#011validation-mae:34122.9\u001b[0m\n",
      "\u001b[31m[109]#011train-mae:4432.04#011validation-mae:34102.1\u001b[0m\n",
      "\u001b[31m[110]#011train-mae:4383.42#011validation-mae:34129.6\u001b[0m\n",
      "\u001b[31m[111]#011train-mae:4317.69#011validation-mae:34135.1\u001b[0m\n",
      "\u001b[31m[112]#011train-mae:4260.16#011validation-mae:34140.3\u001b[0m\n",
      "\u001b[31m[113]#011train-mae:4184.38#011validation-mae:34135.2\u001b[0m\n",
      "\u001b[31m[114]#011train-mae:4109.6#011validation-mae:34127.9\u001b[0m\n",
      "\u001b[31m[115]#011train-mae:4055.82#011validation-mae:34164.1\u001b[0m\n",
      "\u001b[31m[116]#011train-mae:3990.95#011validation-mae:34168.5\u001b[0m\n",
      "\u001b[31m[117]#011train-mae:3938.48#011validation-mae:34223.1\u001b[0m\n",
      "\u001b[31m[118]#011train-mae:3888.29#011validation-mae:34244.7\u001b[0m\n",
      "\u001b[31m[119]#011train-mae:3839.31#011validation-mae:34222.1\u001b[0m\n",
      "\u001b[31m[120]#011train-mae:3775.37#011validation-mae:34211.6\u001b[0m\n",
      "\u001b[31m[121]#011train-mae:3739.4#011validation-mae:34155.7\u001b[0m\n",
      "\u001b[31m[122]#011train-mae:3691.95#011validation-mae:34129.4\u001b[0m\n",
      "\u001b[31m[123]#011train-mae:3644.72#011validation-mae:34098.5\u001b[0m\n",
      "\u001b[31m[124]#011train-mae:3594.11#011validation-mae:34121.9\u001b[0m\n",
      "\u001b[31m[125]#011train-mae:3526.19#011validation-mae:34104.1\u001b[0m\n",
      "\u001b[31m[126]#011train-mae:3485.5#011validation-mae:34101\u001b[0m\n",
      "\u001b[31m[127]#011train-mae:3445.16#011validation-mae:34097.5\u001b[0m\n",
      "\u001b[31m[128]#011train-mae:3398.77#011validation-mae:34099.2\u001b[0m\n",
      "\u001b[31m[129]#011train-mae:3354.12#011validation-mae:34081.2\u001b[0m\n",
      "\u001b[31m[130]#011train-mae:3311.96#011validation-mae:34073.2\u001b[0m\n",
      "\u001b[31m[131]#011train-mae:3264.91#011validation-mae:34065\u001b[0m\n",
      "\u001b[31m[132]#011train-mae:3227.74#011validation-mae:34085.1\u001b[0m\n",
      "\u001b[31m[133]#011train-mae:3180.81#011validation-mae:34054.4\u001b[0m\n",
      "\u001b[31m[134]#011train-mae:3131.59#011validation-mae:34019.5\u001b[0m\n",
      "\u001b[31m[135]#011train-mae:3089.05#011validation-mae:34029.1\u001b[0m\n",
      "\u001b[31m[136]#011train-mae:3043.05#011validation-mae:34008.5\u001b[0m\n",
      "\u001b[31m[137]#011train-mae:3015#011validation-mae:33988.4\u001b[0m\n",
      "\u001b[31m[138]#011train-mae:2985.52#011validation-mae:33994.3\u001b[0m\n",
      "\u001b[31m[139]#011train-mae:2933.73#011validation-mae:33995.6\u001b[0m\n",
      "\u001b[31m[140]#011train-mae:2888.76#011validation-mae:33998.7\u001b[0m\n",
      "\u001b[31m[141]#011train-mae:2856.36#011validation-mae:33961.5\u001b[0m\n",
      "\u001b[31m[142]#011train-mae:2809.3#011validation-mae:33967.8\u001b[0m\n",
      "\u001b[31m[143]#011train-mae:2773.2#011validation-mae:33992.3\u001b[0m\n",
      "\u001b[31m[144]#011train-mae:2730.63#011validation-mae:34007.2\u001b[0m\n",
      "\u001b[31m[145]#011train-mae:2697.36#011validation-mae:33999.3\u001b[0m\n",
      "\u001b[31m[146]#011train-mae:2655.33#011validation-mae:34006.4\u001b[0m\n",
      "\u001b[31m[147]#011train-mae:2623.55#011validation-mae:33985.1\u001b[0m\n",
      "\u001b[31m[148]#011train-mae:2590.04#011validation-mae:33986.4\u001b[0m\n",
      "\u001b[31m[149]#011train-mae:2566.62#011validation-mae:33982.2\u001b[0m\n",
      "\u001b[31m[150]#011train-mae:2520.65#011validation-mae:33977\u001b[0m\n",
      "\u001b[31m[151]#011train-mae:2488.97#011validation-mae:33985.5\u001b[0m\n",
      "\u001b[31m[152]#011train-mae:2454.75#011validation-mae:33977.8\u001b[0m\n",
      "\u001b[31m[153]#011train-mae:2435.73#011validation-mae:33990.5\u001b[0m\n",
      "\u001b[31m[154]#011train-mae:2417.01#011validation-mae:33957.9\u001b[0m\n",
      "\u001b[31m[155]#011train-mae:2381.29#011validation-mae:33970.8\u001b[0m\n",
      "\u001b[31m[156]#011train-mae:2357.61#011validation-mae:33966.9\u001b[0m\n",
      "\u001b[31m[157]#011train-mae:2331.06#011validation-mae:33952.2\u001b[0m\n",
      "\u001b[31m[158]#011train-mae:2295.88#011validation-mae:33947\u001b[0m\n",
      "\u001b[31m[159]#011train-mae:2271.71#011validation-mae:33935.8\u001b[0m\n",
      "\u001b[31m[160]#011train-mae:2244.65#011validation-mae:33929.6\u001b[0m\n",
      "\u001b[31m[161]#011train-mae:2209.48#011validation-mae:33943.1\u001b[0m\n",
      "\u001b[31m[162]#011train-mae:2180.99#011validation-mae:33944.7\u001b[0m\n",
      "\u001b[31m[163]#011train-mae:2149.53#011validation-mae:33949.6\u001b[0m\n",
      "\u001b[31m[164]#011train-mae:2117.12#011validation-mae:33964.4\u001b[0m\n",
      "\u001b[31m[165]#011train-mae:2088.33#011validation-mae:33957.3\u001b[0m\n",
      "\u001b[31m[166]#011train-mae:2056.73#011validation-mae:33942.7\u001b[0m\n",
      "\u001b[31m[167]#011train-mae:2030.75#011validation-mae:33945.8\u001b[0m\n",
      "\u001b[31m[168]#011train-mae:2010.34#011validation-mae:33941.6\u001b[0m\n",
      "\u001b[31m[169]#011train-mae:1988.94#011validation-mae:33947.7\u001b[0m\n",
      "\u001b[31m[170]#011train-mae:1966.06#011validation-mae:33968.5\u001b[0m\n",
      "\u001b[31m[171]#011train-mae:1934.07#011validation-mae:33973.7\u001b[0m\n",
      "\u001b[31m[172]#011train-mae:1901.58#011validation-mae:33977.3\u001b[0m\n",
      "\u001b[31m[173]#011train-mae:1874.53#011validation-mae:33950.2\u001b[0m\n",
      "\u001b[31m[174]#011train-mae:1862.23#011validation-mae:33937.8\u001b[0m\n",
      "\u001b[31m[175]#011train-mae:1844.15#011validation-mae:33942\u001b[0m\n",
      "\u001b[31m[176]#011train-mae:1819.11#011validation-mae:33920.3\u001b[0m\n",
      "\u001b[31m[177]#011train-mae:1786.59#011validation-mae:33923.1\u001b[0m\n",
      "\u001b[31m[178]#011train-mae:1770.41#011validation-mae:33920.6\u001b[0m\n",
      "\u001b[31m[179]#011train-mae:1743.47#011validation-mae:33918.9\u001b[0m\n",
      "\u001b[31m[180]#011train-mae:1716.13#011validation-mae:33911.8\u001b[0m\n",
      "\u001b[31m[181]#011train-mae:1697.81#011validation-mae:33904.7\u001b[0m\n",
      "\u001b[31m[182]#011train-mae:1677.1#011validation-mae:33895.9\u001b[0m\n",
      "\u001b[31m[183]#011train-mae:1657.64#011validation-mae:33878.4\u001b[0m\n",
      "\u001b[31m[184]#011train-mae:1636.69#011validation-mae:33881.1\u001b[0m\n",
      "\u001b[31m[185]#011train-mae:1622.11#011validation-mae:33868.8\u001b[0m\n",
      "\u001b[31m[186]#011train-mae:1598.86#011validation-mae:33864.9\u001b[0m\n",
      "\u001b[31m[187]#011train-mae:1577.95#011validation-mae:33876.3\u001b[0m\n",
      "\u001b[31m[188]#011train-mae:1556.41#011validation-mae:33869.4\u001b[0m\n",
      "\u001b[31m[189]#011train-mae:1537.24#011validation-mae:33870.2\u001b[0m\n",
      "\u001b[31m[190]#011train-mae:1522.69#011validation-mae:33864.4\u001b[0m\n",
      "\u001b[31m[191]#011train-mae:1505.27#011validation-mae:33862.4\u001b[0m\n",
      "\u001b[31m[192]#011train-mae:1487.45#011validation-mae:33861.2\u001b[0m\n",
      "\u001b[31m[193]#011train-mae:1468.26#011validation-mae:33868.3\u001b[0m\n",
      "\u001b[31m[194]#011train-mae:1451.53#011validation-mae:33855.4\u001b[0m\n",
      "\u001b[31m[195]#011train-mae:1428#011validation-mae:33863.9\u001b[0m\n",
      "\u001b[31m[196]#011train-mae:1410.82#011validation-mae:33854.3\u001b[0m\n",
      "\u001b[31m[197]#011train-mae:1393.36#011validation-mae:33856.4\u001b[0m\n",
      "\u001b[31m[198]#011train-mae:1375.75#011validation-mae:33856.8\u001b[0m\n",
      "\u001b[31m[199]#011train-mae:1357.14#011validation-mae:33862.3\u001b[0m\n",
      "\u001b[31m[200]#011train-mae:1346.91#011validation-mae:33868.1\u001b[0m\n",
      "\u001b[31m[201]#011train-mae:1330.31#011validation-mae:33862.6\u001b[0m\n",
      "\u001b[31m[202]#011train-mae:1313.4#011validation-mae:33860.2\u001b[0m\n",
      "\u001b[31m[203]#011train-mae:1296.79#011validation-mae:33848.8\u001b[0m\n",
      "\u001b[31m[204]#011train-mae:1281.49#011validation-mae:33848\u001b[0m\n",
      "\u001b[31m[205]#011train-mae:1269.65#011validation-mae:33844.5\u001b[0m\n",
      "\u001b[31m[206]#011train-mae:1254.88#011validation-mae:33856.5\u001b[0m\n",
      "\u001b[31m[207]#011train-mae:1238.95#011validation-mae:33854.3\u001b[0m\n",
      "\u001b[31m[208]#011train-mae:1219.31#011validation-mae:33854.7\u001b[0m\n",
      "\u001b[31m[209]#011train-mae:1205.78#011validation-mae:33845.6\u001b[0m\n",
      "\u001b[31m[210]#011train-mae:1193.12#011validation-mae:33838\u001b[0m\n",
      "\u001b[31m[211]#011train-mae:1182.05#011validation-mae:33845.5\u001b[0m\n",
      "\u001b[31m[212]#011train-mae:1165.3#011validation-mae:33843.1\u001b[0m\n",
      "\u001b[31m[213]#011train-mae:1152.04#011validation-mae:33840.6\u001b[0m\n",
      "\u001b[31m[214]#011train-mae:1133.7#011validation-mae:33839.1\u001b[0m\n",
      "\u001b[31m[215]#011train-mae:1122.48#011validation-mae:33840.5\u001b[0m\n",
      "\u001b[31m[216]#011train-mae:1111.32#011validation-mae:33834.3\u001b[0m\n",
      "\u001b[31m[217]#011train-mae:1092.47#011validation-mae:33837.2\u001b[0m\n",
      "\u001b[31m[218]#011train-mae:1074.25#011validation-mae:33841.6\u001b[0m\n",
      "\u001b[31m[219]#011train-mae:1061.36#011validation-mae:33836.5\u001b[0m\n",
      "\u001b[31m[220]#011train-mae:1048.02#011validation-mae:33831.6\u001b[0m\n",
      "\u001b[31m[221]#011train-mae:1030.36#011validation-mae:33834.2\u001b[0m\n",
      "\u001b[31m[222]#011train-mae:1021.15#011validation-mae:33830.7\u001b[0m\n",
      "\u001b[31m[223]#011train-mae:1009.24#011validation-mae:33833.5\u001b[0m\n",
      "\u001b[31m[224]#011train-mae:995.897#011validation-mae:33824.9\u001b[0m\n",
      "\u001b[31m[225]#011train-mae:985.981#011validation-mae:33829.7\u001b[0m\n",
      "\u001b[31m[226]#011train-mae:972.709#011validation-mae:33828.4\u001b[0m\n",
      "\u001b[31m[227]#011train-mae:961.105#011validation-mae:33830.8\u001b[0m\n",
      "\u001b[31m[228]#011train-mae:953.342#011validation-mae:33829\u001b[0m\n",
      "\u001b[31m[229]#011train-mae:941.9#011validation-mae:33827.4\u001b[0m\n",
      "\u001b[31m[230]#011train-mae:929.966#011validation-mae:33821.9\u001b[0m\n",
      "\u001b[31m[231]#011train-mae:918.661#011validation-mae:33825.3\u001b[0m\n",
      "\u001b[31m[232]#011train-mae:907.833#011validation-mae:33826.1\u001b[0m\n",
      "\u001b[31m[233]#011train-mae:893.407#011validation-mae:33822.7\u001b[0m\n",
      "\u001b[31m[234]#011train-mae:885.793#011validation-mae:33816.4\u001b[0m\n",
      "\u001b[31m[235]#011train-mae:875.66#011validation-mae:33818.5\u001b[0m\n",
      "\u001b[31m[236]#011train-mae:866.456#011validation-mae:33819.8\u001b[0m\n",
      "\u001b[31m[237]#011train-mae:859.224#011validation-mae:33821.8\u001b[0m\n",
      "\u001b[31m[238]#011train-mae:849.325#011validation-mae:33826.5\u001b[0m\n",
      "\u001b[31m[239]#011train-mae:840.462#011validation-mae:33827.4\u001b[0m\n",
      "\u001b[31m[240]#011train-mae:830.261#011validation-mae:33824.2\u001b[0m\n",
      "\u001b[31m[241]#011train-mae:820.785#011validation-mae:33826\u001b[0m\n",
      "\u001b[31m[242]#011train-mae:811.738#011validation-mae:33828.5\u001b[0m\n",
      "\u001b[31m[243]#011train-mae:800.199#011validation-mae:33821.4\u001b[0m\n",
      "\u001b[31m[244]#011train-mae:790.181#011validation-mae:33816.7\u001b[0m\n",
      "\u001b[31m[245]#011train-mae:776.415#011validation-mae:33818.7\u001b[0m\n",
      "\u001b[31m[246]#011train-mae:769.493#011validation-mae:33812\u001b[0m\n",
      "\u001b[31m[247]#011train-mae:760.617#011validation-mae:33813.6\u001b[0m\n",
      "\u001b[31m[248]#011train-mae:749.281#011validation-mae:33819.7\u001b[0m\n",
      "\u001b[31m[249]#011train-mae:739.768#011validation-mae:33825.2\u001b[0m\n",
      "\u001b[31m[250]#011train-mae:729.054#011validation-mae:33822\u001b[0m\n",
      "\u001b[31m[251]#011train-mae:722.551#011validation-mae:33816.1\u001b[0m\n",
      "\u001b[31m[252]#011train-mae:714.557#011validation-mae:33816.9\u001b[0m\n",
      "\u001b[31m[253]#011train-mae:704.573#011validation-mae:33823\u001b[0m\n",
      "\u001b[31m[254]#011train-mae:698.124#011validation-mae:33818.7\u001b[0m\n",
      "\u001b[31m[255]#011train-mae:692.454#011validation-mae:33821.7\u001b[0m\n",
      "\u001b[31m[256]#011train-mae:683.918#011validation-mae:33826\u001b[0m\n",
      "\u001b[31m[257]#011train-mae:678.519#011validation-mae:33825.1\u001b[0m\n",
      "\u001b[31m[258]#011train-mae:670.926#011validation-mae:33823.4\u001b[0m\n",
      "\u001b[31m[259]#011train-mae:664.189#011validation-mae:33828\u001b[0m\n",
      "\u001b[31m[260]#011train-mae:659.27#011validation-mae:33828.9\u001b[0m\n",
      "\u001b[31m[261]#011train-mae:650.226#011validation-mae:33825.5\u001b[0m\n",
      "\u001b[31m[262]#011train-mae:643.058#011validation-mae:33819\u001b[0m\n",
      "\u001b[31m[263]#011train-mae:634.003#011validation-mae:33818.7\u001b[0m\n",
      "\u001b[31m[264]#011train-mae:626.738#011validation-mae:33808.8\u001b[0m\n",
      "\u001b[31m[265]#011train-mae:619.14#011validation-mae:33808.3\u001b[0m\n",
      "\u001b[31m[266]#011train-mae:613.674#011validation-mae:33815.3\u001b[0m\n",
      "\u001b[31m[267]#011train-mae:606.74#011validation-mae:33818.7\u001b[0m\n",
      "\u001b[31m[268]#011train-mae:600.298#011validation-mae:33819.8\u001b[0m\n",
      "\u001b[31m[269]#011train-mae:595.432#011validation-mae:33817.5\u001b[0m\n",
      "\u001b[31m[270]#011train-mae:587.858#011validation-mae:33817.5\u001b[0m\n",
      "\u001b[31m[271]#011train-mae:578.914#011validation-mae:33822.1\u001b[0m\n",
      "\u001b[31m[272]#011train-mae:572.217#011validation-mae:33821.8\u001b[0m\n",
      "\u001b[31m[273]#011train-mae:567.616#011validation-mae:33825.5\u001b[0m\n",
      "\u001b[31m[274]#011train-mae:560.939#011validation-mae:33824\u001b[0m\n",
      "\u001b[31m[275]#011train-mae:554.275#011validation-mae:33824.2\u001b[0m\n",
      "\u001b[31m[276]#011train-mae:545.39#011validation-mae:33828.1\u001b[0m\n",
      "\u001b[31m[277]#011train-mae:538.922#011validation-mae:33831.2\u001b[0m\n",
      "\u001b[31m[278]#011train-mae:533.059#011validation-mae:33822.4\u001b[0m\n",
      "\u001b[31m[279]#011train-mae:527.855#011validation-mae:33826.9\u001b[0m\n",
      "\u001b[31m[280]#011train-mae:524.672#011validation-mae:33825.5\u001b[0m\n",
      "\u001b[31m[281]#011train-mae:517.873#011validation-mae:33823.6\u001b[0m\n",
      "\u001b[31m[282]#011train-mae:513.162#011validation-mae:33825\u001b[0m\n",
      "\u001b[31m[283]#011train-mae:508.173#011validation-mae:33820.9\u001b[0m\n",
      "\u001b[31m[284]#011train-mae:503.726#011validation-mae:33819.1\u001b[0m\n",
      "\u001b[31m[285]#011train-mae:497.857#011validation-mae:33816.1\u001b[0m\n",
      "\u001b[31m[286]#011train-mae:490.12#011validation-mae:33813.1\u001b[0m\n",
      "\u001b[31m[287]#011train-mae:483.61#011validation-mae:33812.5\u001b[0m\n",
      "\u001b[31m[288]#011train-mae:478.885#011validation-mae:33813.6\u001b[0m\n",
      "\u001b[31m[289]#011train-mae:472.405#011validation-mae:33817.8\u001b[0m\n",
      "\u001b[31m[290]#011train-mae:465.814#011validation-mae:33815\u001b[0m\n",
      "\u001b[31m[291]#011train-mae:460.687#011validation-mae:33813.4\u001b[0m\n",
      "\u001b[31m[292]#011train-mae:457.793#011validation-mae:33813.8\u001b[0m\n",
      "\u001b[31m[293]#011train-mae:452.598#011validation-mae:33810.3\u001b[0m\n",
      "\u001b[31m[294]#011train-mae:446.767#011validation-mae:33809.1\u001b[0m\n",
      "\u001b[31m[295]#011train-mae:440.944#011validation-mae:33807\u001b[0m\n",
      "\u001b[31m[296]#011train-mae:435.611#011validation-mae:33808.7\u001b[0m\n",
      "\u001b[31m[297]#011train-mae:429.721#011validation-mae:33807.9\u001b[0m\n",
      "\u001b[31m[298]#011train-mae:425.012#011validation-mae:33807.7\u001b[0m\n",
      "\u001b[31m[299]#011train-mae:418.218#011validation-mae:33808.5\u001b[0m\n",
      "\u001b[31m[300]#011train-mae:414.9#011validation-mae:33806.3\u001b[0m\n",
      "\u001b[31m[301]#011train-mae:408.387#011validation-mae:33805\u001b[0m\n",
      "\u001b[31m[302]#011train-mae:403.841#011validation-mae:33804.3\u001b[0m\n",
      "\u001b[31m[303]#011train-mae:398.69#011validation-mae:33801.1\u001b[0m\n",
      "\u001b[31m[304]#011train-mae:393.803#011validation-mae:33801.5\u001b[0m\n",
      "\u001b[31m[305]#011train-mae:389.92#011validation-mae:33803.7\u001b[0m\n",
      "\u001b[31m[306]#011train-mae:385.611#011validation-mae:33803.5\u001b[0m\n",
      "\u001b[31m[307]#011train-mae:383.394#011validation-mae:33800.9\u001b[0m\n",
      "\u001b[31m[308]#011train-mae:380.211#011validation-mae:33802.6\u001b[0m\n",
      "\u001b[31m[309]#011train-mae:374.987#011validation-mae:33802.9\u001b[0m\n",
      "\u001b[31m[310]#011train-mae:371.877#011validation-mae:33800.6\u001b[0m\n",
      "\u001b[31m[311]#011train-mae:366.64#011validation-mae:33801\u001b[0m\n",
      "\u001b[31m[312]#011train-mae:362.701#011validation-mae:33802.4\u001b[0m\n",
      "\u001b[31m[313]#011train-mae:358.549#011validation-mae:33803.2\u001b[0m\n",
      "\u001b[31m[314]#011train-mae:354.771#011validation-mae:33799.5\u001b[0m\n",
      "\u001b[31m[315]#011train-mae:350.669#011validation-mae:33796.3\u001b[0m\n",
      "\u001b[31m[316]#011train-mae:346.278#011validation-mae:33792.3\u001b[0m\n",
      "\u001b[31m[317]#011train-mae:343.308#011validation-mae:33790.1\u001b[0m\n",
      "\u001b[31m[318]#011train-mae:339.383#011validation-mae:33790\u001b[0m\n",
      "\u001b[31m[319]#011train-mae:335.649#011validation-mae:33791.2\u001b[0m\n",
      "\u001b[31m[320]#011train-mae:331.478#011validation-mae:33789.4\u001b[0m\n",
      "\u001b[31m[321]#011train-mae:326.418#011validation-mae:33790\u001b[0m\n",
      "\u001b[31m[322]#011train-mae:323.625#011validation-mae:33789\u001b[0m\n",
      "\u001b[31m[323]#011train-mae:319.616#011validation-mae:33788.6\u001b[0m\n",
      "\u001b[31m[324]#011train-mae:315.064#011validation-mae:33786.8\u001b[0m\n",
      "\u001b[31m[325]#011train-mae:312.096#011validation-mae:33784.4\u001b[0m\n",
      "\u001b[31m[326]#011train-mae:309.308#011validation-mae:33784.6\u001b[0m\n",
      "\u001b[31m[327]#011train-mae:305.279#011validation-mae:33785.8\u001b[0m\n",
      "\u001b[31m[328]#011train-mae:301.179#011validation-mae:33787.8\u001b[0m\n",
      "\u001b[31m[329]#011train-mae:297.391#011validation-mae:33790.8\u001b[0m\n",
      "\u001b[31m[330]#011train-mae:294.023#011validation-mae:33790.1\u001b[0m\n",
      "\u001b[31m[331]#011train-mae:289.642#011validation-mae:33788.9\u001b[0m\n",
      "\u001b[31m[332]#011train-mae:287.121#011validation-mae:33790.2\u001b[0m\n",
      "\u001b[31m[333]#011train-mae:283.544#011validation-mae:33791.2\u001b[0m\n",
      "\u001b[31m[334]#011train-mae:281.016#011validation-mae:33790.3\u001b[0m\n",
      "\u001b[31m[335]#011train-mae:278.113#011validation-mae:33790\u001b[0m\n",
      "\u001b[31m[336]#011train-mae:275.51#011validation-mae:33785.2\u001b[0m\n",
      "\u001b[31m[337]#011train-mae:271.493#011validation-mae:33786.6\u001b[0m\n",
      "\u001b[31m[338]#011train-mae:267.75#011validation-mae:33787.6\u001b[0m\n",
      "\u001b[31m[339]#011train-mae:264.293#011validation-mae:33785.1\u001b[0m\n",
      "\u001b[31m[340]#011train-mae:261.925#011validation-mae:33784.5\u001b[0m\n",
      "\u001b[31m[341]#011train-mae:260.638#011validation-mae:33784.9\u001b[0m\n",
      "\u001b[31m[342]#011train-mae:257.68#011validation-mae:33784.9\u001b[0m\n",
      "\u001b[31m[343]#011train-mae:255.9#011validation-mae:33787.4\u001b[0m\n",
      "\u001b[31m[344]#011train-mae:254.42#011validation-mae:33786.4\u001b[0m\n",
      "\u001b[31m[345]#011train-mae:251.797#011validation-mae:33784.9\u001b[0m\n",
      "\u001b[31m[346]#011train-mae:249.894#011validation-mae:33786.5\u001b[0m\n",
      "\u001b[31m[347]#011train-mae:246.912#011validation-mae:33783.6\u001b[0m\n",
      "\u001b[31m[348]#011train-mae:242.829#011validation-mae:33784.7\u001b[0m\n",
      "\u001b[31m[349]#011train-mae:239.684#011validation-mae:33783.2\u001b[0m\n",
      "\u001b[31m[350]#011train-mae:237.332#011validation-mae:33783.4\u001b[0m\n",
      "\u001b[31m[351]#011train-mae:235.849#011validation-mae:33781.6\u001b[0m\n",
      "\u001b[31m[352]#011train-mae:233.747#011validation-mae:33781.9\u001b[0m\n",
      "\u001b[31m[353]#011train-mae:231.044#011validation-mae:33779.5\u001b[0m\n",
      "\u001b[31m[354]#011train-mae:228.981#011validation-mae:33779.2\u001b[0m\n",
      "\u001b[31m[355]#011train-mae:226.146#011validation-mae:33777.4\u001b[0m\n",
      "\u001b[31m[356]#011train-mae:224.796#011validation-mae:33779.1\u001b[0m\n",
      "\u001b[31m[357]#011train-mae:221.472#011validation-mae:33777.5\u001b[0m\n",
      "\u001b[31m[358]#011train-mae:219.641#011validation-mae:33777.1\u001b[0m\n",
      "\u001b[31m[359]#011train-mae:217.629#011validation-mae:33777.5\u001b[0m\n",
      "\u001b[31m[360]#011train-mae:215.389#011validation-mae:33777.7\u001b[0m\n",
      "\u001b[31m[361]#011train-mae:212.842#011validation-mae:33777.6\u001b[0m\n",
      "\u001b[31m[362]#011train-mae:210.564#011validation-mae:33775.5\u001b[0m\n",
      "\u001b[31m[363]#011train-mae:208.645#011validation-mae:33777.8\u001b[0m\n",
      "\u001b[31m[364]#011train-mae:207.069#011validation-mae:33779.7\u001b[0m\n",
      "\u001b[31m[365]#011train-mae:204.471#011validation-mae:33779.3\u001b[0m\n",
      "\u001b[31m[366]#011train-mae:200.872#011validation-mae:33778.9\u001b[0m\n",
      "\u001b[31m[367]#011train-mae:199.089#011validation-mae:33778.2\u001b[0m\n",
      "\u001b[31m[368]#011train-mae:196.856#011validation-mae:33777.5\u001b[0m\n",
      "\u001b[31m[369]#011train-mae:195.172#011validation-mae:33776.2\u001b[0m\n",
      "\u001b[31m[370]#011train-mae:193.463#011validation-mae:33775.2\u001b[0m\n",
      "\u001b[31m[371]#011train-mae:191.867#011validation-mae:33773.6\u001b[0m\n",
      "\u001b[31m[372]#011train-mae:189.491#011validation-mae:33772.5\u001b[0m\n",
      "\u001b[31m[373]#011train-mae:187.674#011validation-mae:33773.8\u001b[0m\n",
      "\u001b[31m[374]#011train-mae:184.902#011validation-mae:33774.4\u001b[0m\n",
      "\u001b[31m[375]#011train-mae:182.679#011validation-mae:33772.8\u001b[0m\n",
      "\u001b[31m[376]#011train-mae:180.167#011validation-mae:33770\u001b[0m\n",
      "\u001b[31m[377]#011train-mae:178.445#011validation-mae:33771.5\u001b[0m\n",
      "\u001b[31m[378]#011train-mae:176.945#011validation-mae:33772.4\u001b[0m\n",
      "\u001b[31m[379]#011train-mae:174.973#011validation-mae:33772.7\u001b[0m\n",
      "\u001b[31m[380]#011train-mae:173.607#011validation-mae:33772.5\u001b[0m\n",
      "\u001b[31m[381]#011train-mae:171.779#011validation-mae:33772.9\u001b[0m\n",
      "\u001b[31m[382]#011train-mae:170.373#011validation-mae:33775\u001b[0m\n",
      "\u001b[31m[383]#011train-mae:168.476#011validation-mae:33773.8\u001b[0m\n",
      "\u001b[31m[384]#011train-mae:167.282#011validation-mae:33776.1\u001b[0m\n",
      "\u001b[31m[385]#011train-mae:166.111#011validation-mae:33775.1\u001b[0m\n",
      "\u001b[31m[386]#011train-mae:164.852#011validation-mae:33775.2\u001b[0m\n",
      "\u001b[31m[387]#011train-mae:162.342#011validation-mae:33775.2\u001b[0m\n",
      "\u001b[31m[388]#011train-mae:160.259#011validation-mae:33777.7\u001b[0m\n",
      "\u001b[31m[389]#011train-mae:158.447#011validation-mae:33778.1\u001b[0m\n",
      "\u001b[31m[390]#011train-mae:157.164#011validation-mae:33778\u001b[0m\n",
      "\u001b[31m[391]#011train-mae:154.988#011validation-mae:33777.4\u001b[0m\n",
      "\u001b[31m[392]#011train-mae:152.882#011validation-mae:33777.2\u001b[0m\n",
      "\u001b[31m[393]#011train-mae:152.016#011validation-mae:33777.4\u001b[0m\n",
      "\u001b[31m[394]#011train-mae:150.772#011validation-mae:33777\u001b[0m\n",
      "\u001b[31m[395]#011train-mae:149.398#011validation-mae:33777.2\u001b[0m\n",
      "\u001b[31m[396]#011train-mae:147.455#011validation-mae:33776.1\u001b[0m\n",
      "\u001b[31m[397]#011train-mae:145.702#011validation-mae:33775.6\u001b[0m\n",
      "\u001b[31m[398]#011train-mae:143.985#011validation-mae:33775.9\u001b[0m\n",
      "\u001b[31m[399]#011train-mae:141.668#011validation-mae:33775.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 46\n",
      "Billable seconds: 46\n"
     ]
    }
   ],
   "source": [
    "optimized_xgb = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06663755951957767\n"
     ]
    }
   ],
   "source": [
    "top_mae = 33775.5\n",
    "mape = top_mae / y_val.mean()\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. Now that we have found our optimal hyperparameters and trained our model, we are ready to use it to predict the sale price of our active listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "We will use SageMaker's Batch Transform functionality to test our model, so first we will define a transformer object using our optimized model from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer = optimized_xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................!\n"
     ]
    }
   ],
   "source": [
    "# Earlier we saved X_test to S3 and stored that path as 'test_location'\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.9 KiB/1.9 KiB (29.0 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-2-359641297910/sagemaker-xgboost-190906-2349-009-77266-2019-09-07-00-01-14-086/test.csv.out to ../data/listings/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "# Output is saved to S3, so we will need to load it into this notebook from S3\n",
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir\n",
    "\n",
    "# Predicted values for the test set will be saved to Pandas Series object 'y_pred'\n",
    "y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mape(y_true, y_pred):\n",
    "#     y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "#     return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400.27176339286\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAPE of model's predictions of unseen samples\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value seems like a pretty good fit since \\\\$32,400 is less than 6 percent of the median sale price of \\\\$546,300 in the region. So now that we have tested our model, and the MAE score is satisfactory, we can use this model to predict the actual potential sales price of active listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model for Predicting Value of Active Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
